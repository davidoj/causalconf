%!TEX root = main.tex

\section{Repeatable experiments}

While there are types of measurement processes we could consider, statistical inference usually proceeds from repeatable measurement processes. A common precise notion of repeatability is the assumption of \emph{exchangeability}. The term ``exchangeability'', like the term random variable, is used to refer to both \emph{measurement processes} and \emph{probability models}. If I say a measurement process $\proc{S}$ taking values in $S^n$ is exchangeable, I might mean mean:
\begin{itemize}
    \item I believe that there is some probabilistic model $(\prob{P},\Omega,\sigalg{F})$ and random variable $\RV{S}$ appropriate for modelling $\proc{S}$ and
    \begin{enumerate}
        \item The same model is appropriate for any measurement process that first peforms $\proc{S}$ and subsequently shuffles the results according to a permutation $\text{swap}:S^n\to S^n$ or
        \item The same model is appropriate for any measurement process related to $\proc{S}$ by interchanging experimental units or subjects in the real world
    \end{enumerate} 
\end{itemize}

On the other hand, if I say a probability model $(\prob{P},S^{|A|},\sigalg{S}^{|A|})$ is exchangeable, I mean

\begin{itemize}
    \item For any finite permutation $\text{swap}:S^{|A|}\kto S^{|A|}$, $\prob{P}^{\RV{S}}\text{swap}_{a} = \prob{P}^{\RV{S}}$
\end{itemize}

If I believe a measurement process is exchangeable in the first sense, it implies an exchangeable probability model is appropriate to model it. Measurement process exchangeability in the second sense, which is what is usually meant by ``exchangeable'' when it is mentioned in literature on causal modelling, requires us to make explicit what the mathematical implications of ``interchanging experimental units'' are, because experimental units are parts of the real world and not directly elements of any model.

The precise mathematical implication of the first kind of measurement process exchangeability facilitated the proof of De Finetti's well-known representation theorem; in our language, De Finetti's representation theorem shows the equivalence between the probability gap models defined by ``the random variables $\RV{X}_i$ are an infinite exchangeable sequence'' and model defined by ``the random variables $\RV{X}_i$ are independent and identically distributed condtional on the hypothesis $\RV{H}$'' (proofs of De Finetti's theorem provide definitions $\RV{H}$).

De Finetti's theorem shows that the assumption of measurement process exchangeability implies a model of conditionally independent and identically distributed random variables. The question arises: can we make precise a notion of ``interchanging experimental units'' that implies common causal modelling assumptions found in causal Bayesian network and potential outcomes literature? Answering this question is complicated by the fact that some of the modelling assumptions we are seeking to reproduce have often only been stated informally.

In this section, we will consider \emph{do-models}; these are see-do models $(\prob{P},\RV{X},\RV{D},\RV{Y},R)$ for which the observations are trivial $\RV{X}=*$. These models cannot be compared directly to common causal models, which are generally see-do models with nontrivial observations. We ignore observations because they allow us to focus on the question of how to construct models of repeatable experiments involving both decisions and consequences. Once we know how to do this, we can introduce nontrivial observations and see how the resulting models correspond to certain types of causal Bayesian network and potential outcomes models.

We will consider two different notions of ``repeatable experiments''. Both require a sequence of ``decisions'' to be made and a sequence of consequences, and we assume that each decision corresponds to a single consequence. One could think about these paired sqeuences as a series of experiments each with different setting choices available; the decisions are the setting choices and the consequences are the results of each experiment. The first notion we consider will be \emph{commutativity of exchange} -- we consider the same model appropriate if we alter our experiment by swapping the experimental settings, or if we make analogous swaps to the experimental results. This assumption could be considered a version of the assumption that experimental units can be interchanged. Consider an experiment involving handing out money or not to person A or person B. Commutativity of exchange says that we should expect the same results from 
\begin{itemize}
    \item Applying A's choice to B and examining the consequences for B
    \item Applying A's choice to A and examining the consequences for A
\end{itemize}

Under the assumption of commutativity of exchange, consequences of decisions for one ``unit'' may still depend on decisions made for other ``units''. Consider again the experiment above, except instead of two people it is a whole country of people. It might be reasonable to posit that the consequences of giving money to A and not to anyone else are a permutation of the consequences of giving money to B and not to anybody else (supposing we know nothing else about A and B). However, giving money to A and everyone else will have different consequences for A than giving money to A and no-one else; in the former case, we will create inflation that is not created in the latter.

The second notion of ``repeatable experiments'' is \emph{causal contractibility}, a strictly stronger assumption than commutativity of exchange. Causal contractibility is the assumption that, given two different sequences of decisions, the marginal model of consequences corresponding to matching subsequences of decisions will be equal. A causally contractibly model says that, if I make the same choice for any subcollection of experiments, I expect the same results from those experiments regardless of whatever choices I make elsewhere.

Causal contractibility is equivalent to the existence of an exchangeable ``table lookup'' model that is has much in common with potential outcomes based causal models. The assumption of exchangeability of the lookup table is weaker than the assumption of ``exchangeable potential outcomes'' found in, for example, \citet{greenland_identifiability_1986}; this latter assumption could be called ``conditional exchangeability''.

% Another way to see where we are going is to consider graphical statements of our and De Finetti's result.

% Take $S=\{0,1\}$ and identify the space $\Delta(S)$ of probability measures on $S$ with the interval $[0,1]$. De Finetti showed that any infinite exchangeable probability measure $\prob{P}_\alpha$ on $\{0,1\}^\mathbb{N}$ can be represented by a prior $\prob{P}_\alpha^{\RV{H}}\in [0,1]$ for some $\RV{H}:\Omega\to H$ and a conditional probability $\prob{P}^{\RV{S}_0|\RV{H}}:[0,1]\kto \{0,1\}$ such that

% \begin{align}
%     \prob{P}_\alpha &= \tikzfig{de_finetti_rep0}\label{eq:definettirep}
% \end{align}

% Here $\prob{P}^{\RV{S}_0|\RV{H}}$ can be defined concretely by $\prob{P}^{\RV{S}_0|\RV{H}}(1|h)=h$. Equivalently, the probability gap model on $S^\mathbb{N}$ defined by the assumption of exchangeability is equivalent to the probability gap model defined by the conditional probability

% \begin{align}
%     \prob{P}^{\RV{S}|\RV{H}} = \tikzfig{de_finetti_conditional}
% \end{align}

% That is, there is some hypothesis $\RV{H}$ and conditional on $\RV{H}$ the measurements are independent and identically distributed. The proof of this is constructive -- $\RV{H}$ is a function of $\RV{S}$.



% \begin{align}
%     \prob{P}^{\RV{Y}|\RV{HD}} = \tikzfig{do_model_representation}
% \end{align}

% We will further argue that the class of see-do models considered in CBN and potential outcomes literature is equivalent to the family of causally contractible and exchangeable do-models where the decision rule for the first $n$ places is fixed to an unknown value, and may be freely chosen thereafter.

\subsection{Assumptions of repeatability and their consequences}

A do model is a see-do model with nothing to see. It is purely a model of decisions and consequences.

\begin{definition}[Do model]\label{def:domodel}
A \emph{do-model} is a see-do model $(\prob{P},\RV{X},\RV{D},\RV{Y},R)$ with trivial observations $\RV{X}=*$; we omit $\RV{X}$ and define it by $(\prob{P},\RV{D},\RV{Y},R)$.
\end{definition}

A do model ``commutes with exchange'' if exchanging decisions or exchanging consequences yields the same model for any finite permuation. The term \emph{commute} comes from the notion that we can apply the exchange before the model $\prob{P}$ or after it and get the same result.

\begin{definition}[Commutativity of exchange]\label{def:caus_exch}
Suppose we have a fundamental probability set $\Omega$ and a do model $(\prob{P},\RV{D},\RV{Y},R)$ such that $\RV{D}:=(\RV{D}_i)_{i\in \mathbb{N}}$ and $\RV{Y}:=(\RV{Y}_i)_{i\in\mathbb{N}}$. For a finite permutation $\rho:\mathbb{N}\to\mathbb{N}$, define $\text{swap}_{\rho(D)}:D\kto D$ by $(d_i)_{i\in\mathbb{N}}\mapsto \delta_{(d_{\rho(i)})_{i\in\mathbb{N}}}$ and $\text{swap}_{\rho(D\times Y)}:D\times Y\kto D\times Y$ by $(x_i)_{i\in\mathbb{N}}\mapsto \delta_{(x_{\rho(i)})_{i\in\mathbb{N}}}$. If, for any two decision rules $\alpha,\beta \in R$,
\begin{align}
    \prob{P}_\alpha^{\RV{D}}\text{swap}_{\rho(D)} &= \prob{P}_{\beta}^{\RV{D}}\\
    \implies  \prob{P}_\alpha\text{swap}_{\rho(D\times Y)}&=\prob{P}_\beta
\end{align}
Then $\prob{P}$ \emph{commutes with exchanges}.
\end{definition}

A do model with causal contractibility must give identical results for any identical subsequences of two decisions when we limit our attention to the corresponding subsequences of consequences. For example, if we have $\RV{D}=(\RV{D}_1,\RV{D}_2,\RV{D}_3)$ and $\RV{Y}=(\RV{Y}_1,\RV{Y}_2,\RV{Y}_3)$ and $\prob{P}_\alpha^{\RV{D}_1\RV{D}_3}=\prob{P}_\beta^{\RV{D}_3\RV{D}_2}$ then $\prob{P}_{\alpha}^{\RV{Y}_1\RV{Y}_3}=\prob{P}_\beta^{\RV{Y}_3\RV{Y}_2}$.

\begin{definition}[Causal contractibility]\label{def:caus_cont}
Suppose we have a fundamental probability set $\Omega$ and a do model $(\prob{P},\RV{D},\RV{Y},R)$ such that $\RV{D}:=(\RV{D}_i)_{i\in \mathbb{N}}$ and $\RV{Y}:=(\RV{Y}_i)_{i\in\mathbb{N}}$. For any $A=(s_i)_{i\in A}$, $T=(t_i)_{i\in A}$, $A\subset\mathbb{N}$ and $i<j\implies p_i<p_j \And q_i<q_j$, let $\RV{D}_S:=(\RV{D}_i)_{i\in S}$ and $\RV{D}_T:=(\RV{D}_i)_{i\in T}$. If for any $\alpha,\beta\in R$
\begin{align}
    \prob{P}_\alpha^{\RV{D}_{S}}=\prob{P}_\beta^{\RV{D}_{T}}\implies \prob{P}_\alpha^{(\RV{D_i,Y_i})_{i\in S}}=\prob{P}_\beta^{(\RV{D_i,Y_i})_{i\in T}}
\end{align}
then $\prob{P}$ is \emph{causally contractible}.
\end{definition}

\begin{theorem}
Piecewise replicability implies commutativity of exchange.
\end{theorem}

\begin{proof}
Consider $\alpha,\beta\in R$ such that $\prob{P}_\alpha^{\RV{D}}\text{swap}_{\rho(D)} s= \prob{P}_{\beta}^{\RV{D}}$. Then  $\prob{P}_\alpha^{\RV{D}_{\rho(\mathbb{N})}} = \prob{P}_{\beta}^{\RV{D}}$ also. For any finite $A\subset \mathbb{N}$
\begin{align}
    \prob{P}_\alpha^{\RV{D}_{\rho(A)}} = \prob{P}_{\beta}^{\RV{D}_A}
\end{align}
so by piecewise replicability
\begin{align}
    \prob{P}_\alpha^{(\RV{D}_i,\RV{Y}_i)_{i\in \rho(A)}} = \prob{P}_{\beta}^{(\RV{D}_i,\RV{Y}_i)_{i\in A}}
\end{align}
Thus by Kolmogorov's extension theorem
\begin{align}
    ^{(\RV{D}_i,\RV{Y}_i)_{i\in \rho(\mathbb{N})}} &= \prob{P}_\alpha^{(\RV{D}_i,\RV{Y}_i)_{i\in \mathbb{N}}}\text{swap}_{\rho(D\times A)}\\
                                         &= \prob{P}_{\beta}^{(\RV{D}_i,\RV{Y}_i)_{i\in \mathbb{N}}}
\end{align}
\end{proof}

Commutativity of exchange does not imply piecewise replicability. Each consequence $\RV{Y}_i$ can depend on a symmetric function of $\RV{D}$ as well as $\RV{D}_i$. For example, suppose $|D|=2$, $D=Y=\{0,1\}$ and we have a do-model $\prob{P}$ such that for all $\alpha\in R$

\begin{align}
    \prob{P}_\alpha^{\RV{Y}_1\RV{Y}_2|\RV{D}_1\RV{D}_2}(y_1,y_2|d_1,d_2) &= \llbracket (y_1,y_2)= (d_1+d_2,d_1+d_2) \rrbracket
\end{align}

Then $\prob{P}_{00}^{\RV{Y}_1}(y_1) = \llbracket y_1=0\rrbracket$ while $\prob{P}_{01}^{\RV{Y}_1} = \llbracket y_1=1 \rrbracket$, so $\prob{P}$ is not piecewise replicable. However, taking $(d_i,d_j)$ to be the decision function that deterministically chooses $(d_i,d_j)$,

\begin{align}
    \prob{P}_{d_2,d_1}^{\RV{Y}_1\RV{Y}_2|\RV{D}_1\RV{D}_2}(y_1,y_2) &= \llbracket (y_1,y_2)= (d_2+d_1,d_2+d_1) \rrbracket\\
    &= \llbracket (y_2,y_1)= (d_1+d_2,d_1+d_2) \rrbracket\\
    &= \prob{P}_{d_1,d_2}^{\RV{Y}_1\RV{Y}_2|\RV{D}_1\RV{D}_2}(y_2,y_1)
\end{align}

so $\prob{P}$ commutes with exchange.

There is a representation theorem for models that commute with exchange which implies that for $\prob{P}$ that commutes with exchange, $\RV{Y}_i\CI_{\prob{P}}(\RV{D}_j,\RV{Y}_j)_{j\in \mathbb{N}}\setminus \{i\}|\RV{H}\RV{D}_i$, where $\RV{H}$ is a symmetric function of $(\RV{Y}_i,\RV{D}_i)_{i\in\mathbb{N}}$.

% \begin{proposition}[Representation of do-models that commute with exchange]
% Suppose we have a fundamental probability set $\Omega$ and a do model $(\prob{P},\RV{D},\RV{Y},R)$ such that $\RV{D}:=(\RV{D}_i)_{i\in \mathbb{N}}$ and $\RV{Y}:=(\RV{Y}_i)_{i\in\mathbb{N}}$ where $\prob{P}$ commutes with exchange and there is some $\alpha^*\in R$ such that $\prob{P}^{\alpha^*}\gg\prob{P}_\beta$ for all $\beta in R$. Then there exists a symmetric function $\RV{H}:(Y\times D)^\mathbb{N}\to H$ such that  $\prob{P}^{\RV{Y}|\RV{DH}}$ exists and $\RV{Y}_i\CI_{\prob{P}}(\RV{D}_j,\RV{Y}_j)_{j\in \mathbb{N}}\setminus \{i\}|\RV{H}\RV{D}_i$, or equivalently 
% \begin{align}
%     \prob{P}^{\RV{Y}} &= \tikzfig{do_model_representation}
% \end{align}
% \end{proposition}

% % \begin{lemma}[Contraction and independence]
% % Let $\RV{J}$, $\RV{K}$ and $\RV{L}$ be variables on $\Omega$ and $\prob{Q}\in \Delta(\Omega)$ a base measure such that $\prob{Q}^{\RV{JK}}=\prob{Q}^{\RV{JL}}$ and $\sigma{K}\subset \sigma{L}$. Then $\RV{J}\CI\RV{L}|\RV{K}$. 
% % \end{lemma}

% % \begin{proof}
% % From Lemma 1.3 in \citet{kallenberg_basic_2005}.
% % \end{proof}

% \begin{proof}
% If $\prob{P}$ commutes with exchange, then for any $\alpha\in R$ such that $\prob{P}_\alpha^{\RV{D}}$ is exchangeable then $\prob{P}_\alpha$ is also exchangeable. Then there exists $\RV{H}$ a symmetric function of $(\RV{Y}_i,\RV{D}_i)_{i\in\mathbb{N}}$ such that $\RV{Y}_i\CI_{\prob{P}}(\RV{D}_j,\RV{Y}_j)_{j\in \mathbb{N}}\setminus \{i\}|\RV{H}\RV{D}_i$. This is De Finetti's representation theorem, and many proofs exists, see for example \citep{kallenberg_basic_2005}.

% In particular, let 

% \begin{align}
%     \RV{H}:=A\times B\mapsto \lim_{n\to\infty} \frac{1}{n}\sum_{i\in n} \mathds{1}_{A\times B}((\RV{Y}_i, \RV{D}_i))
% \end{align}

% Then for all $\alpha\in R$,
% \begin{align}
%     \prob{P}_\alpha^{(\RV{Y}_i,\RV{D}_i)_{i\in\mathbb{N}}|\RV{H}}(A\times B|h) \overset{a.s.}{=} h(A\times B)\label{eq:given_h}
% \end{align}

% The proof that the limit exists and the above equality holds can again be found int \citep{kallenberg_basic_2005}.
% \end{proof}

\begin{definition}[Contractible probability distribution]
Given a fundamental probability set $\Omega$, variable $\RV{X}:=(\RV{X}_i)_{i\in \mathbb{N}}$ and a probability distribution $\prob{P}^{\RV{X}}\in\Delta(X^{\mathbb{N}})$, any $S=(s_i)_{i\in A}$, $T=(t_i)_{i\in A}$ with $A\subset\mathbb{N}$ and $i<j\implies s_i<s_j \land t_i<t_j$, let $\RV{X}_S:=(\RV{X}_i)_{i\in S}$ and $\RV{X}_T:=(\RV{X}_i)_{i\in T}$. If
\begin{align}
    \prob{P}^{\RV{X}_S} &= \prob{P}^{\RV{X}_T}
\end{align}
 $\prob{P}$ is contractible.
\end{definition}

If we have a do model $\prob{P}$ that is causally contractible, we can represent it as an exchangeable probability distribution and a lookup function. This representation is very similar to the representation of causal models used by the potential outcomes literature.

\begin{theorem}[Table representation of causally contractible do models]
Suppose we have a fundamental probability set $\Omega$ and a do model $(\prob{P},\RV{D},\RV{Y},R)$ such that $\RV{D}:=(\RV{D}_i)_{i\in \mathbb{N}}$ and $\RV{Y}:=(\RV{Y}_i)_{i\in\mathbb{N}}$. $\prob{P}$ is piecewise replicable if and only if 
\begin{align}
    \prob{P}^{\RV{Y}|\RV{D}} &= \tikzfig{lookup_representation}
\end{align}
Where $\prob{P}^{\RV{Y}^D}$ is a contractible probability measure on $Y^{D\times\mathbb{N}}$ with respect to the sequence $\RV{Y}^D:=(\RV{Y}_i^D)_{i\in \mathbb{N}}$ and $\prob{L}^{\RV{D},\RV{Y}^D}$ is the Markov kernel associated with the lookup function
\begin{align}
    l:D^\mathbb{N}\times Y^{D\times \mathbb{N}}&\to Y^\mathbb{N}\\
    ((d_i)_\mathbb{N},(y_{jk})_{D\times\mathbb{N}})&\mapsto (y_{d_i i})_\mathbb{N}
\end{align}
\end{theorem}

\begin{proof}
Only if:
Choose $e:=(e_ij)_{i\in D,j\in\mathbb{N}}\in D^{\mathbb{N}}$ such that $e_{ij} = d_i$, and abusing notation write $e$ for the decision function that chooses $e$ deterministically. Note that the rank order of an element $e_{ij}$ of $e$ is given by the rank function $f:(i,j)\mapsto |D|i+j$.

Define
\begin{align}
    \prob{P}^{\RV{Y}^D}((y_{ij})_{D\times \mathbb{N}}):=\prob{P}_e^{\RV{Y}}((y_{ij})_{D\times \mathbb{N}})
\end{align}

Now consider any $d:=(d_j)_{j\in \mathbb{N}}\in D^{\mathbb{N}}$. By definition of $e$, $e_{id_j}=d_j$ for any $i,j\in \mathbb{N}$. Define the lookup function

\begin{align}
    l_{DD}:D^\mathbb{N}\times D^{D\times \mathbb{N}}&\to D^\mathbb{N}\\
    ((d_i)_\mathbb{N},(e_{jk})_{D\times\mathbb{N}})&\mapsto (e_{d_i i})_\mathbb{N}
\end{align}

Thus

\begin{align}
    l_{DD}(d,e) = d
\end{align}

Define

\begin{align}
    \prob{Q}:D\kto Y\\
    \prob{Q}:= \tikzfig{lookup_representation}
\end{align}

and consider some ordered sequence $A\subset \mathbb{N}$ and $B:= ((d_i,i))_{i\in A}$. Note that $B$ is also ordered according to the rank function $f:(i,j)\mapsto |D|i+j$. Then 

\begin{align}
    \sum_{y\in \RV{Y}^{-1}(y_A)} \prob{Q}(y|d) &= \sum_{y\in \RV{Y}^{-1}(y_A)} \sum_{y^{\prime D}\in Y^D} \llbracket l_{DY}(d,y^{\prime D}) = y \rrbracket \prob{P}^{\RV{Y}^{D\times \mathbb{N}}}(y^{\prime D})\\
    &= \sum_{y\in \RV{Y}^{-1}(y_A)} \sum_{y^{\prime D}\in Y^{D\times \mathbb{N}}} \llbracket l_{DY}(d,y^{\prime D}) = y \rrbracket \prob{P}_e^{\RV{Y}}(y^{\prime D})\\
    &= \sum_{y\in \RV{Y}^{-1}(y_A)}\prod_{i\in A}\sum_{y'\in Y} \llbracket y'_{d_i i} = y_i \rrbracket \prob{P}_e^{\RV{Y}_i}(y')\\
    &= \sum_{y\in \RV{Y}^{-1}(y_A)}\prob{P}_e^{\RV{Y}_{B}}(y)\\
    &= \prob{P}_e^{\RV{Y}_{B}}(y_A)\\
    &= \prob{P}_{l_{DD}(d,e)}^{\RV{Y}_A}(y_A)&\text{by piecewise replicability}\\
    &= \prob{P}_d^{\RV{Y}_A}(y_A)
\end{align}

Because this holds for all $A\subset\mathbb{N}$, by the Kolmogorov extension theorem

\begin{align}
    \prob{Q}(y|d) &= \prob{P}_d^{\RV{Y}}(y)
\end{align}

Because $d$ is the decision function that deterministically chooses $d$, for all $d\in D$

\begin{align}
    \prob{Q}(y|d) &= \prob{P}_d^{\RV{Y}|\RV{D}}(y|d)
\end{align}

And because $\prob{P}_d^{\RV{Y}|\RV{D}}(y|d)$ is unique for all $d\in D^{\mathbb{N}}$ and $\prob{P}^{\RV{Y}|\RV{D}}$ exists by assumption

\begin{align}
    \prob{P}^{\RV{Y}|\RV{D}}=\prob{Q}
\end{align}

Next we will show $\prob{P}^{\RV{Y}^D}$ is contractible. Consider any subsequences $\RV{Y}^D_S$ and $\RV{Y}^D_T$ of $\RV{Y}^D$ with $|S|=|T|$. Let $\rho(S)$ be the ``expansion'' of the indices $S$, i.e. $\rho(S)=(|D|i+j)_{i\in S,j\in D}$. Then by construction of $e$, $e_{\rho(S)}=e_{\rho(T)}$ and therefore

\begin{align}
    \prob{P}^{\RV{Y}^D_S}&= \prob{P}_e^{\RV{Y}_{\rho(S)}})\\
    &= \prob{P}_e^{\RV{Y}_{\rho(T)}})&\text{by contractibility of }\prob{P}\text{ and the equality } e_{\rho(S)}=e_{\rho(T)}\\
    &= \prob{P}^{\RV{Y}^D_T}
\end{align}


If:
Suppose 
\begin{align}
    \prob{P}^{\RV{Y}|\RV{D}} &= \tikzfig{lookup_representation}
\end{align}

and consider any two deterministic decision functions $d,d'\in D^{\mathbb{N}}$ such that some subsequences are equal $d_S=d'_T$.

Let $\RV{Y}^{d_S}=(\RV{Y}_{d_i i})_{i\in S}$.

By definition,

\begin{align}
    \prob{P}^{\RV{Y}_S|\RV{D}}(y_S|d) &= \sum_{y^D_S\in Y^{|D|\times |S|}}\prob{P}^{\RV{Y}^D_S}(y^D_S)\prob{L}^{\RV{D}_S,\RV{Y}^S}(y_S|d,y^D_S)\\
    &= \sum_{y^D_S\in Y^{|D|\times |T|}}\prob{P}^{\RV{Y}^D_T}(y^D_S)\prob{L}^{\RV{D}_S,\RV{Y}^S}(y_S|d,y^D_S)&\text{ by contractibility of }\prob{P}^{\RV{Y}^D_T}\\
    &= \prob{P}^{\RV{Y}_T|\RV{D}}(y_S|d)
\end{align}
\end{proof}

Let the elements of $D$ be denoted by $d_i$, $i\in |D|$ and , and set out $\RV{Y}$ in a table as follows:

\begin{center}
\begin{tabular}{ c c c }
 $\RV{Y}_{f(1,1)}$ & $\RV{Y}_{f(1,2)}$ & $\RV{Y}_{f(1,3)}$ \\ 
 $\RV{Y}_{f(2,1)}$ & $\RV{Y}_{f(2,2)}$ & $\RV{Y}_{f(2,3)}$ \\  
 $\RV{Y}_{f(3,1)}$ & $\RV{Y}_{f(3,2)}$ & $\RV{Y}_{f(3,3)}$    
\end{tabular}
\end{center}



\section{Causal Bayesian Networks}\label{sec:CBN}

Like some of the causal modelling frameworks discussed in the previous section, including see-do models, Causal Bayesian Networks (CBNs) represent both ``observations'' and ``consequences of interventions''. It seems reasonable to think that the real-world things that the see-do framework and the CBN framework address are sometimes the same. The question we have here is: if we have a decision problem represented by a see-do model, when can we represent the same problem with a CBN?

In order to answer this question, we have to deal with the fact that neither theory is formally contained by the other, so for example there's no precise way in which decisions correspond to interventions. The correspondence exists in the territory, the world that is inhabited by measurement processes, not the mathematical world that is inhabited by random variables. We therefore have to make some choices about what corresponds to what that seem to be reasonable given our understanding of what these models are used for.

To compare CBNs to see-do models, we will argue that CBNs can be understood as describing probabilistic models of observations and consequences, just like see-do models. Furthermore, CBNs feature an order-1 probability gap and so they describe a probability 2-comb over observations, interventions and consequences. If we suppose that there is some variable describing decisions that does not appear within the CBN, then we can posit a see-do model over observations, decisions and consequences. Finally, we ask: when is the see-do model compatible with the CBN 2-comb, or more precisely, when can we identify each \emph{decision rule} with a \emph{intervention rule} such that the probability model obtained by inserting a decision rule into the see-do model is identical to the probability model obtained by inserting an intervention rule into the CBN 2-comb. We show that see-do models that exhibit a particular type of symmetry are compatible with CBN 2-combs.

\subsection{Probability 2-combs represented by causal Bayesian networks}

Consider a simplified kind of CBN where a single variable may be intervened on. Note that the structure of the previous section -- $\RV{X}\longrightarrowRHD \RV{Y}$ and $\RV{X}\longleftarrowRHD \RV{W} \longrightarrowRHD \RV{Y}$ -- is generically appliccable to such a model if we identify $\RV{W}$ with the variable formed by taking a sequence of all of the ancestors of $\RV{X}$ and $\RV{Y}$ with the variable formed by taking a sequence of all non-ancestors of $\RV{X}$. The existence of an edge from $\RV{X}$ to $\RV{Y}$ in such a case does no harm as if $\RV{Y}$ is not ``actually'' a descendent of $\RV{X}$ then it will be independent conditional on $\RV{Z}$ (see \citet{peters_structural_2015} for a detailed treatment of when two graphs may or may not imply the same underlying model).

We will adopt the definiton discussed in Section \ref{sec:truncated_fac_again}: we take the causal Bayesian network in question to express the assumption that the result of intervention is modeled by some probability 2-comb $\prob{P}^{\RV{W}\square \RV{Y}|\RV{X}}$ and the observations are distributed according to $\text{insert}(\model{P}_{\text{obs}}^{\RV{X}|\RV{Z}},\prob{P}^{\RV{W}\square\RV{Y}|\RV{X}})$ for some $\model{P}_{\text{obs}}^{\RV{X}|\RV{Z}}$.

We are uncertain about the particular 2-comb $\prob{P}^{\RV{W}\square \RV{Y}|\RV{X}}$ that we should use to model interventions, as well as the particular $\model{P}_{\text{obs}}^{\RV{X}|\RV{Z}}$ appropriate for observations, so we will represent this uncertainty with an unobserved variable $\RV{H}$. Furthermore, if we are being precise about what is being modeled, we suppose that we have a sequence of ``observation'' variables $\RV{V}_{[n]}:=(\RV{W}_i,\RV{X}_i,\RV{Y}_i)_{i\in [n]}$ and a sequence of ``consequence'' variables modeled by $\RV{V}_{(n,m]}:=(\RV{W}_i,\RV{X}_i,\RV{Y}_i)_{i\in (n,m]}$ both defined on a fundamental probability set $\Omega$ (assume $n<m$). 

With this additional detail, we interpret Equation \ref{eq:int_to_obs} as saying

\begin{align}
    \model{Q}_{\text{obs}}^{\RV{W_iX_iY_i}|\RV{H}} &= \text{insert}(\model{Q}_{\text{obs}}^{\RV{X}_{j}|\RV{HW}_{j}},\prob{Q}^{\RV{W}_{j}|\RV{H}\square\RV{Y}_{j}|\RV{X}_{j}})
\end{align}

for all $i\in[n]$, $j\in (n,m]$.

Because we are now considering sequences of observations and consequences, we also think it is reasonable to understand a CBN model as coming equipped with assumptions of mutual independence:

\begin{align}
    \RV{V}_i\CI_{\prob{Q}} \RV{V}_{[m]\setminus \{i\}}|\RV{H}&\forall i\in [n]\\
    \RV{W}_i\CI_{\prob{Q}} \RV{V}_{[m]\setminus \{i\}}|\RV{H}&\forall i\in [m]\\
    \RV{Y}_i\CI_{\prob{Q}} \RV{V}_{[m]\setminus \{i\}}|(\RV{H},\RV{X}_i,\RV{W}_i)&\forall i\in [m]\\
\end{align}

The first condition says that the observations $\RV{V}_{[n]}$ are mutually independent, the second that if we ignore the $\RV{X}_i$s and $\RV{Y}_i$s, then the $\RV{W}_i$s are mutually independent for all $[m]$ and the third says that the $\RV{Y}_i$s are independent of the other variables in the sequence conditional on $(\RV{H},\RV{X}_i,\RV{W}_i)$. Note that we exclude $\RV{X}_i$ from these conditional independence assumptions. The reason for this is that we interpret $\RV{X}_i$ as a directly controlled variable and as such it may be chosen to be dependent on other variables in the sequence.

\begin{definition}[Order 2 model associated with the CBN in question]\label{def:cbn_o2}
A CBN order 2 model $\prob{Q}^{\RV{V}_{[n]}\RV{W}_{(n,m]}|\RV{H}\square \RV{Y}_{(n,m]}|\RV{X}_{(n,m]}}$ where $\RV{V}_{i} = (\RV{W}_i,\RV{X}_i,\RV{Y}_i)$ for $i\in [m]$, such that the CBN mutual independences hold:
\begin{align}
    \RV{V}_i\CI_{\prob{Q}} \RV{V}_{[m]\setminus \{i\}}|\RV{H}&\forall i\in [n]\label{eq:cbn_ci1}\\
    \RV{W}_i\CI_{\prob{Q}} \RV{V}_{[m]\setminus \{i\}}|\RV{H}&\forall i\in [m]\label{eq:cbn_ci2}\\
    \RV{Y}_i\CI_{\prob{Q}} \RV{V}_{[m]\setminus \{i\}}|(\RV{H,X}_i,\RV{W}_i)&\forall i\in [m]\label{eq:cbn_ci3}\\
\end{align}
Under these assumptions $\prob{Q}^{\RV{W}_i|\RV{H}}$ and $\prob{Q}^{\RV{Y}_i|\RV{H}\RV{X}_i\RV{W}_i}$ exist, and for all $i\in [n],j,k\in [m]$
\begin{align}
    \model{Q}^{\RV{W}_{j}|\RV{H}\square\RV{Y}_{j}|\RV{X}_{j}}&=\model{Q}^{\RV{W}_{k}|\RV{H}\square\RV{Y}_{k}|\RV{X}_{k}}\label{eq:identically_distributed}\\
    \model{Q}^{\RV{W_iX_iY_i}|\RV{H}} &= \text{insert}(\model{Q}_{\text{obs}}^{\RV{X}_{j}|\RV{HW}_{j}},\prob{Q}^{\RV{W}_{j}|\RV{H}\square\RV{Y}_{j}|\RV{X}_{j}})\label{eq:cbn_insert}
\end{align}
for all $i\in[n]$, $j\in (n,m]$.
\end{definition}


\begin{theorem}[Existence of CBN 2-comb]\label{th:cbn_2comb_exist}
Given a CBN order 2 model $\prob{Q}^{\RV{V}_{[n]}\RV{W}_{(n,m]}|\RV{H}\square \RV{Y}_{(n,m]}|\RV{X}_{(n,m]}}$ in accordance with Definition \ref{def:cbn_o2}, there exist conditional probabilities $\prob{Q}^{\RV{W}_i|\RV{H}}$ and $\prob{Q}^{\RV{Y}_i|\RV{H}\RV{X}_i\RV{W}_i}$ for all $i$.
\end{theorem}

\begin{proof}
Order 2 models $\prob{Q}^{\RV{V}_{[n]}\RV{W}_{(n,m]}|\RV{H}\square \RV{Y}_{(n,m]}|\RV{X}_{(n,m]}}$ have the following conditional probabilities:
\begin{align}
   & \prob{Q}^{\RV{V}_{[n]}\RV{W}_{(n,m])}|\RV{H}}&\text{exists}\label{eq:obs_cbn_existence}\\
   & \prob{Q}^{\RV{Y}_{(n,m]}|\RV{X}_{(n,m]}\RV{W}_{(n,m]}\RV{V}_{[n]}\RV{H}}&\text{exists}\label{eq:int_cbn_existence}
\end{align}

Equations \ref{eq:obs_cbn_existence} and \ref{eq:int_cbn_existence} together with conditional independences \ref{eq:cbn_ci1}, \ref{eq:cbn_ci2}, \ref{eq:cbn_ci3} and Theorem \ref{th:cons_ci} imply there exist versions of the following conditional proabilities such that

\begin{align}
    \prob{Q}^{\RV{V}_i|\RV{H}\RV{V}_{[m]\setminus\{i\}}}&=\prob{Q}^{\RV{V}_i|\RV{H}}\otimes \text{erase}_{V^{m-1}} & \forall i\in[n]\\
    \prob{Q}^{\RV{W}_i|\RV{H}\RV{V}_{[m]\setminus\{i\}}}&=\prob{Q}^{\RV{W}_i|\RV{H}}\otimes \text{erase}_{V^{m-1}} & \forall i\in[m]\\
    \prob{Q}^{\RV{Y}_i|\RV{H}\RV{X}_i\RV{W}_i\RV{V}_{[m]\setminus\{i\}}}&= \prob{Q}^{\RV{Y}_i|\RV{H}\RV{X}_i\RV{W}_i}\otimes \text{erase}_{V^{m-1}} & \forall i\in [m]
\end{align}
\end{proof}

Note also that Equation \ref{eq:identically_distributed} implies that the conditional probabilities from Theorem \ref{th:cbn_2comb_exist} can be chosen to be equal for all $i,j\in [m]$:
\begin{align}
    \prob{Q}^{\RV{W}_i|\RV{H}} = \prob{Q}^{\RV{W}_j|\RV{H}}\label{eq:identical_1}\\
    \model{Q}^{\RV{Y}_i|\RV{X}_i\RV{W}_i\RV{H}} &= \model{Q}^{\RV{Y}_j|\RV{X}_j\RV{W}_j\RV{H}}\label{eq:identical_2}
\end{align}

\begin{theorem}[CBN observations are identically distributed]
Given a CBN order 2 model $\prob{Q}^{\RV{V}_{[n]}\RV{W}_{(n,m]}|\RV{H}\square \RV{Y}_{(n,m]}|\RV{X}_{(n,m]}}$ in accordance with Definition \ref{def:cbn_o2}, there exists $\prob{Q}^{\RV{V}_{i}|\RV{H}}$ for $i\in [n]$ and for all $i,j\in [n]$
\begin{align}
    \prob{Q}^{\RV{V}_i|\RV{H}} = \prob{Q}^{\RV{V}_j|\RV{H}}\label{eq:identical_3}
\end{align}
\end{theorem}

\begin{proof}
Existence follows from the fact that $\RV{V}_i=\pi_i\circ\RV{V}_{[n]}$ with $\pi_i$ the function $V^n\to V$ that projects the $i$th index. Theorem \ref{th:recurs_pushf} then implies $\prob{Q}^{\RV{V}_i|\RV{H}}=\prob{Q}^{\RV{V}_{[n]}|\RV{H}}\kernel{F}_{\pi_i}$.

Equality follows from the fact that for all $i,j\in[n]$
\begin{align}
    \model{Q}^{\RV{V}_i|\RV{H}} &= \text{insert}(\model{Q}_{\text{obs}}^{\RV{X}_{j}|\RV{HW}_{j}},\prob{Q}^{\RV{W}_{j}|\RV{H}\square\RV{Y}_{j}|\RV{X}_{j}})\\
    &= \model{Q}^{\RV{V}_j|\RV{H}}
\end{align}
\end{proof}

\subsection{See-do models corresponding to causal Bayesian networks}

We have defined a class of order 2 probability gap models associated with causal Bayesian networks. We next want to ask: when does a see-do model induce an order 2 model associated with a CBN? Specificially, given a see-do model $\prob{T}^{\RV{V}_{[n]}|\RV{H}\square \RV{V}_{(n,m]}|\RV{D}}$ with decision rules of type $\{\prob{T}_\alpha^{\RV{D}|\RV{V}_{[n]}}\}_{\alpha\in A}$, when is there a CBN model $\prob{Q}^{\RV{V}_{[n]}\RV{W}_{(n,m]}|\RV{H}\square \RV{Y}_{(n,m]}|\RV{X}_{(n,m]}}$ with inserts of type $\{\prob{Q}_\alpha^{\RV{X}_{(n,m]}|\RV{V}_{[n]}\RV{W}_{(n,m]}\RV{H}}\}_{\alpha\in A}$ such that marginalising $\prob{T}_\alpha$ over $\RV{D}$ yields $\prob{Q}_\alpha$ for all $\alpha\in A$?

\begin{align}
    \model{T}^{\RV{V}_{[m]}|\RV{H}}_\alpha&=\tikzfig{seedo_equality2}\\
    &=\tikzfig{seedo_equality} \label{eq:consistent}\\
    &= \model{Q}^{\RV{V}_{[m]}|\RV{H}}_\alpha
\end{align}

We need a number of conditions to hold for this to be true of any $\prob{T}$; first, $\prob{T}$ needs to satisfy the CBN versions of ``mutually independent'' (Eqs. \ref{eq:cbn_ci1}-\ref{eq:cbn_ci3}) as well as the CBN version of ``identically distributed'' (Eqs. \ref{eq:identical_1}, \ref{eq:identical_2} and \ref{eq:identical_3}). Finally, we require decisions $\RV{D}$ to act as ``interventions'' on $\RV{X}$ in an appropriate way.

Theorem \ref{th:seedo_rep} shows that this correspondence holds exactly when:
\begin{itemize}
    \item The CBN mutual indpendences (Definition \ref{def:cbn_o2}) hold for the $\prob{T}$
    \item For all $i\in (n,m]$, $\RV{W}_i\CI_{\prob{T}}\RV{D}|\RV{H}$
    \item For all $i\in [m]$, $\RV{Y}_i\CI_{\prob{T}}\RV{D}|(\RV{W}_i,\RV{X}_i,\RV{H})$; we say that under conditions of perfect information, $(\RV{W}_i,\RV{X}_i)$ control $\RV{Y}_i$ by proxy
\end{itemize}

\begin{theorem}\label{th:seedo_rep}
Given a see-do model $\prob{T}^{\RV{V}_{[n]}|\RV{H}\square \RV{V}_{(n,m]}|\RV{D}}$ there exists a corresponding CBN probability 2-comb $\prob{Q}^{\RV{V}_{[n]}\RV{W}_{(n,m]}|\RV{H}\square \RV{Y}_{(n,m]}|\RV{X}_{(n,m]}}$ if and only if (1) the CBN mutual independences hold
\begin{align}
    \RV{V}_i\CI_{\prob{T}} \RV{V}_{[m]\setminus \{i\}}|\RV{H}&\forall i\in [n]\\
    \RV{W}_i\CI_{\prob{T}} \RV{V}_{[m]\setminus \{i\}}|\RV{H}&\forall i\in [m]\\
    \RV{Y}_i\CI_{\prob{T}} \RV{V}_{[m]\setminus \{i\}}|\RV{HX}_i&\forall i\in [m]\\
\end{align}
(2) for every insert $\alpha$ the following conditional probabilities are identical
\begin{align}
    \prob{T}_\alpha^{\RV{V}_i|\RV{H}} &= \prob{T}_\alpha^{\RV{V}_j|\RV{H}}&\forall i,j\in [n]\\
    \prob{T}_\alpha^{\RV{W}_i|\RV{H}} &= \prob{T}_\alpha^{\RV{W}_j|\RV{H}}&\forall i,j\in [m]\\
    \model{T}_\alpha^{\RV{Y}_i|\RV{X}_i\RV{W}_i\RV{H}} &= \model{T}_\alpha^{\RV{Y}_j|\RV{X}_j\RV{W}_j\RV{H}}&\forall i,j\in [m]
\end{align}
(3) $\RV{W}_i$ is unaffected by $\RV{D}$
\begin{align}
    \RV{W}_i\CI_{\prob{D}}
\end{align}
And (4) under conditions of perfect information, $(\RV{W}_i,\RV{X}_i,\RV{V}_{[n]})$ control $\RV{Y}_i$ by proxy:
\begin{align}
    \RV{Y}_i\CI_{\prob{T}}\RV{D}|(\RV{W}_i,\RV{X}_i,\RV{H},\RV{V}_{[n]})&\forall i\in [m]
\end{align}
\end{theorem}

\begin{proof}
\textbf{If:}
If all assumptions hold, we can write
\begin{align}
    \model{T}^{\RV{V}_{[n]}\RV{V}_j|\RV{HD}} = \tikzfig{t_vs_u}
\end{align}
For each $\model{S}_\alpha^{\RV{D}|\RV{V}_{[n]}}$, define
\begin{align}
    \model{R}_\alpha^{\RV{X}_j|\RV{V}_{[n]}\RV{W}_j\RV{H}}:= \tikzfig{defn_ra}
\end{align}
Then
\begin{align}
    &\tikzfig{seedo_equality2}\\
    &= \tikzfig{seedo_cbn_with_s}\\
    &= \tikzfig{seedo_equality}
\end{align}
\textbf{Only if:}
Suppose the CBN mutual independences do not hold for $\prob{T}$. Then there must be some $\alpha$ such that one of these conditional independences does not hold for $\prob{T}_\alpha$. By construction of CBN order 2 models, these indepenences hold for every probability model in the range of every CBN order 2 model $\prob{Q}$. Thus there is no CBN model corresponding to $\prob{T}$.

Suppose for some $\alpha$ and $i,j\in [n]$ we have $\prob{T}_\alpha^{\RV{V}_i|\RV{H}} \neq \prob{T}_\alpha^{\RV{V}_j|\RV{H}}$. 

Suppose the assumption of proxy control does not hold for $\prob{T}$. Then there is some $d,d'\in D$, $w\in W$, $h\in H$, $v\in V^{n}$, $x\in X$ and $y\in Y$ such that
\begin{align}
    \model{T}^{\RV{Y}_j|\RV{W}_j\RV{V}_{[n]}\RV{HX}_j\RV{D}}(y|w,v,h,x,d) &\neq \model{T}^{\RV{Y}_j|\RV{W}_j\RV{V}_{[n]}\RV{HX}_j\RV{D}}(y|w,v,h,x,d')\label{eq:not_indep}\\
    &\text{and }\model{T}_\alpha^{\RV{X}_j\RV{W}_j\RV{V}_{[n]}|\RV{HD}}(x,w,v|h,d) >0\\
    &\text{and }\model{T}_\alpha^{\RV{X}_j\RV{W}_j\RV{V}_{[n]}|\RV{HD}}(x,w,v|h,d') >0\\
\end{align}

If Equation \ref{eq:not_indep} only held on sets of measure 0 then we could choose versions of the conditional probabilities such that the independence held.

Then
\begin{align}
    \model{T}_d^{\RV{Y}_j|\RV{W}_j\RV{V}_{[n]}\RV{HX}_j}(y|w,v,h,x)&= \model{T}^{\RV{Y}_j|\RV{W}_j\RV{V}_{[n]}\RV{HX}_j\RV{D}}(y|w,v,h,x,d)\\
    &\neq \model{T}^{\RV{Y}_j|\RV{W}_j\RV{V}_{[n]}\RV{HX}_j\RV{D}}(y|w,v,h,x,d')\\
    &= \model{T}_{d'}^{\RV{Y}_j|\RV{W}_j\RV{V}_{[n]}\RV{HX}_j}(y|w,v,h,x)\\
    \implies \model{T}_d^{\RV{Y}_j|\RV{W}_j\RV{V}_{[n]}\RV{HX}_j\RV{D}}(y|w,v,h,x) &\neq \model{Q}_d^{\RV{Y}_j|\RV{W}_j\RV{V}_{[n]}\RV{HX}_j\RV{D}}(y|w,v,h,x)\\
    \text{or } \model{T}_{d'}^{\RV{Y}_j|\RV{W}_j\RV{V}_{[n]}\RV{HX}_j\RV{D}}(y|w,v,h,x) &\neq \model{Q}_{d'}^{\RV{Y}_j|\RV{W}_j\RV{V}_{[n]}\RV{HX}_j\RV{D}}(y|w,v,h,x)
\end{align}
As the conditional probabilities disagree on a positive measure set, $\model{P}\neq\model{Q}$.

Suppose assumption 3 holds but assumption 4 does not. Then for some $h\in H$, some $w\in W$, $v\in V^{|A|}$, $x\in X$ with positive measure and some $y\in Y$
\begin{align}
    \model{P}_d^{\RV{Y}_j|\RV{W}_j\RV{V}_{[n]}\RV{HX}_j\RV{D}}(y|w,v,h,x)&= \model{T}^{\RV{Y}_j|\RV{W}_j\RV{V}_{[n]}\RV{HX}_j}(y|w,v,h,x)\\
    &\neq \model{U}^{\RV{Y}_j|\RV{W}_j\RV{V}_{[n]}\RV{HX}_j}(y|w,v,h,x)\\
    &\neq model{Q}_d^{\RV{Y}_j|\RV{W}_j\RV{V}_{[n]}\RV{HX}_j\RV{D}}(y|w,v,h,x)
\end{align}
\end{proof}

Conditional independences like $(\RV{V}_{[n]},\RV{W}_j)\CI_{\model{T}} \RV{D}|\RV{H}$ and $\RV{Y}_j\CI_{\model{T}}\RV{D}|\RV{W}_j\RV{V}_{[n]}\RV{HX}_j$ bear some resemblance to the condition of ``limited unresponsiveness'' proposed by \citet{heckerman_decision-theoretic_1995}. They are conceptually similar in that they indicate that a particular variable does not ``depend on'' a decision $\RV{D}$ in some sense. As Heckerman points out, however, limited unresponsiveness is not equivalent to conditional independence. We tentatively speculate that there may be a relation between our ``pre-choice variables'' $(\RV{W}_j,\RV{V}_{[n]},\RV{H})$ and the ``state'' in Heckerman's work crucial for defining limited unresponsiveness.

\subsection{Proxy control}

We say that $(\RV{V}_{[n]},\RV{W}_j)\CI_{\model{T}} \RV{D}|\RV{H}$ expresses the notion that $\RV{W}_j$ is a \emph{pre-choice variable} and $(\RV{W}_j,\RV{V}_{[n]},\RV{X}_j)$ are \emph{proxies for }$\RV{D}$ with respect to $\RV{Y}$ under conditions of full information. To justify this terminology, we note that under a strong assumption of identifiability $\RV{Y}_j\CI\RV{H}|\RV{W}_j\RV{V}_{[n]}\RV{X}_j$ (i.e. the observed data allow us to identify $\RV{H}$ for the purposes of determining $\RV{T}^{\RV{Y}_j|\RV{W}_j\RV{V}_{[n]}\RV{X}_j\RV{H}}$), then we can write
\begin{align}
    \model{T}^{\RV{V}_{[n]}\RV{V}_{(n,m]}|\RV{H}\RV{D}} &=\tikzfig{strong_identifiability}\\
                                              &=\tikzfig{strong_identifiability2}
                                              &= \model{T}^{\RV{V}_{[n]}\RV{W}_j\RV{X}_j|\RV{H}\RV{D}}\kernel{M}
\end{align}

That is, under conditions of full information, knowing how to control the proxies $(\RV{W}_j,\RV{V}_{[n]},\RV{X}_j)$ is sufficient to control $\RV{Y}$. This echoes \citet{pearl_does_2018}'s view on causal effects representing ``stable characteristics'':
\begin{quote}
Smoking cannot be stopped by any legal or educational means available to us today; cigarette advertising can. That does not stop researchers from aiming to estimate ``the effect of smoking on cancer,'' and doing so from experiments in which they vary the instrument—cigarette advertisement—not smoking. The reason they would be interested in the atomic intervention $P(\text{cancer}|do(\text{smoking}))$ rather than (or in addition to) $P(\text{cancer}|do(\text{advertising}))$ is that the former represents a stable biological characteristic of the population, uncontaminated by social factors that affect susceptibility to advertisement, thus rendering it transportable across cultures and environments. With the help of this stable characteristic, one can assess the effects of a wide variety of practical policies, each employing a different smoking-reduction instrument.
\end{quote}