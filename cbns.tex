%!TEX root = main.tex

\section{Repeatable experiments}

While there are types of measurement processes we could consider, statistical inference usually proceeds from repeatable measurement processes. A common precise notion of repeatability is the assumption of \emph{exchangeability}. The term ``exchangeability'', like the term random variable, is used to refer to assumptions about \emph{measurement processes} as well as properties of \emph{probability models}. If I say a measurement process $\proc{S}$ taking values in $S^n$ is exchangeable, I might mean:
\begin{itemize}
    \item I believe that there is some probabilistic model $(\prob{P},\Omega,\sigalg{F})$ and random variable $\RV{S}$ appropriate for modelling $\proc{S}$ and
    \begin{enumerate}
        \item The same model is appropriate for any measurement process that first peforms $\proc{S}$ and subsequently shuffles the results according to any permutation $\text{swap}_a:S^n\to S^n$ or
        \item The same model is appropriate for any measurement process related to $\proc{S}$ by interchanging experimental units or subjects in the real world
    \end{enumerate} 
\end{itemize}

On the other hand, if I say a probability model $(\prob{P},S^{|A|},\sigalg{S}^{|A|})$ is exchangeable, I mean

\begin{itemize}
    \item For any finite permutation $\text{swap}_A:S^{|A|}\kto S^{|A|}$, $\prob{P}^{\RV{S}}\text{swap}_{a} = \prob{P}^{\RV{S}}$
\end{itemize}

If I believe a measurement process is exchangeable in the first sense, then this implies that the same probability model is appropriate to model $\proc{S}$ as to model $\text{swap}_a\circ \proc{S}$, which implies that $\prob{P}^{\RV{S}}$ should be an exchangeable probability model. Measurement process exchangeability in the second sense requires us to make explicit the mathematical implications of ``interchanging experimental units'', as our semantics of random variables do not say anything about swapping things in the real world. However, the second kind of measurement process exchangeability is more interesting in the context of causal modelling. When we are \emph{acting} on the world, our future actions will often depend on what we have observed in the past, which will often rule out exchangeability in the first sense. Furthermore, our actions have consequences and so permuting the \emph{labels} associated with actions while not actually changing the actions we take is not a particularly interesting operation. Rather, we are interested in how a model might or might not change if we swap the \emph{actual actions} we take. Swapping experimental units while holding actions constant is one way to achieve this, as it changes the identity of which unit receives which action. See \citet{dawid_decision-theoretic_2020} and \citet{greenland_identifiability_1986} for further discussions of exchangeability in the context of causal modelling, and note that both authors consider exchanging to be an operation that alters which person receives which treatment.

De Finetti's well-known representation theorem shows that exchangeable probability models feature a ``hypothesis'' $\RV{H}$ such that the sequence $\RV{S}$ is independent and identically distributed conditional on $\RV{H}$. That is: a measurement process that is exchangeable in the first sense should be modelled by a conditionally indpendent and identically distributed sequence of random variables. The question we want to address here is whether measurement processes that are exchangeable in the second sense imply causal models with particular structure. The answer is yes, although as we discuss the key assumption is \emph{causal contractibility} rather than exchangeability.

In this section, we will at first consider \emph{blind} decision functions -- that is, decision functions that pay no attention to the data already available. We are interested in repetitive symmetries, and these symmetries are typically broken if our decisions are based on past observations. Furthermore, we can define the entire see-do model by its behaviour on blind decision functions. We also assume that the hypotheses are trivial $\RV{H}=*$; once the decision is chosen, we are left with a single probability model. This also substantially simplifies the arguments to be made.

We will consider two different notions of ``repeatable experiments''. Both require a sequence of ``decisions'' to be made and a sequence of consequences, and we assume that each decision corresponds to a single consequence. One could think about these paired sqeuences as a series of experiments each with different setting choices available; the decisions are the setting choices and the consequences are the results of each experiment. The first notion we consider will be \emph{commutativity of exchange} -- we consider the same model appropriate if we alter our experiment by swapping the experimental settings, or if we make analogous swaps to the experimental results. This assumption could be considered a version of the assumption that experimental units can be interchanged. Consider an experiment involving handing out money or not to person A or person B. Commutativity of exchange says that we should use the same probability model to represent the following two predictions: 
\begin{itemize}
    \item Applying choice 1 to A and choice 2 to B and predicting the vector (consequences for A, consequences for B)
    \item Applying choice 2 to A and choice 1 to B and predicting the vector (consequences for B, consequences for A)
\end{itemize}

Under the assumption of commutativity of exchange, consequences of decisions for one ``experimental unit'' may still depend on decisions made for other ``experimental units''. Consider again the experiment above, except instead of two people we are considering giving money to everyone in a particular country. Supposing we don't otherwise know much about the people we are giving money to, it might be reasonable to posit that a model of the consequences should observe commutativity of exchange. However, giving money to A as well as everyone else will have different consequences for A than giving money to A and no-one else; in the former case, we will create more inflation than in the latter.

The second notion of ``repeatable experiments'' is \emph{causal contractibility}, a strictly stronger assumption than commutativity of exchange. Causal contractibility is the assumption that, given two different sequences of decisions, the marginal model of consequences corresponding to matching subsequences of decisions will be equal. A causally contractibly model says that, if I make the same choice for any subcollection of experiments, I expect the same results from those experiments regardless of whatever choices I make elsewhere.


% Another way to see where we are going is to consider graphical statements of our and De Finetti's result.

% Take $S=\{0,1\}$ and identify the space $\Delta(S)$ of probability measures on $S$ with the interval $[0,1]$. De Finetti showed that any infinite exchangeable probability measure $\prob{P}_\alpha$ on $\{0,1\}^\mathbb{N}$ can be represented by a prior $\prob{P}_\alpha^{\RV{H}}\in [0,1]$ for some $\RV{H}:\Omega\to H$ and a conditional probability $\prob{P}^{\RV{S}_0|\RV{H}}:[0,1]\kto \{0,1\}$ such that

% \begin{align}
%     \prob{P}_\alpha &= \tikzfig{de_finetti_rep0}\label{eq:definettirep}
% \end{align}

% Here $\prob{P}^{\RV{S}_0|\RV{H}}$ can be defined concretely by $\prob{P}^{\RV{S}_0|\RV{H}}(1|h)=h$. Equivalently, the probability gap model on $S^\mathbb{N}$ defined by the assumption of exchangeability is equivalent to the probability gap model defined by the conditional probability

% \begin{align}
%     \prob{P}^{\RV{S}|\RV{H}} = \tikzfig{de_finetti_conditional}
% \end{align}

% That is, there is some hypothesis $\RV{H}$ and conditional on $\RV{H}$ the measurements are independent and identically distributed. The proof of this is constructive -- $\RV{H}$ is a function of $\RV{S}$.



% \begin{align}
%     \prob{P}^{\RV{Y}|\RV{HD}} = \tikzfig{do_model_representation}
% \end{align}

% We will further argue that the class of see-do models considered in CBN and potential outcomes literature is equivalent to the family of causally contractible and exchangeable do-models where the decision rule for the first $n$ places is fixed to an unknown value, and may be freely chosen thereafter.

\subsection{Assumptions of repeatability applicable to models of decisions and consequences}

In this section we formalise the notion of commutativity of exchange and causal contractibility. We will then go on to prove two representation theorems for causally contractible models -- firstly, that they can be represented with a tabular probability model and a lookup function, a construction that is very similar to the kinds of causal models employed by the potential outcomes framework (although they do not necessarily share the semantics of potential outcomes). Secondly, we will show that contractible causal models can also be represented by jointly independent repetitions of a ``unit-level consequence map'', indexed by a hypothesis $\RV{H}$.

To begin with, we will define do models, which are see-do models with nothing to see.

\begin{definition}[Do model]\label{def:domodel}
A \emph{do model} is an infinite sequential probability gap model $(\prob{P}_{\square}^{\RV{Y}\|\RV{D}},R)$ where $R$ is a subset of the \emph{blind} decision functions: for all $n$, $\prob{P}_\alpha^{\RV{D}_{[n]}\|\RV{Y}_{[n-1]}}=\text{erase}_{Y^{n-1}}\otimes \prob{P}_\alpha^{\RV{D}_{[n]}}$ for some $\prob{P}_\alpha^{\RV{D}_{[n]}}\in\Delta(D^n)$. That is, we don't permit any decision $\RV{D}_i$ to depend on prior observations $\RV{Y}_i$s.
\end{definition}

Do models are useful because the $n-comb$ $\prob{P}_{\square}^{\RV{Y}_{[n]}\|\RV{D}_{[n]}}$ is also the conditional $\prob{P}_{\square}^{\RV{Y}|\RV{D}}$ (which otherwise may not exist).

\begin{theorem}[Existence of conditional in do models]
Given a do model $(\prob{P}_{\square}^{\RV{Y}\|\RV{D}},R)$, for all $\alpha\in R$, $n\in\mathbb{N}$
\begin{align}
    \prob{P}_\alpha^{\RV{Y}_{[n]}\RV{D}_i} = \prob{P}_\alpha^{\RV{D}_{[n]}}\odot \prob{P}_\square^{\RV{Y}_{[n]}\|\RV{D}_{[n]}}
\end{align}
That is, $\prob{P}_\square^{\RV{Y}_{[n]}\|\RV{D}_{[n]}}\cong \prob{P}_\square^{\RV{Y}_{[n]}|\RV{D}_{[n]}}$
\end{theorem}

\begin{proof}
For any $n>1\in \mathbb{N}$, $\alpha\in R$

\begin{align}
    \prob{P}_\alpha^{\RV{Y}_{[n]}\RV{D}_{[n]}} &= \tikzfig{do_model_1}\\
    &= \tikzfig{do_model_2}\\
    &= \tikzfig{do_model_3}\\
    &= \tikzfig{do_model_4}\\
    \implies \prob{P}_\alpha^{\RV{Y}_{[n]}|\RV{D}_{[n]}} &= \tikzfig{do_model_5}\\
    &= \prob{P}_\alpha^{\RV{Y}_{[n-1]}|\RV{D}_{[n-1]}}\combprod \prob{P}_\square^{\RV{Y}_n|\RV{Y}_{[n-1]}\RV{D}_n}
\end{align}

Applying this recursively with $\prob{P}_\alpha^{\RV{Y}_{[1]}|\RV{D}_{[1]}}=\prob{P}_\square^{\RV{Y}_{[1]}|\RV{D}_{[1]}}$ yields

\begin{align}
    \prob{P}_\alpha^{\RV{Y}_{[n]}|\RV{D}_{[n]}} = \prob{P}_\square^{\RV{Y}_{[n]}\|\RV{D}_{[n]}}
\end{align}
as desired.
\end{proof}

A do model ``commutes with exchange'' if exchanging decisions or exchanging consequences yields the same model for any finite permuation. The term \emph{commute} comes from the notion that we can apply the exchange before the conditional $\prob{P}_{\square}^{\RV{Y}|\RV{D}}$ or after it and get the same result.

\begin{definition}[Commutativity of exchange]\label{def:caus_exch}
Suppose we have a fundamental probability set $\Omega$ and a do model $(\prob{P}_{\square}^{\RV{Y}|\RV{D}},R)$ such that $\RV{D}:=(\RV{D}_i)_{i\in \mathbb{N}}$ and $\RV{Y}:=(\RV{Y}_i)_{i\in\mathbb{N}}$. For a finite permutation $\rho:\mathbb{N}\to\mathbb{N}$, define $\text{swap}_{\rho(D)}:D\kto D$ by $(d_i)_{i\in\mathbb{N}}\mapsto \delta_{(d_{\rho(i)})_{i\in\mathbb{N}}}$ and $\text{swap}_{\rho(D\times Y)}:D\times Y\kto D\times Y$ by $(x_i)_{i\in\mathbb{N}}\mapsto \delta_{(x_{\rho(i)})_{i\in\mathbb{N}}}$. If, for any two decision rules $\alpha,\beta \in R$,
\begin{align}
    \prob{P}_\alpha^{\RV{D}}\text{swap}_{\rho(D)} &= \prob{P}_{\beta}^{\RV{D}}\\
    \implies  \prob{P}_\alpha\text{swap}_{\rho(D\times Y)}&=\prob{P}_\beta
\end{align}
Then $\prob{P}$ \emph{commutes with exchanges}.
\end{definition}

A do model is causally contractible if it gives identical results for any identical subsequences of two decisions when we limit our attention to the corresponding subsequences of consequences. For example, if we have $\RV{D}=(\RV{D}_1,\RV{D}_2,\RV{D}_3)$ and $\RV{Y}=(\RV{Y}_1,\RV{Y}_2,\RV{Y}_3)$ and $\prob{P}_\alpha^{\RV{D}_1\RV{D}_3}=\prob{P}_\beta^{\RV{D}_3\RV{D}_2}$ then $\prob{P}_{\alpha}^{\RV{Y}_1\RV{Y}_3}=\prob{P}_\beta^{\RV{Y}_3\RV{Y}_2}$.

\begin{definition}[Causal contractibility]\label{def:caus_cont}
Suppose we have a fundamental probability set $\Omega$ and a do model $(\prob{P},\RV{D},\RV{Y},R)$ such that $\RV{D}:=(\RV{D}_i)_{i\in \mathbb{N}}$ and $\RV{Y}:=(\RV{Y}_i)_{i\in\mathbb{N}}$. For any $A=(s_i)_{i\in A}$, $T=(t_i)_{i\in A}$, $A\subset\mathbb{N}$ and $i<j\implies p_i<p_j \And q_i<q_j$, let $\RV{D}_S:=(\RV{D}_i)_{i\in S}$ and $\RV{D}_T:=(\RV{D}_i)_{i\in T}$. If for any $\alpha,\beta\in R$
\begin{align}
    \prob{P}_\alpha^{\RV{D}_{S}}=\prob{P}_\beta^{\RV{D}_{T}}\implies \prob{P}_\alpha^{(\RV{D_i,Y_i})_{i\in S}}=\prob{P}_\beta^{(\RV{D_i,Y_i})_{i\in T}}
\end{align}
then $\prob{P}$ is \emph{causally contractible}.
\end{definition}

Commutativity of exchange does not imply causal contractibility. For example, suppose $|D|=2$, $D=Y=\{0,1\}$ and we have a do-model $\prob{P}$ such that for all $\alpha\in R$

\begin{align}
    \prob{P}_\alpha^{\RV{Y}_1\RV{Y}_2|\RV{D}_1\RV{D}_2}(y_1,y_2|d_1,d_2) &= \llbracket (y_1,y_2)= (d_1+d_2,d_1+d_2) \rrbracket
\end{align}

Then $\prob{P}_{00}^{\RV{Y}_1}(y_1) = \llbracket y_1=0\rrbracket$ while $\prob{P}_{01}^{\RV{Y}_1} = \llbracket y_1=1 \rrbracket$, so $\prob{P}$ is not piecewise replicable. However, taking $(d_i,d_j)$ to be the decision function that deterministically chooses $(d_i,d_j)$,

\begin{align}
    \prob{P}_{d_2,d_1}^{\RV{Y}_1\RV{Y}_2|\RV{D}_1\RV{D}_2}(y_1,y_2) &= \llbracket (y_1,y_2)= (d_2+d_1,d_2+d_1) \rrbracket\\
    &= \llbracket (y_2,y_1)= (d_1+d_2,d_1+d_2) \rrbracket\\
    &= \prob{P}_{d_1,d_2}^{\RV{Y}_1\RV{Y}_2|\RV{D}_1\RV{D}_2}(y_2,y_1)
\end{align}

so $\prob{P}$ commutes with exchange.

There is a representation theorem for models that commute with exchange which implies that for $\prob{P}$ that commutes with exchange, $\RV{Y}_i\CI_{\prob{P}}(\RV{D}_j,\RV{Y}_j)_{j\in \mathbb{N}}\setminus \{i\}|\RV{H}\RV{D}_i$, where $\RV{H}$ is a symmetric function of $(\RV{Y}_i,\RV{D}_i)_{i\in\mathbb{N}}$.

% \begin{proposition}[Representation of do-models that commute with exchange]
% Suppose we have a fundamental probability set $\Omega$ and a do model $(\prob{P},\RV{D},\RV{Y},R)$ such that $\RV{D}:=(\RV{D}_i)_{i\in \mathbb{N}}$ and $\RV{Y}:=(\RV{Y}_i)_{i\in\mathbb{N}}$ where $\prob{P}$ commutes with exchange and there is some $\alpha^*\in R$ such that $\prob{P}^{\alpha^*}\gg\prob{P}_\beta$ for all $\beta in R$. Then there exists a symmetric function $\RV{H}:(Y\times D)^\mathbb{N}\to H$ such that  $\prob{P}^{\RV{Y}|\RV{DH}}$ exists and $\RV{Y}_i\CI_{\prob{P}}(\RV{D}_j,\RV{Y}_j)_{j\in \mathbb{N}}\setminus \{i\}|\RV{H}\RV{D}_i$, or equivalently 
% \begin{align}
%     \prob{P}^{\RV{Y}} &= \tikzfig{do_model_representation}
% \end{align}
% \end{proposition}

% % \begin{lemma}[Contraction and independence]
% % Let $\RV{J}$, $\RV{K}$ and $\RV{L}$ be variables on $\Omega$ and $\prob{Q}\in \Delta(\Omega)$ a base measure such that $\prob{Q}^{\RV{JK}}=\prob{Q}^{\RV{JL}}$ and $\sigma{K}\subset \sigma{L}$. Then $\RV{J}\CI\RV{L}|\RV{K}$. 
% % \end{lemma}

% % \begin{proof}
% % From Lemma 1.3 in \citet{kallenberg_basic_2005}.
% % \end{proof}

% \begin{proof}
% If $\prob{P}$ commutes with exchange, then for any $\alpha\in R$ such that $\prob{P}_\alpha^{\RV{D}}$ is exchangeable then $\prob{P}_\alpha$ is also exchangeable. Then there exists $\RV{H}$ a symmetric function of $(\RV{Y}_i,\RV{D}_i)_{i\in\mathbb{N}}$ such that $\RV{Y}_i\CI_{\prob{P}}(\RV{D}_j,\RV{Y}_j)_{j\in \mathbb{N}}\setminus \{i\}|\RV{H}\RV{D}_i$. This is De Finetti's representation theorem, and many proofs exists, see for example \citep{kallenberg_basic_2005}.

% In particular, let 

% \begin{align}
%     \RV{H}:=A\times B\mapsto \lim_{n\to\infty} \frac{1}{n}\sum_{i\in n} \mathds{1}_{A\times B}((\RV{Y}_i, \RV{D}_i))
% \end{align}

% Then for all $\alpha\in R$,
% \begin{align}
%     \prob{P}_\alpha^{(\RV{Y}_i,\RV{D}_i)_{i\in\mathbb{N}}|\RV{H}}(A\times B|h) \overset{a.s.}{=} h(A\times B)\label{eq:given_h}
% \end{align}

% The proof that the limit exists and the above equality holds can again be found int \citep{kallenberg_basic_2005}.
% \end{proof}

\subsection{Representations of contractible probability models}

We prove two representation theorems for causally contractible do models. Theorem \ref{th:table_rep} shows that a do model is contractible if and only if it can be represented with a contractible probability distribution over a ``table of variables''\todo{matrix of variables?} and a lookup function. This is interesting in its own right, as tabular probability distributions and lookup functions are core elements of the potential outcomes approach. However, as we will point out, this lookup table may or may not support an interpretation as a table of potential outcomes. Furthermore, we make use of this theorem in proving Theorem \ref{th:iid_rep}, which shows a do model is contractible if and only if it can be represented by independent copies of a unit level consequence map jointly parametrised by a hypothesis. We will argue in the next section that jointly parametrised consequence maps are fundamental to all approaches to causal inference.

\begin{definition}[Contractible probability distribution]
Given a fundamental probability set $\Omega$, variable $\RV{X}:=(\RV{X}_i)_{i\in \mathbb{N}}$ and a probability distribution $\prob{P}^{\RV{X}}\in\Delta(X^{\mathbb{N}})$, any $S=(s_i)_{i\in A}$, $T=(t_i)_{i\in A}$ with $A\subset\mathbb{N}$ and $i<j\implies s_i<s_j \land t_i<t_j$, let $\RV{X}_S:=(\RV{X}_i)_{i\in S}$ and $\RV{X}_T:=(\RV{X}_i)_{i\in T}$. If
\begin{align}
    \prob{P}^{\RV{X}_S} &= \prob{P}^{\RV{X}_T}
\end{align}
 $\prob{P}$ is contractible.
\end{definition}

If we have a do model $\prob{P}$ that is causally contractible, we can represent it as an exchangeable probability distribution and a lookup function.

\todo[inline]{The following can be deduced from the theorems after it, but I thought it might be helpful to have the explanation.}

That is, we can define a variable $\RV{Y}^D:\Omega\to Y^{D\times\mathbb{N}}$ which can be represented as a matrix of variables $\RV{Y}_{ij}$

\begin{align}
    \RV{Y}^D &= \tikzfig{Y_table_representation}
\end{align}

and, given any deterministic decision function $\delta_d$, $d=(d_i)_{i\in\mathbb{N}}\in D^{\mathbb{N}}$, we can find $\prob{P}^{\RV{Y}|\RV{D}}$ by ``looking up'' $d$ in the table. For example, if $d=(1,2,3,2,...)$, Equation \ref{eq:table_lookup_example} illustrates the idea of ``looking up'' the relevant elements of $\RV{Y}^D$ and Equation \ref{eq:table_lookup_cons} illustrates the resulting value of $\prob{P}^{\RV{Y}|\RV{D}}$.

\begin{align}
    \tikzfig{Y_table_lookup}\label{eq:table_lookup_example}\\
    \prob{P}^{\RV{Y}|\RV{D}}(y|(1,2,3,2,...)) = \prob{P}^{\RV{Y}_11\RV{Y}_22\RV{Y}_{33}\RV{Y}_{24}...}(y)\label{eq:table_lookup_cons}
\end{align}

The contractibility of $\prob{P}^{\RV{Y}^D}$ means that any two subcollections of columns of the same size are equal in distribution, and the exchangeability of $\prob{P}^{\RV{Y}^D}$ means that the random variable obtained by permuting its columns is also equal in distribution to $\RV{Y}^D$.

This representation is very similar to the potential outcomes representation of causal models, with two points of friction. Firstly, we used the assumption of contractibility to derive the contractible table representation, and so we make no claims about what kind of do-model is represented by a non-contractible table lookup. Secondly, we do not yet include any notion of observations, which is a key element of potential outcomes models.

\begin{theorem}[Table representation of causally contractible do models]\label{th:table_rep}
Suppose we have a fundamental probability set $\Omega$ and a do model $(\prob{P},\RV{D},\RV{Y},R)$ such that $\RV{D}:=(\RV{D}_i)_{i\in \mathbb{N}}$ and $\RV{Y}:=(\RV{Y}_i)_{i\in\mathbb{N}}$. $\prob{P}$ is causally contractible if and only if 
\begin{align}
    \prob{P}^{\RV{Y}|\RV{D}} &= \tikzfig{lookup_representation}\\
    &\iff\\
    \prob{P}^{\RV{Y}|\RV{D}}(y|d) &= \prob{P}^{(\RV{Y}^D_{d_i i})_{\mathbb{N}}}(y)
\end{align}
Where $\prob{P}^{\RV{Y}^D}$ is a contractible probability measure on $Y^{D\times\mathbb{N}}$ with respect to the sequence $\RV{Y}^D:=(\RV{Y}_{ij}^D)_{i\in D,j\in \mathbb{N}}$ and $\prob{L}^{\RV{D},\RV{Y}^D}$ is the Markov kernel associated with the lookup function
\begin{align}
    l:D^\mathbb{N}\times Y^{D\times \mathbb{N}}&\to Y\\
    ((d_i)_\mathbb{N},(y_{ij})_{i\in D,j\in \mathbb{N}})&\mapsto y_{d_i i}
\end{align}
\end{theorem}

\begin{proof}
Only if:
Choose $e:=(e_i)_{i\in\mathbb{N}}$ such that $e_{|D|i+j}$ is the $i$th element of $D$ for all $i,j\in \mathbb{N}$. Abusing notation, write $e$ also for the decision function that chooses $e$ deterministically.

Define
\begin{align}
    \prob{P}^{\RV{Y}^D}((y_{ij})_{D\times \mathbb{N}}):=\prob{P}_e^{\RV{Y}}((y_{|D|i+j})_{i\in D, j\in \mathbb{N}})
\end{align}

Now consider any $d:=(d_i)_{i\in \mathbb{N}}\in D^{\mathbb{N}}$. By definition of $e$, $e_{|D|d_i + i}=d_i$ for any $i,j\in \mathbb{N}$.

\begin{align}
    \prob{Q}:D\kto Y\\
    \prob{Q}:= \tikzfig{lookup_representation}
\end{align}

and consider some ordered sequence $A\subset \mathbb{N}$ and $B:= ((|D|d_i+i))_{i\in A}$. Note that $e_B:=(e_{|D|d_i +i})_{i\in B}=d_A=(d_i)_{i\in A}$. Then 

\begin{align}
    \sum_{y\in \RV{Y}^{-1}(y_A)} \prob{Q}(y|d) &= \sum_{y\in \RV{Y}^{-1}(y_A)} \prob{P}^{(\RV{Y}^{D}_{d_ii})_{A}}(y) \\
    &= \sum_{y\in \RV{Y}^{-1}(y_A)} \prob{P}_e^{(\RV{Y}_{|D|d_i+i})_{A}}(y)\\
    &= \prob{P}_e^{\RV{Y}_{B}}(y_A)\\
    &= \prob{P}_{d}^{\RV{Y}_A}(y_A)&\text{by causal contractibility}
\end{align}

Because this holds for all $A\subset\mathbb{N}$, by the Kolmogorov extension theorem

\begin{align}
    \prob{Q}(y|d) &= \prob{P}_d^{\RV{Y}}(y)
\end{align}

Because $d$ is the decision function that deterministically chooses $d$, for all $d\in D$

\begin{align}
    \prob{Q}(y|d) &= \prob{P}_d^{\RV{Y}|\RV{D}}(y|d)
\end{align}

And because $\prob{P}_d^{\RV{Y}|\RV{D}}(y|d)$ is unique for all $d\in D^{\mathbb{N}}$ and $\prob{P}^{\RV{Y}|\RV{D}}$ exists by assumption

\begin{align}
    \prob{P}^{\RV{Y}|\RV{D}}=\prob{Q}
\end{align}

Next we will show $\prob{P}^{\RV{Y}^D}$ is contractible. Consider any subsequences $\RV{Y}^D_S$ and $\RV{Y}^D_T$ of $\RV{Y}^D$ with $|S|=|T|$. Let $\rho(S)$ be the ``expansion'' of the indices $S$, i.e. $\rho(S)=(|D|i+j)_{i\in S,j\in D}$. Then by construction of $e$, $e_{\rho(S)}=e_{\rho(T)}$ and therefore

\begin{align}
    \prob{P}^{\RV{Y}^D_S}&= \prob{P}_e^{\RV{Y}_{\rho(S)}})\\
    &= \prob{P}_e^{\RV{Y}_{\rho(T)}})&\text{by contractibility of }\prob{P}\text{ and the equality } e_{\rho(S)}=e_{\rho(T)}\\
    &= \prob{P}^{\RV{Y}^D_T}
\end{align}


If:
Suppose 
\begin{align}
    \prob{P}^{\RV{Y}|\RV{D}} &= \tikzfig{lookup_representation}
\end{align}

and consider any two deterministic decision functions $d,d'\in D^{\mathbb{N}}$ such that some subsequences are equal $d_S=d'_T$.

Let $\RV{Y}^{d_S}=(\RV{Y}_{d_i i})_{i\in S}$.

By definition,

\begin{align}
    \prob{P}^{\RV{Y}_S|\RV{D}}(y_S|d) &= \sum_{y^D_S\in Y^{|D|\times |S|}}\prob{P}^{\RV{Y}^D_S}(y^D_S)\prob{L}^{\RV{D}_S,\RV{Y}^S}(y_S|d,y^D_S)\\
    &= \sum_{y^D_S\in Y^{|D|\times |T|}}\prob{P}^{\RV{Y}^D_T}(y^D_S)\prob{L}^{\RV{D}_S,\RV{Y}^S}(y_S|d,y^D_S)&\text{ by contractibility of }\prob{P}^{\RV{Y}^D_T}\\
    &= \prob{P}^{\RV{Y}_T|\RV{D}}(y_S|d)
\end{align}
\end{proof}

Note that in some versions of potential outcomes, for example \citet{rubin_causal_2005}, potential outcomes are defined as table-and-lookup models, except without the assumption that the probability distribution over the table is contractible. Our argument for a potential outcomes representation does not go through in this case, because it hinges on the fact that we can ``wrap'' the outcomes under a particular blind decision into a table, and then use contractibility to choose one outcome from each column, however using contractibility also gives us exchangeability of the columns.

It is also worth noting that the lookup table does not need to have an interpretation as a collection of potential outcomes. For example, consider a series of bets on fair coinflips -- in this case, the consequence $\RV{Y}_i$ is uniform on $\{0,1\}$ for any decision $\RV{D}_i$. Tha $D=Y=\{0,1\}$ and $\prob{P}_\alpha^{\RV{Y}_n}(y)=\prod_{i\in [n]} 0.5$ for all $n$, $y\in Y^n$, $\alpha\in R$. Then the construction in Theorem \ref{th:table_rep} yields $\prob{P}^{Y^D_i}(y^D_i)=\prod_{j\in D} 0.5$ for all $y^D_i\in Y^D$. That is, $\RV{Y}^0_i$ and $\RV{Y}^1_i$ are independent and uniformly distributed. However, if we wanted $\RV{Y}^0_i$ to represent ``what would happen if I bet 0 on turn $i$'' and $\RV{Y}^1$ to represent ``what would happen if I bet 1 on turn $i$'', then we actually want $\RV{Y}^0_i = 1-\RV{Y}^1_i$. Thus the measurement table lookup is formally similar to the potential outcomes setup, but potential outcomes attributes additional semantics to the entries in the lookup table which can impose extra requirements on their distribution.

Theorem \ref{th:contractibility_commutativity} establishes a claim made earlier: that contractibility is strictly stronger than commutativity of exchange.

\begin{theorem}\label{th:contractibility_commutativity}
Causal contractibility implies commutativity of exchange.
\end{theorem}

\begin{proof}
Given a finite permutation $\rho:\mathbb{N}\to\mathbb{N}$ and any sequence $x:=(x_i)_{i\in \mathbb{N}}$ let $\rho(x)=(x_{\rho(i)})_{i\in\mathbb{N}}$ or equivalently $(x_{i})_{i\in\rho(\mathbb{N})}$. Then for any $d=(d_{i})_{i\in\mathbb{N}}$ and $y^D:=(y_{ij})_{i\in D,j\in \mathbb{N}}$:

\begin{align}
    l(\rho(d),y^D) &= (y_{d_{\rho(i)} i})_{i\in\mathbb{N}}\\
                 &= (y_{d_i \rho^{-1}(i)})_{i\in \rho(\mathbb{N})}\\
                 &= \rho(l(d,\rho^{-1}(y^D)))
\end{align}

Suppose we have a fundamental probability set $\Omega$ and a do model $(\prob{P},\RV{D},\RV{Y},R)$ with $\RV{D}:=(\RV{D}_i)_{i\in \mathbb{N}}$ and $\RV{Y}:=(\RV{Y}_i)_{i\in\mathbb{N}}$ and $\prob{P}$ causally contractible. Then
\begin{align}
    \prob{P}^{\RV{Y}|\RV{D}} &= \tikzfig{lookup_representation}
\end{align}
For contractible $\prob{P}^{\RV{Y}^D}$. Therefore $\prob{P}^{\RV{Y}^D}$ is also exchangeable \citet{kallenberg_basic_2005}. But then, given a decision function $d$ and a finite permutation $\rho:\mathbb{N}\to \mathbb{N}$
\begin{align}
    \prob{P}_{\rho(d)}^{\RV{Y}}(y) &= \sum_{y^{\prime D}\in Y^{D\times \mathbb{N}}} \llbracket l_{DY}(\rho(d),y^{\prime D}) = y \rrbracket \prob{P}^{\RV{Y}^D}(y^{\prime D})\\
                                &= \sum_{y^{\prime D}\in Y^{D\times \mathbb{N}}} \llbracket l_{DY}(d,\rho^{-1}(y^{\prime D})) = \rho^{-1}(y) \rrbracket \prob{P}^{\RV{Y}^D}(y^{\prime D})\\
                                &= \sum_{y^{\prime D}\in Y^{D\times \mathbb{N}}} \llbracket l_{DY}(d,\rho^{-1}(y^{\prime D})) = \rho^{-1}(y) \rrbracket \prob{P}^{\RV{Y}^D}(\rho^{-1}(y^{\prime D}))\\
                                &= \prob{P}_{\rho(d)}^{\RV{Y}}(\rho^{-1}(y))
\end{align}
\end{proof}

We can also represent contractible do-models as a Markov kernels that map from decisions to probability distributions over consequences copied $\mathbb{N}$ times and jointly parametrised by a hypothesis $\RV{H}$. 

\begin{theorem}\label{th:iid_rep}
Suppose we have a fundamental probability set $\Omega$ and a do model $(\prob{P},\RV{D},\RV{Y},R)$ such that $\RV{D}:=(\RV{D}_i)_{i\in \mathbb{N}}$ and $\RV{Y}:=(\RV{Y}_i)_{i\in\mathbb{N}}$. $\prob{P}$ is causally contractible if and only if there exists some $\RV{H}:\Omega\to H$ such that $\prob{P}^{\RV{Y}_i|\RV{H}\RV{D}_i}$ exists for all $i\in \mathbb{N}$ and
\begin{align}
    \prob{P}^{\RV{Y}|\RV{H}\RV{D}} &= \tikzfig{do_model_representation}\\
    &\iff\\
    \RV{Y}_i&\CI_{\prob{P}} \RV{Y}_{\mathbb{N}\setminus i},\RV{D}_{\mathbb{N}\setminus i}|\RV{H}\RV{D}_i&\forall i\in \mathbb{N}\\
    \land \prob{P}^{\RV{Y}_i|\RV{H}\RV{D}_i} &= \prob{P}^{\RV{Y}_0|\RV{H}\RV{D}_0} & \forall i\in \mathbb{N}
\end{align}
\end{theorem}

\begin{proof}
If:
By the assumptions of independence and identical conditionals, for any deterministic decision functions $d,d'\in D$ with equal subsequences $d_S=d'_T$
\begin{align}
    \prob{P}_d^{\RV{Y}_S|\RV{H}\RV{D}}(y|d) &= \int_H\prod_{i\in S}\prob{P}^{\RV{Y}_0|\RV{H}\RV{D}_0}(y_i|h,d_i)d\prob{P}^{\RV{H}}(h)\\
                                          &= \int_{H}\prod_{i\in T}\prob{P}^{\RV{Y}_0|\RV{H}\RV{D}_0}(y_i|h,d'_i)d\prob{P}^{\RV{H}}(h) & \text{by equality of subsequences}\\
                                          &= \prob{P}_{d'}^{\RV{Y}_T|\RV{H}\RV{D}}(y|d)
\end{align}

Only if:
We have
\begin{align}
    \prob{P}^{\RV{Y}|\RV{D}} &= \tikzfig{lookup_representation}
\end{align}

Also, by contractibility of $\prob{P}^{\RV{Y}^D}$ and De Finetti's theorem, there is some $\RV{H}$ such that

\begin{align}
    \prob{P}^{\RV{Y}^\RV{D}} &= \tikzfig{de_finetti_potential_outcomes}
\end{align}

In particular, let $\RV{Y}^D_{\cdot i}:=(\RV{Y}^D_{ji})_{j\in D}$ and $\RV{Y}^D_{\cdot \{i\}^C} = (\RV{Y}^D_{jk})_{j\in D, k\in \mathbb{N}\setminus \{i\}}$, and

\begin{align}
    &\RV{Y}^D_{\cdot i} \CI_{\prob{P}} \RV{Y}^D_{\cdot \{i\}^C} |\RV{H} & \text{ representation theorem}\label{eq:pci_1}\\
    &\RV{Y}^D\RV{H} \CI_{\prob{P}} \RV{D} &\text{ by Theorem \ref{th:cons_ci} and existence of }\prob{P}^{\RV{Y}^D\RV{H}}\label{eq:pci_2}\\
    &\RV{Y}^D_{\cdot i}\CI_{\prob{P}} \RV{D} |\RV{Y}^D_{\cdot \{i\}^C}\RV{H}&\text{ weak union on Eq. }\ref{eq:pci_2}\\
    &\RV{Y}^D_{\cdot i}\CI_{\prob{P}} \RV{D}\RV{Y}^D_{\cdot \{i\}^C} |\RV{H}&\text{ contraction on Eqs. \ref{eq:pci_1} and \ref{eq:pci_2}}\label{eq:pci_4}\\
    &\RV{Y}^D_{\cdot i}\CI_{\prob{P}} \RV{D}_{\{i\}^C}\RV{Y}^D_{\cdot \{i\}^C} |\RV{H}\RV{D}_i&\text{ weak union on Eq. \ref{eq:pci_4}}\label{eq:pci_5}\\
    &\RV{D}_{i} \CI_{\prob{P}}\RV{Y}^D_{\cdot \{i\}^C} \RV{D}_{\{i\}^C} |\RV{H}\RV{D}_i \RV{Y}^D_{\cdot i}&\text{ due to conditioning on }\RV{D}_i\label{eq:pci_6}\\
    &\RV{Y}^D_{i}\RV{D}_i \CI_{\prob{P}} \RV{D}_{\{i\}^C}\RV{Y}^D_{\cdot \{i\}^C} |\RV{H}\RV{D}_i&\text{ contraction on Eqs. \ref{eq:pci_5} and \ref{eq:pci_6}}\label{eq:pci_7}\\
\end{align}

Now, note that $(\RV{Y}_i,\RV{D}_i)$ is a deterministic function of $(\RV{Y}^D_{i},\RV{D}_i)$ and $(\RV{Y}_{\{i\}^C},\RV{D}_{\{i\}^C})$ is a deterministic function of $(\RV{Y}^D_{\{i\}^C},\RV{D}_{\{i\}^C})$. Therefore

\begin{align}
    &\RV{Y}_i \CI_{\prob{P}} \RV{D}_{\{i\}^C}\RV{Y}_{\{i\}^C} |\RV{H}\RV{D}_i&
\end{align}

So, by Theorem \ref{th:cons_ci}, $\prob{P}^{\RV{Y}_i|\RV{HD}}$ exists and by contractibility of $\prob{P}^{\RV{Y}^D}$, for any $i,j\in\mathbb{N}$

\begin{align}
    \prob{P}^{\RV{Y}_i|\RV{HD_i}}(y_i|h,d_i) &= \prob{P}^{\RV{Y}^D_{d_i i}|\RV{H}}(y_i|h) \\
    &= \prob{P}^{\RV{Y}^D_{d_i j}|\RV{H}}(y_i|h)\\
    &= \prob{P}^{\RV{Y}_j|\RV{HD}_j}(y_i|h,d_i)
\end{align}
\end{proof}

\subsection{Potential outcomes}

