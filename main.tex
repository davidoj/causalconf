\documentclass{article}

% If your paper is accepted, change the options for the package
% aistats2020 as follows:
%
% \usepackage[accepted]{aistats2020}
%
% This option will print headings for the title of your paper and
% headings for the authors names, plus a copyright note at the end of
% the first column of the first page.

% If you set papersize explicitly, activate the following three lines:
%\special{papersize = 8.5in, 11in}
%\setlength{\pdfpageheight}{11in}
%\setlength{\pdfpagewidth}{8.5in}

% If you use natbib package, activate the following three lines:
\usepackage[round]{natbib}
\renewcommand{\bibname}{References}
\renewcommand{\bibsection}{\subsubsection*{\bibname}}

% If you use BibTeX in apalike style, activate the following line:
%\bibliographystyle{apalike}

\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

% My packages

\usepackage[mathscr]{euscript}
\usepackage{graphicx}
\usepackage {tikz}
\usetikzlibrary {positioning}
\usetikzlibrary{shapes.misc}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{calc}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{intersections}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{dsfont}
\usepackage{stmaryrd }
\usepackage{csquotes}
\usepackage{wasysym}
\usepackage[]{todonotes}
\usepackage[shortlabels]{enumitem}
\usepackage{bm}
\usepackage{isomath}
\usepackage{mathtools}

\makeatletter
\newcommand{\newreptheorem}[2]
  {\newtheorem*{rep@#1}{\rep@title}\newenvironment{rep#1}[1]
  {\def\rep@title{#2 \ref*{##1}}\begin{rep@#1}}{\end{rep@#1}}}
\makeatother

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newreptheorem{theorem}{Theorem}

\newtheorem{innercustomthm}{Theorem}
\newenvironment{customthm}[1]
  {\renewcommand\theinnercustomthm{#1}\innercustomthm}
  {\endinnercustomthm}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}

\DeclareMathAlphabet{\mathsfit}{T1}{\sfdefault}{\mddefault}{\sldefault}

\newcommand{\CI}{\mathrel{\text{\scalebox{1.07}{$\perp\mkern-10mu\perp$}}}}
\newcommand{\CII}{\mathrel{\text{\scalebox{1.07}{$\perp\mkern-10mu\perp\mkern-10mu\perp$}}}}
\newcommand{\RV}[1]{\ensuremath{\mathsf{#1}}}
\newcommand{\URV}[1]{\ensuremath{\underline{\RV{#1}}}}
\newcommand{\PA}[2]{\ensuremath{\text{Pa}_{#1}(#2)}}
\newcommand{\ND}[2]{\ensuremath{\text{ND}_{#1}(#2)}}
\newcommand{\CH}[2]{\ensuremath{\text{Ch}_{#1}(#2)}}
\newcommand{\DE}[2]{\ensuremath{\text{De}_{#1}(#2)}}
\newcommand{\ID}[1]{\ensuremath{\text{Id}_{#1}}}
\newcommand{\utimes}{\ensuremath{\underline{\otimes}}}
\newcommand{\prob}[1]{\ensuremath{\mathbb{#1}}}
\newcommand{\kernel}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\model}[1]{\ensuremath{\mathbb{#1}}}
\newcommand{\seedo}{\ensuremath{\mathbb{T}}}
\newcommand{\diagram}[1]{\ensuremath{\mathscr{#1}}}
\newcommand{\sigalg}[1]{\ensuremath{\mathcal{#1}}}
\newcommand{\vecRV}[1]{\ensuremath{\mathsfbfit{#1}}}
\newcommand{\vecVal}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\prodSet}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\indx}[1]{\ensuremath{\mathcal{#1}}}
\newcommand{\nod}[1]{\ensuremath{\mathsfit{#1}}}

\makeatletter
\newcommand*\bigcdot{\mathpalette\bigcdot@{.5}}
\newcommand*\bigcdot@[2]{\mathbin{\vcenter{\hbox{\scalebox{#2}{$\m@th#1\bullet$}}}}}
\makeatother

\tikzset{
    triangle/.style = {regular polygon, regular polygon sides=3 },
    node rotated/.style = {rotate=90},
    border rotated/.style = {shape border rotate=90},
    dist/.style = {triangle,draw,border rotated, inner sep=0pt},
    smalldist/.style = {triangle,draw,border rotated},
    kernel/.style={rectangle,draw,inner sep = 2pt},
    expectation/.style = {triangle,draw,inner sep=0pt,shape border rotate=270},
    copymap/.style = {circle,fill,inner sep=1pt}}

\newcommand\DCI{
    \begin{tikzpicture}[scale=0.35]
    \draw[->] (1,0) -- (0,0);
    \draw (0.6,0) -- (0.6,0.75);
    \draw (0.4,0) -- (0.4,0.75);
    \end{tikzpicture}
}

\newcommand\splitter[1]{%
\begin{tikzpicture}[scale=#1]
\draw (0,-1) -- (0,0);
\draw (0,0) to [bend right] (1,1);
\draw (0,0) to [bend left] (-1,1);
\end{tikzpicture}
}

\newcommand\stopper[1]{%
\begin{tikzpicture}[scale=#1]
\draw[-{Rays [n=8]}] (0,-1) -- (0,0);
\end{tikzpicture}
}

\newcommand\source[1]{%
\begin{tikzpicture}[scale=#1]
\path (0,0) node[prob,fill=gray] (P) {};
\draw (P) -- ($(P.east) + (1,0)$);
\end{tikzpicture}
}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\arginf}{arg\,inf}
\DeclareMathOperator*{\argsup}{arg\,sup}

\newcommand{\cheng}[1]{ {\color{purple}[{\bf Cheng:~{#1}}]} }

\title{Modular probability for causal modelling}
\date{\today}

\author{ David Johnston }

\begin{document}

\maketitle


% \begin{abstract}

\section{Introduction}

The typical way to construct a probability model is to define a sample space $(\Omega,\sigalg{F})$ and an ambient probability measure $\prob{P}:\sigalg{F}\to[0,1]$, which together form a ``probability space'' $(\prob{P},\Omega,\sigalg{F})$. Random variables are then defined as measurable functions on the sample space $\RV{X}:(\Omega,\sigalg{F})\to (Q,\sigalg{Q})$. Under this theory, the names given to random variables are arbitrary. However, in practice the names given to random variables are not arbitrary: it is fairly common to talk about two different probability distributions $\prob{P}_1[\RV{X}]$ and $\prob{P}_2[\RV{X}]$ over the same random variable with the intention that these define two different models of the same set of propositions. Alternatively, we might define two probability spaces $(\prob{P}_1,\Omega,\sigalg{F})$, $(\prob{P}_2,\Omega,\sigalg{F})$ on the same sample space with random variables $\RV{X}:\Omega\to A$ and $\RV{Y}:\Omega\to A$ given by the same measurable functions $\RV{X}(\omega)=\RV{Y}(\omega)$ but with the intention that $\prob{P}_1(\RV{X})$ and $\prob{P}_2(\RV{Y})$ model different phenomena. Such issues are particularly prevalent in causal modelling, where (for example) we might take a probability distribution $\prob{P}[\RV{X}\RV{Y}\RV{Z}]$, then modify it in accordance with the do-calculus with respect to some graph $\mathcal{G}$ to obtain $\prob{P}[\RV{Y}|do(\RV{X}=x)]$. Clearly $\prob{P}[\RV{X}\RV{Y}\RV{Z}]$ and $\prob{P}[\RV{Y}|do(\RV{X}=x)]$ are different probability distributions, and the variable $\RV{Y}$ seems to refer to the same set of propositions in each. 

Here we propose a theory of variable naming that formally specifies a method for dealing with ``variable names''. We define \emph{named variables} as a subset of random variables -- namely, those random variables that we care to give names. A \emph{modelling context} holds a number of different conditional probability spaces along with a collection of named random variables. Random variables names function similarly to type definitions -- the conditional probability distributions in each probability space can be combined in an operation that we call \emph{extension} with arbitrary conditional probabilities providing that the names of their respective named variable sets can be matched in appropriate ways. We call this ``modular probability'', as it enables us to take collections of conditional probabilities from our modelling context and assemble them like lego pieces, if they have the right attachments for one another.

Our contributions are:

\begin{itemize}
  \item A theory of named variables
  \item Using this theory, we explore causal models under the decision theoretic, graphical model and potential outcomes approach, and show how the latter two approaches can be embedded in the former approach
  \item We examine an ambiguity in the definition of Causal Bayesian Networks that is made obvious when we attempt to apply our theory of named varibles
  \item We examine how a particular kind of lego piece -- a \emph{comb} -- arises repeatedly in causal models and gives a natural way to understand conditional vs ``causal'' dependece
\end{itemize}


% \end{abstract}
\tableofcontents


\input{probability}
\input{seedo}
\input{cbns}
\input{potential_outcomes}
\input{appendix}
% \input{chapter_3_twoplayer_statistical_models}
% \input{chapter_4_statistical_decision_theory}
% \input{chapter_5_interventions_counterfactuals}
% \input{chapter_6_imitability_inference}
% \input{chapter_7_godscomputer}

\bibliographystyle{plainnat}
\bibliography{references}

\appendix
\newpage
\section*{Appendix:}

% \input{appendix_AIstats}

\end{document}
