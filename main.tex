\documentclass{article}

% If your paper is accepted, change the options for the package
% aistats2020 as follows:
%
% \usepackage[accepted]{aistats2020}
%
% This option will print headings for the title of your paper and
% headings for the authors names, plus a copyright note at the end of
% the first column of the first page.

% If you set papersize explicitly, activate the following three lines:
%\special{papersize = 8.5in, 11in}
%\setlength{\pdfpageheight}{11in}
%\setlength{\pdfpagewidth}{8.5in}

% If you use natbib package, activate the following three lines:
\usepackage[round]{natbib}
\renewcommand{\bibname}{References}
\renewcommand{\bibsection}{\subsubsection*{\bibname}}

% If you use BibTeX in apalike style, activate the following line:
%\bibliographystyle{apalike}

\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

% My packages
\usepackage{tikzit}
\input{diagrams.tikzstyles}
\usepackage[mathscr]{euscript}
\usepackage{graphicx}
\usepackage {tikz}
\usetikzlibrary {positioning}
\usetikzlibrary{shapes.misc}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{calc}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{intersections}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{dsfont}
\usepackage{stmaryrd }
\usepackage{csquotes}
\usepackage{wasysym}
\usepackage[]{todonotes}
\usepackage[shortlabels]{enumitem}
\usepackage{bm}
\usepackage{isomath}
\usepackage{mathtools}
\usepackage{algpseudocode}
\usepackage{algorithm}

\makeatletter
\newcommand{\newreptheorem}[2]
  {\newtheorem*{rep@#1}{\rep@title}\newenvironment{rep#1}[1]
  {\def\rep@title{#2 \ref*{##1}}\begin{rep@#1}}{\end{rep@#1}}}
\makeatother

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newreptheorem{theorem}{Theorem}

\newtheorem{innercustomthm}{Theorem}
\newenvironment{customthm}[1]
  {\renewcommand\theinnercustomthm{#1}\innercustomthm}
  {\endinnercustomthm}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}

\DeclareMathAlphabet{\mathsfit}{T1}{\sfdefault}{\mddefault}{\sldefault}

\newcommand{\CI}{\mathrel{\text{\scalebox{1.07}{$\perp\mkern-10mu\perp$}}}}
\newcommand{\CII}{\mathrel{\text{\scalebox{1.07}{$\perp\mkern-10mu\perp\mkern-10mu\perp$}}}}
\newcommand{\RV}[1]{\ensuremath{\mathsf{#1}}}
\newcommand{\URV}[1]{\ensuremath{\underline{\RV{#1}}}}
\newcommand{\PA}[2]{\ensuremath{\text{Pa}_{#1}(#2)}}
\newcommand{\ND}[2]{\ensuremath{\text{ND}_{#1}(#2)}}
\newcommand{\CH}[2]{\ensuremath{\text{Ch}_{#1}(#2)}}
\newcommand{\DE}[2]{\ensuremath{\text{De}_{#1}(#2)}}
\newcommand{\ID}[1]{\ensuremath{\text{Id}_{#1}}}
\newcommand{\utimes}{\ensuremath{\underline{\otimes}}}
\newcommand{\prob}[1]{\ensuremath{\mathbb{#1}}}
\newcommand{\disint}[1]{\ensuremath{\overline{\prob{#1}}}}
\newcommand{\kernel}[1]{\ensuremath{\mathbb{#1}}}
\newcommand{\model}[1]{\ensuremath{\mathbb{#1}}}
\newcommand{\diagram}[1]{\ensuremath{\mathscr{#1}}}
\newcommand{\sigalg}[1]{\ensuremath{\mathcal{#1}}}
\newcommand{\vecRV}[1]{\ensuremath{\mathsfbfit{#1}}}
\newcommand{\vecVal}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\prodSet}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\indx}[1]{\ensuremath{\mathcal{#1}}}
\newcommand{\nod}[1]{\ensuremath{\mathsfit{#1}}}
\newcommand{\kto}{\ensuremath{\rightarrowtriangle}}
\newcommand{\proc}[1]{\ensuremath{\mathscr{#1}}}
\newcommand{\yields}{\ensuremath{\bowtie}}
\newcommand{\submodel}{\ensuremath{\sqsubset}}
\newcommand{\seedo}[5]{\ensuremath{\model{#1}^{\RV{#3}|\RV{#2}\square\RV{#5}|\RV{#4}}}}
\newcommand{\rseedo}[6]{\ensuremath{\model{#1}^{\RV{#3}|\RV{#2}\framebox{#6}\RV{#5}|\RV{#4}}}}
\newcommand{\set}{\ensuremath{\bowtie}}
\newcommand{\cprod}{\ensuremath{\odot}}
\newcommand{\bigcprod}{\ensuremath{\bigodot}}
\newcommand{\combprod}{\ensuremath{\underline{\cprod}}}
\newcommand{\combbreak}{\ensuremath{\wr}}
\newcommand{\bigcombprod}{\ensuremath{\underline{\bigcprod}}}
\algnewcommand\algorithmicassert{\texttt{assert}}
\algnewcommand\Assert[1]{\State \algorithmicassert(#1)}%


\providecommand\longrightarrowRHD{\relbar\joinrel\relbar\joinrel\mathrel\RHD}
\providecommand\longleftarrowRHD{\mathrel\LHD\joinrel\relbar\joinrel\relbar}

\makeatletter
\newcommand*\bigcdot{\mathpalette\bigcdot@{.5}}
\newcommand*\bigcdot@[2]{\mathbin{\vcenter{\hbox{\scalebox{#2}{$\m@th#1\bullet$}}}}}
\makeatother

\tikzset{
    triangle/.style = {regular polygon, regular polygon sides=3 },
    node rotated/.style = {rotate=90},
    border rotated/.style = {shape border rotate=90},
    dist/.style = {triangle,draw,border rotated, inner sep=0pt},
    smalldist/.style = {triangle,draw,border rotated},
    kernel/.style={rectangle,draw,inner sep = 2pt},
    expectation/.style = {triangle,draw,inner sep=0pt,shape border rotate=270},
    copymap/.style = {circle,fill,inner sep=1pt}}

\newcommand\DCI{
    \begin{tikzpicture}[scale=0.35]
    \draw[->] (1,0) -- (0,0);
    \draw (0.6,0) -- (0.6,0.75);
    \draw (0.4,0) -- (0.4,0.75);
    \end{tikzpicture}
}

\newcommand\splitter[1]{%
\begin{tikzpicture}[scale=#1]
\draw (0,-1) -- (0,0);
\draw (0,0) to [bend right] (1,1);
\draw (0,0) to [bend left] (-1,1);
\end{tikzpicture}
}

\newcommand\stopper[1]{%
\begin{tikzpicture}[scale=#1]
\draw[-{Rays [n=8]}] (0,-1) -- (0,0);
\end{tikzpicture}
}

\newcommand\swap[1]{%
\begin{tikzpicture}[scale=#1]
\draw (0,0) to [out=90, in=270] (0.5,1);
\draw (0.5,0) to [out=90,in=270] (0,1);
\end{tikzpicture}
}

\newcommand\source[1]{%
\begin{tikzpicture}[scale=#1]
\path (0,0) node[prob,fill=gray] (P) {};
\draw (P) -- ($(P.east) + (1,0)$);
\end{tikzpicture}
}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\arginf}{arg\,inf}
\DeclareMathOperator*{\argsup}{arg\,sup}

\newcommand{\cheng}[1]{ {\color{purple}[{\bf Cheng:~{#1}}]} }

\title{When does one variable have a probabilistic causal effect on another?}
\date{\today}

\author{ David Johnston }

\begin{document}

\maketitle


% \begin{abstract}
\tableofcontents


\section{Introduction}

Two widely used approaches to causal modelling are \emph{graphical causal models} and \emph{potential outcomes models}. Graphical causal models, which include Causal Bayesian Networks and Structural Causal Models, provide a set of \emph{intervention} operations that take probability distributions and a graph and return a modified probability distribution \citep{pearl_causality:_2009}. Potential outcomes models feature \emph{potential outcome variables} that represent the ``potential'' value that a quantity of interest would take under the right circumstances, a potential that may be realised if the circumstances actually arise, but will otherwise remain only a potential or \emph{counterfactual} value \citep{rubin_causal_2005}.

Causal inference work undertaken using either approaches is often directed towards determining the likely effects of different actions that could be taken. This kind of application is strongly suggested by the terminology of ``interventions'' and ``potential outcomes''. However, if we want to reason clearly about using data to inform choices of actions, suggestive terminology is not enough to underpin a sound understanding of the correspondence between causal models and action selection problems.

% One challenge for both of these approaches is understanding how their causal primitives -- interventions and potential outcome variables respectively -- relate to the causal questions we are interested in. This challenge is related to the distinction, first drawn by \citep{korzybski_science_1933}, between ``the map'' and ``the territory''. Causal models, like other models, are ``maps'' that purport to represent a ``territory'' that we are interested in understanding. Causal primitives are elements of the maps, and the things to which they refer are parts of the territory. The maps contain all the things that we can talk about unambiguously, so it is challenging to speak clearly about how parts of the maps relate to parts of the territory that fall outside of the maps.

As a motivating example for our contribution, \citet{hernan_does_2008} observed that many epidemiological papers have been published estimating the ``causal effect'' of body mass index. However, Hernán argued, because there are many different \emph{actions} that might affect body mass index, the potential outcomes associated with body mass index themselves are ill-defined. This would not be particularly problematic if we regarded the search for treatment effects as an endeavour entirely separate from questions of choosing actions -- it's only because we want potential outcomes to tell us something about effects of actions that a many-to-one relationship between ``actions'' and ``causal effects'' becomes troublesome.

In a response to Hernán's observation, \citet{pearl_does_2018} argues that \emph{interventions} (by which we mean the operation defined by a causal graphical model) are well defined, but by default they describe ``virtual interventions'' or ``ideal, atomic interventions'', and real actions may instead be described by some more complicated variety of intervention operation. Even with this clarification, it appears that the relationship between interventions and actions is not straightforward. In particular, one might wonder what standard we can use to determine if an action is ``ideal'' and ``atomic'', apart from the question begging standard of agreement with interventions in a given causal graphical model.

In another response, \citet{shahar_association_2009} argued that a properly specified intervention on body mass index will necessarily yield a conclusion that intervention on body mass index has no effect at all on anything apart from body mass index itself. If this is accepted, then it might seem that there is a whole body of literature devoted to estimating a ``causal effect'' that is necessarily equal to zero! It seems that there is a need to clarify the relationship between actions and causal effects.

\subsection{Our approach}

We focus our attention on the following problem: given an experiment with sequence of variable pairs $(\RV{X}_i,\RV{Y}_i)$ and a collection of decision functions $A$ that the experimenter may choose, when is there a unique probabilistic function $H\times X\kto Y$ that defines the ``causal consequence'' of $\RV{X}_i$ on $\RV{Y}_i$ for all $i$? We choose the setting of repeatable experiments because causal inferences are, in practice, usually drawn from sequential data generated from repeatable experiments or sampling procedures. Here the set $H$ represents a set of hypotheses that -- under some choices of decision function -- becomes deterministic in the limit of infinite data.

To answer this question, we require clarity on what we mean by ``variable'', and so we begin with an explanation of a theory of variables. This theory is close to a standard account, but we are somewhat more explicit than usual about the relationship between variables and measurement procedures.

We then address the problem of creating probabilistic models of variables that permit us to evaluate different choices of decision function. To this end, we introduce \emph{probability sets}, which can be though of as partially specified probability models, and \emph{probability gap models} which can be thought of as probability sets along with a selection of choices for ``filling the gap''. We typically specify probability sets with conditional probabilities, and the criterion of \emph{validity} ensures that we don't inadvertently end up specifying empty probability sets -- a problem that can arise in the context of modelling interventions on body mass index.

We then prove that a condition we call \emph{causal contractibility} is equivalent to the existence of repeatable causal consequences. This result is akin to De Finetti's theorem showing the equivalence between exchangeability and the existence of a ``unique but unknown'' distribution such that all variables are independent and identically distributed according to it.

Finally, we consider the question of \emph{when} casual contractibility might be reasonable to assume. This requires us to consider the measurement processes associated with the variables that we think may or may not be causally contractible. We suggest two sufficient sets of conditions:
\begin{enumerate}
  \item The $\RV{X}_i$s are deterministically equal for all experimental units
  \item The evidence is symmetric for all experimental units, the order of experimentation is irrelevant and the $\RV{X}_i$ are deterministic given the choice of decision function
  \item There exists some $(\RV{D}_i,\RV{Y}_i)_{i\in M}$ causally contractible and $\RV{Y}_i\CI\RV{D}_i|\RV{H}\RV{X}_i$
\end{enumerate}

The first two conditions for causal contractibility are very unlikely to hold for body mass index, both because body mass index may not be functionally related to the available actions and because body mass index cannot be deterministically controlled. The third condition might hold for body mass index with respect to some sets of actions, but this is an empirical question.

% \end{abstract}


\input{probability}
\input{seedo}
\input{representation_repeatability}
\input{appendix_bucket}
% \input{chapter_3_twoplayer_statistical_models}
% \input{chapter_4_statistical_decision_theory}
% \input{chapter_5_interventions_counterfactuals}
% \input{chapter_6_imitability_inference}
% \input{chapter_7_godscomputer}

\bibliographystyle{plainnat}
\bibliography{references}

\appendix
\newpage
\section*{Appendix:}

% \input{appendix_AIstats}

\end{document}
