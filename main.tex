\documentclass{article}

% If your paper is accepted, change the options for the package
% aistats2020 as follows:
%
% \usepackage[accepted]{aistats2020}
%
% This option will print headings for the title of your paper and
% headings for the authors names, plus a copyright note at the end of
% the first column of the first page.

% If you set papersize explicitly, activate the following three lines:
%\special{papersize = 8.5in, 11in}
%\setlength{\pdfpageheight}{11in}
%\setlength{\pdfpagewidth}{8.5in}

% If you use natbib package, activate the following three lines:
\usepackage[round]{natbib}
\renewcommand{\bibname}{References}
\renewcommand{\bibsection}{\subsubsection*{\bibname}}

% If you use BibTeX in apalike style, activate the following line:
%\bibliographystyle{apalike}

\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

% My packages
\usepackage{tikzit}
\input{diagrams.tikzstyles}
\usepackage[mathscr]{euscript}
\usepackage{graphicx}
\usepackage {tikz}
\usetikzlibrary {positioning}
\usetikzlibrary{shapes.misc}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{calc}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{intersections}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{dsfont}
\usepackage{stmaryrd }
\usepackage{csquotes}
\usepackage{wasysym}
\usepackage[]{todonotes}
\usepackage[shortlabels]{enumitem}
\usepackage{bm}
\usepackage{isomath}
\usepackage{mathtools}
\usepackage{algpseudocode}
\usepackage{algorithm}

\makeatletter
\newcommand{\newreptheorem}[2]
  {\newtheorem*{rep@#1}{\rep@title}\newenvironment{rep#1}[1]
  {\def\rep@title{#2 \ref*{##1}}\begin{rep@#1}}{\end{rep@#1}}}
\makeatother

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newreptheorem{theorem}{Theorem}

\newtheorem{innercustomthm}{Theorem}
\newenvironment{customthm}[1]
  {\renewcommand\theinnercustomthm{#1}\innercustomthm}
  {\endinnercustomthm}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}

\DeclareMathAlphabet{\mathsfit}{T1}{\sfdefault}{\mddefault}{\sldefault}

\newcommand{\CI}{\mathrel{\text{\scalebox{1.07}{$\perp\mkern-10mu\perp$}}}}
\newcommand{\CII}{\mathrel{\text{\scalebox{1.07}{$\perp\mkern-10mu\perp\mkern-10mu\perp$}}}}
\newcommand{\RV}[1]{\ensuremath{\mathsf{#1}}}
\newcommand{\URV}[1]{\ensuremath{\underline{\RV{#1}}}}
\newcommand{\PA}[2]{\ensuremath{\text{Pa}_{#1}(#2)}}
\newcommand{\ND}[2]{\ensuremath{\text{ND}_{#1}(#2)}}
\newcommand{\CH}[2]{\ensuremath{\text{Ch}_{#1}(#2)}}
\newcommand{\DE}[2]{\ensuremath{\text{De}_{#1}(#2)}}
\newcommand{\ID}[1]{\ensuremath{\text{Id}_{#1}}}
\newcommand{\utimes}{\ensuremath{\underline{\otimes}}}
\newcommand{\prob}[1]{\ensuremath{\mathbb{#1}}}
\newcommand{\disint}[1]{\ensuremath{\overline{\prob{#1}}}}
\newcommand{\kernel}[1]{\ensuremath{\mathbb{#1}}}
\newcommand{\model}[1]{\ensuremath{\mathbb{#1}}}
\newcommand{\diagram}[1]{\ensuremath{\mathscr{#1}}}
\newcommand{\sigalg}[1]{\ensuremath{\mathcal{#1}}}
\newcommand{\vecRV}[1]{\ensuremath{\mathsfbfit{#1}}}
\newcommand{\vecVal}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\prodSet}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\indx}[1]{\ensuremath{\mathcal{#1}}}
\newcommand{\nod}[1]{\ensuremath{\mathsfit{#1}}}
\newcommand{\kto}{\ensuremath{\rightarrowtriangle}}
\newcommand{\proc}[1]{\ensuremath{\mathscr{#1}}}
\newcommand{\yields}{\ensuremath{\bowtie}}
\newcommand{\submodel}{\ensuremath{\sqsubset}}
\newcommand{\seedo}[5]{\ensuremath{\model{#1}^{\RV{#3}|\RV{#2}\square\RV{#5}|\RV{#4}}}}
\newcommand{\rseedo}[6]{\ensuremath{\model{#1}^{\RV{#3}|\RV{#2}\framebox{#6}\RV{#5}|\RV{#4}}}}
\newcommand{\set}{\ensuremath{\bowtie}}
\newcommand{\cprod}{\ensuremath{\odot}}
\newcommand{\bigcprod}{\ensuremath{\bigodot}}
\newcommand{\combprod}{\ensuremath{\underline{\cprod}}}
\newcommand{\combbreak}{\ensuremath{\wr}}
\newcommand{\bigcombprod}{\ensuremath{\underline{\bigcprod}}}
\algnewcommand\algorithmicassert{\texttt{assert}}
\algnewcommand\Assert[1]{\State \algorithmicassert(#1)}%


\providecommand\longrightarrowRHD{\relbar\joinrel\relbar\joinrel\mathrel\RHD}
\providecommand\longleftarrowRHD{\mathrel\LHD\joinrel\relbar\joinrel\relbar}

\makeatletter
\newcommand*\bigcdot{\mathpalette\bigcdot@{.5}}
\newcommand*\bigcdot@[2]{\mathbin{\vcenter{\hbox{\scalebox{#2}{$\m@th#1\bullet$}}}}}
\makeatother

\tikzset{
    triangle/.style = {regular polygon, regular polygon sides=3 },
    node rotated/.style = {rotate=90},
    border rotated/.style = {shape border rotate=90},
    dist/.style = {triangle,draw,border rotated, inner sep=0pt},
    smalldist/.style = {triangle,draw,border rotated},
    kernel/.style={rectangle,draw,inner sep = 2pt},
    expectation/.style = {triangle,draw,inner sep=0pt,shape border rotate=270},
    copymap/.style = {circle,fill,inner sep=1pt}}

\newcommand\DCI{
    \begin{tikzpicture}[scale=0.35]
    \draw[->] (1,0) -- (0,0);
    \draw (0.6,0) -- (0.6,0.75);
    \draw (0.4,0) -- (0.4,0.75);
    \end{tikzpicture}
}

\newcommand\splitter[1]{%
\begin{tikzpicture}[scale=#1]
\draw (0,-1) -- (0,0);
\draw (0,0) to [bend right] (1,1);
\draw (0,0) to [bend left] (-1,1);
\end{tikzpicture}
}

\newcommand\stopper[1]{%
\begin{tikzpicture}[scale=#1]
\draw[-{Rays [n=8]}] (0,-1) -- (0,0);
\end{tikzpicture}
}

\newcommand\swap[1]{%
\begin{tikzpicture}[scale=#1]
\draw (0,0) to [out=90, in=270] (0.5,1);
\draw (0.5,0) to [out=90,in=270] (0,1);
\end{tikzpicture}
}

\newcommand\source[1]{%
\begin{tikzpicture}[scale=#1]
\path (0,0) node[prob,fill=gray] (P) {};
\draw (P) -- ($(P.east) + (1,0)$);
\end{tikzpicture}
}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\arginf}{arg\,inf}
\DeclareMathOperator*{\argsup}{arg\,sup}

\newcommand{\cheng}[1]{ {\color{purple}[{\bf Cheng:~{#1}}]} }

\title{When does one variable have a probabilistic causal effect on another?}
\date{\today}

\author{ David Johnston, Robert C. Williamson, Cheng Soon Ong }

\begin{document}

\maketitle


% \begin{abstract}
\tableofcontents


\section{Introduction}

Two widely used approaches to causal modelling are \emph{graphical causal models} and \emph{potential outcomes models}. Graphical causal models, which include Causal Bayesian Networks and Structural Causal Models, provide a set of \emph{intervention} operations that take probability distributions and a graph and return a modified probability distribution \citep{pearl_causality:_2009}. Potential outcomes models feature \emph{potential outcome variables} that represent the ``potential'' value that a quantity of interest would take under particular circumstances, a potential that may be realised if the circumstances actually arise, but will otherwise remain only a potential or \emph{counterfactual} value \citep{rubin_causal_2005}.

Causal inference work undertaken using either approaches is often directed towards determining the likely effects of different actions that could be taken. This kind of application is strongly suggested by the terminology of ``interventions'' and ``potential outcomes''. However, if we want to reason clearly about using data to inform choices of actions, suggestive terminology is not enough to underpin a sound understanding of the correspondence between causal models and action selection problems.

% One challenge for both of these approaches is understanding how their causal primitives -- interventions and potential outcome variables respectively -- relate to the causal questions we are interested in. This challenge is related to the distinction, first drawn by \citep{korzybski_science_1933}, between ``the map'' and ``the territory''. Causal models, like other models, are ``maps'' that purport to represent a ``territory'' that we are interested in understanding. Causal primitives are elements of the maps, and the things to which they refer are parts of the territory. The maps contain all the things that we can talk about unambiguously, so it is challenging to speak clearly about how parts of the maps relate to parts of the territory that fall outside of the maps.

As a motivating example for our contribution, \citet{hernan_does_2008} observed that many epidemiological papers have been published estimating the ``causal effect'' of body mass index. However, Hernán argued, because there are many different \emph{actions} that might affect body mass index, the potential outcomes associated with body mass index themselves are ill-defined. This would not be particularly problematic if we regarded the search for treatment effects as an endeavour entirely separate from questions of choosing actions -- it's only because we want potential outcomes to tell us something about effects of actions that a many-to-one relationship between ``actions'' and ``causal effects'' becomes troublesome.

In a response to Hernán's observation, \citet{pearl_does_2018} argues that \emph{interventions} (by which we mean the operation defined by a causal graphical model) are well defined, but by default they describe ``virtual interventions'' or ``ideal, atomic interventions'', and real actions may instead be described by some more complicated variety of intervention operation. Even with this clarification, it appears that the relationship between interventions and actions is not straightforward. In particular, one might wonder what standard we can use to determine if an action is ``ideal'' and ``atomic'', apart from the question begging standard of agreement with interventions in a given causal graphical model.

In another response, \citet{shahar_association_2009} argued that a properly specified intervention on body mass index will necessarily yield a conclusion that intervention on body mass index has no effect at all on anything apart from body mass index itself. If this is accepted, then it might seem that there is a whole body of literature devoted to estimating a ``causal effect'' that is necessarily equal to zero! It seems that there is a need to clarify the relationship between actions and causal effects.

The question we focus on here is: when is there a well-defined causal effect of one variable on another? Many works on causal inference focus on the question of when we can \emph{infer} the causal effect of one variable on another from a given sequence of data. In contrast, the question we focus on is not immediately applicable to practical problems where investigators want to infer causal effects, but any such investigation must accept, implicitly at least, that causal effects do in fact exist. Thus we see our work as foundational to this key question of causation. 

\subsection{Our approach}

We start with two attitudes (they're not precise enough to call assumptions):
\begin{itemize}
  \item To understand ``probabilistic causal effects'', we need to study probabilistic models of decisions and consequences
  \item ``Well-defined probabilistic causal effects'' can be understood as symmetries of models of decisions and consequences
\end{itemize}

To the first proposition, one may object that counterfactual reasoning is the real theoretical foundation of causal modelling, and models of decisions and consequences are a special case of counterfactual reasoning (see \citet{pearl_book_2018} for example). To sidestep arguments of this nature: if all we accomplish is a better understanding of formal decision making and not causation as such, then our endeavour is still worthwhile. 

The second proposition is similar to De Finetti's analysis of the concept of a sequence of events distributed according to a ``constant but unknown probability $\prob{Q}$''. De Finetti observed that, while one may use a probability model $\prob{P}$ to express an uncertain forecast of the outcomes of a sequence of events, the probability $\prob{Q}$ itself seems to represent something of a different kind. In particular, interpreting $\prob{Q}$ requires some additional theory of what it means for a probability model to be correct, while interpreting $\prob{P}$ only requires us to say what it means for an outcome to be realised. De Finetti's solution to this question was to propose that an unknown probability $\prob{Q}$ could be understood as a feature of a forecast $\prob{P}$ which has the property of exchangeability.

In a similar fashion, we observe that one can use a probabilistic model to help make a decision without any theory of what it means for some variable to have a causal effect on some other variable. Thus, like the constant but unknown probability $\prob{Q}$, a ``fixed but unknown causal effect $\RV{Q}(\RV{Y}|do(\RV{X}))$'' requires a theory of what it means for a causal effect to be correct in addition to a probabilistic model of the consequences of decisions. By analogy with De Finetti's reasoning, we propose a theory of causal effects as properties of probabilistic decision models that have a certain type of symmetry that we call \emph{response contractibility}.

As we have just mentioned, we aren't proposing that this is a compelling account of ``causal effects'' in every sense in which the phrase is ever used. However, many causal investigations involve analysing sequences of events that are in some sense repeatable with the aim of helping people interested in influencing similar events in the future to make good decisions. Our theory applies to analysis in this setting. We are studying a particular kind of causal effect which we call a \emph{repeatable response}. Thus, our motivating question is more precisely stated as ``when do probabilistic decision models entail the existence of fixed but unknown conditional probabilities representing repeatable responses?''

To answer this question, we introduce two different pieces of theory. Firstly, we present a mathematical theory of \emph{probability sets}, which extends the standard theory of probability by replacing individual probability measures with sets of probability measures. This extension allows us to model situations in which:
\begin{itemize}
  \item We are able to decide on one choice from a number of different possible choices
  \item The result of each decision is associated with a different probability measure
  \item There are some features of the resulting probability measures that are common to every choice available
\end{itemize}
We note that there are similarities between the theory of probability sets and \emph{imprecise probability} \citep{walley_statistical_1991}, but the precise connections between our theory and different theories of imprecise probability are an open question.

We use the theory of probability sets reason about models of decision problems. However, reasoning about a given model of a problem is only half the story -- we also need to be able to decide when a model is appropriate for a problem. This motivates the second piece of theory presented here: a theory of variables and measurement procedures. This theory is somewhat vague, and we don't see a way to avoid vagueness. We propose \emph{measurement procedures} that are function-like things whose ``domain'' is what we vaguely refer to as ``the real world''. Executing a measurement procedure involves interacting with the real world somehow such that, ultimately, a unique element of a well-defined mathematical set is returned. Because measurement procedures have mathematical sets as their ``codomain'', they can be composed with functions. Because their ``domain'' is the real world, we cannot compose functions with measurement procedures. Variables are functions -- with well-defined domains and codomains -- that we identify with measurement procedures. 

This theory is suggested by many introductions to probability theory. For example, \citet{boole_theory_1862} discusses elements of ``the actual problem'', described in natural language, and a corresponding collection of ``ideal events'' which models the actual problem and also also obey postulates of probability theory. \citet{feller_introduction_1968} describes experiments and observations as ``things whose results take unique values in well-defined mathematical sets''. However, our theory is most informed by the theory of random variables presented by \citet{menger_random_2003}, whom we credit with many of the insights, although our terminology and notation differs somewhat.

\subsection{Contributions}

A secondary contribution of this paper is the notion of \emph{validity} of a model represented by a probability set. This is simply the requirement that the probability set is nonempty. The problem of whether a probability set is valid is analogous to the problem of whether a probability distribution satisfying a collection of constraints exists, discussed in \citet{vorobev_consistent_1962}, although our use of the concept is somewhat more elementary. We discuss how an incautious attempt to build a model of ``interventions on body mass index'' can yield an invalid model.

There are two main contributions. The first is a formal result akin to De Finetti's representation theorem \citep{de_finetti_foresight_1992}. De Finetti's theorem shows that \emph{exchangeability} of a probability model is equivalent -- in a certain sense -- to the existence of a ``fixed but unknown'' probability distribution over a sequence of observations. We introduce a symmetry called \emph{causal contractibility} and show that it is -- in a similar sense -- equivalent to the existence of a ``fixed but unknown'' conditional probability representing the response of one variable to the value of another.

\todo[inline]{There's a logic issue I still need to work out regarding whether causal contractibility assumes determinism or not}

Our second contribution is to consider what kinds of measurement processes support a judgement of causal contractibility. We show that subtly different descriptions of measurement process can support or fail to support such a judgement. In particular, we examine how judgements of causal contractibility might be supported when a decision deterministically fixes a sequence of choices at a point in time when they all look equivalent to a decision maker, but not supported by a measurement process that is described identically except the choices are not deterministically fixed. We also discuss how causal contractibility for nondeterministic variables can follow from a prior judgement of causal contractibility in combination with a certain kind of conditional independence that we call \emph{proxy control}.

We consider it an open question whether judgements of causal contractibility are supported by any measurement procedure that isn't described either of the options we consider -- that is, by measurement procedures that don't involve deterministically selecting choices from a position of ``epistemic indifference'' or from proxy control in combination with a prior judgement of causal contractibility.
% \end{abstract}

\todo[inline]{Roadmap}

\input{variables}
\input{probability}
\input{seedo}
\input{representation_repeatability}
\input{appendix_bucket}
\input{conclusion}
% \input{chapter_4_statistical_decision_theory}
% \input{chapter_5_interventions_counterfactuals}
% \input{chapter_6_imitability_inference}
% \input{chapter_7_godscomputer}

\bibliographystyle{plainnat}
\bibliography{references}

\appendix
\newpage
\section*{Appendix:}

% \input{appendix_AIstats}

\end{document}
