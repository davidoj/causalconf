\documentclass{article}

% If your paper is accepted, change the options for the package
% aistats2020 as follows:
%
% \usepackage[accepted]{aistats2020}
%
% This option will print headings for the title of your paper and
% headings for the authors names, plus a copyright note at the end of
% the first column of the first page.

% If you set papersize explicitly, activate the following three lines:
%\special{papersize = 8.5in, 11in}
%\setlength{\pdfpageheight}{11in}
%\setlength{\pdfpagewidth}{8.5in}

% If you use natbib package, activate the following three lines:
\usepackage[round]{natbib}
\renewcommand{\bibname}{References}
\renewcommand{\bibsection}{\subsubsection*{\bibname}}

% If you use BibTeX in apalike style, activate the following line:
%\bibliographystyle{apalike}

\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

% My packages
\usepackage{tikzit}
\input{diagrams.tikzstyles}
\usepackage[mathscr]{euscript}
\usepackage{graphicx}
\usepackage {tikz}
\usetikzlibrary {positioning}
\usetikzlibrary{shapes.misc}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{calc}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{intersections}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{dsfont}
\usepackage{stmaryrd }
\usepackage{csquotes}
\usepackage{wasysym}
\usepackage[]{todonotes}
\usepackage[shortlabels]{enumitem}
\usepackage{bm}
\usepackage{isomath}
\usepackage{mathtools}
\usepackage{algpseudocode}
\usepackage{algorithm}

\makeatletter
\newcommand{\newreptheorem}[2]
  {\newtheorem*{rep@#1}{\rep@title}\newenvironment{rep#1}[1]
  {\def\rep@title{#2 \ref*{##1}}\begin{rep@#1}}{\end{rep@#1}}}
\makeatother

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newreptheorem{theorem}{Theorem}
\newreptheorem{lemma}{Lemma}

\newtheorem{innercustomthm}{Theorem}
\newenvironment{customthm}[1]
  {\renewcommand\theinnercustomthm{#1}\innercustomthm}
  {\endinnercustomthm}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}

\DeclareMathAlphabet{\mathsfit}{T1}{\sfdefault}{\mddefault}{\sldefault}

\newcommand{\CI}{\mathrel{\text{\scalebox{1.07}{$\perp\mkern-10mu\perp$}}}}
\newcommand{\CII}{\mathrel{\text{\scalebox{1.07}{$\perp\mkern-10mu\perp\mkern-10mu\perp$}}}}
\newcommand{\RV}[1]{\ensuremath{\mathsf{#1}}}
\newcommand{\URV}[1]{\ensuremath{\underline{\RV{#1}}}}
\newcommand{\PA}[2]{\ensuremath{\text{Pa}_{#1}(#2)}}
\newcommand{\ND}[2]{\ensuremath{\text{ND}_{#1}(#2)}}
\newcommand{\CH}[2]{\ensuremath{\text{Ch}_{#1}(#2)}}
\newcommand{\DE}[2]{\ensuremath{\text{De}_{#1}(#2)}}
\newcommand{\ID}[1]{\ensuremath{\text{Id}_{#1}}}
\newcommand{\utimes}{\ensuremath{\underline{\otimes}}}
\newcommand{\prob}[1]{\ensuremath{\mathbb{#1}}}
\newcommand{\disint}[1]{\ensuremath{\overline{\prob{#1}}}}
\newcommand{\kernel}[1]{\ensuremath{\mathbb{#1}}}
\newcommand{\model}[1]{\ensuremath{\mathbb{#1}}}
\newcommand{\diagram}[1]{\ensuremath{\mathscr{#1}}}
\newcommand{\sigalg}[1]{\ensuremath{\mathcal{#1}}}
\newcommand{\vecRV}[1]{\ensuremath{\mathsfbfit{#1}}}
\newcommand{\vecVal}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\prodSet}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\indx}[1]{\ensuremath{\mathcal{#1}}}
\newcommand{\nod}[1]{\ensuremath{\mathsfit{#1}}}
\newcommand{\kto}{\ensuremath{\rightarrowtriangle}}
\newcommand{\proc}[1]{\ensuremath{\mathscr{#1}}}
\newcommand{\yields}{\ensuremath{\bowtie}}
\newcommand{\submodel}{\ensuremath{\sqsubset}}
\newcommand{\seedo}[5]{\ensuremath{\model{#1}^{\RV{#3}|\RV{#2}\square\RV{#5}|\RV{#4}}}}
\newcommand{\rseedo}[6]{\ensuremath{\model{#1}^{\RV{#3}|\RV{#2}\framebox{#6}\RV{#5}|\RV{#4}}}}
\newcommand{\set}{\ensuremath{\bowtie}}
\newcommand{\cprod}{\ensuremath{\odot}}
\newcommand{\bigcprod}{\ensuremath{\bigodot}}
\newcommand{\combprod}{\ensuremath{\underline{\cprod}}}
\newcommand{\combbreak}{\ensuremath{\wr}}
\newcommand{\bigcombprod}{\ensuremath{\underline{\bigcprod}}}
\algnewcommand\algorithmicassert{\texttt{assert}}
\algnewcommand\Assert[1]{\State \algorithmicassert(#1)}%


\providecommand\longrightarrowRHD{\relbar\joinrel\relbar\joinrel\mathrel\RHD}
\providecommand\longleftarrowRHD{\mathrel\LHD\joinrel\relbar\joinrel\relbar}

\makeatletter
\newcommand*\bigcdot{\mathpalette\bigcdot@{.5}}
\newcommand*\bigcdot@[2]{\mathbin{\vcenter{\hbox{\scalebox{#2}{$\m@th#1\bullet$}}}}}
\makeatother

\tikzset{
    triangle/.style = {regular polygon, regular polygon sides=3 },
    node rotated/.style = {rotate=90},
    border rotated/.style = {shape border rotate=90},
    dist/.style = {triangle,draw,border rotated, inner sep=0pt},
    smalldist/.style = {triangle,draw,border rotated},
    kernel/.style={rectangle,draw,inner sep = 2pt},
    expectation/.style = {triangle,draw,inner sep=0pt,shape border rotate=270},
    copymap/.style = {circle,fill,inner sep=1pt}}

\newcommand\DCI{
    \begin{tikzpicture}[scale=0.35]
    \draw[->] (1,0) -- (0,0);
    \draw (0.6,0) -- (0.6,0.75);
    \draw (0.4,0) -- (0.4,0.75);
    \end{tikzpicture}
}

\newcommand\splitter[1]{%
\begin{tikzpicture}[scale=#1]
\draw (0,-1) -- (0,0);
\draw (0,0) to [bend right] (1,1);
\draw (0,0) to [bend left] (-1,1);
\end{tikzpicture}
}

\newcommand\stopper[1]{%
\begin{tikzpicture}[scale=#1]
\draw[-{Rays [n=8]}] (0,-1) -- (0,0);
\end{tikzpicture}
}

\newcommand\swap[1]{%
\begin{tikzpicture}[scale=#1]
\draw (0,0) to [out=90, in=270] (0.5,1);
\draw (0.5,0) to [out=90,in=270] (0,1);
\end{tikzpicture}
}

\newcommand\source[1]{%
\begin{tikzpicture}[scale=#1]
\path (0,0) node[prob,fill=gray] (P) {};
\draw (P) -- ($(P.east) + (1,0)$);
\end{tikzpicture}
}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\arginf}{arg\,inf}
\DeclareMathOperator*{\argsup}{arg\,sup}

\newcommand{\cheng}[1]{ {\color{purple}[{\bf Cheng:~{#1}}]} }

\title{When does one variable have a probabilistic causal effect on another?}
\date{\today}

\author{ David Johnston, Cheng Soon Ong, Robert C. Williamson }

\begin{document}

\maketitle


% \begin{abstract}
\tableofcontents

\begin{abstract}
Popular causal inference frameworks are missing key ingredients. Potential outcomes has no notion of manipulation, and so can only offer informal explanations of critical assumptions like ``stable unit-treatment values'' (SUTVA). Approaches that take manipulation as basic miss the fact that the basic role of a causal model is to represent uncertain knowledge of the consequences of different choices, and as a result, they leave us searching in vain for ``elementary manipulations''. Incorporating both of these ingredients leads us to the ``decision theoretic'' approach to causal inference -- causal models map sets of choices to probability distributions representing our knowledge of the consequences of these choices. With this perspective in hand, we can can prove two basic but important facts about when probabilistic causal effects exist.

\cheng{
We consider a more precise formulation of the consequences of taking an action.
Our decision theoretic approach to causal inference is based on elementary
building blocks, namely probability sets and Markov kernels. We represent
the causal concept of ``consequences of actions'' as a map from sets
(of possible actions) to probability distributions (of outcomes). The new
approach enables us to prove two theorems about the conditions required for
the existance of probabilistic causal effects. We interpret the potential
outcomes setting in our formalism, and provide a resolution to issues such as
stable unit-treatment values and elementary manipulations.
}
\end{abstract}

\section{Introduction}

Two widely used approaches to causal modelling are \emph{graphical causal models} and \emph{potential outcomes models}. Graphical causal models, which include Causal Bayesian Networks (CBNs) and Structural Causal Models (SCMs), provide a set of \emph{intervention} operations that take probability distributions and a graph and return an \emph{interventional probability map} \citep{pearl_causality:_2009}. Potential outcomes models feature \emph{potential outcome variables} that represent the ``potential'' value that a quantity of interest would take under particular circumstances, a potential that may be realised if the circumstances actually arise, but will otherwise represent a potential or \emph{counterfactual} value \citep{rubin_causal_2005}.

It is generally accepted that not every pair of variables admits a unique interventional probability map or unique potential outcomes. In the potential outcomes framework, the ``stable unit-treatment value assumption'' (SUTVA) has been offered as a sufficient condition for the existence of potential outcomes \citet{rubin_causal_2005,imbens_causal_2015}. In the graphical models community, the problem of non-unique interventional distributions is sometimes framed as the problem of determining which variables are \emph{causal variables}. While the distinction between causal variables and random variables is rarely made explicit, the two kinds of variable are not the same.

Two brief examples illustrate this point. First, \emph{height in centimetres} $\RV{H}$ and \emph{height in metres} $\RV{H}'$ are distinct random variables -- concretely, $\RV{H}=100*\RV{H}'$. However it is impossible to take an action that fixes the value of one variable independently of the other. Thus if causal relationships require actions that correspond to the intervention operation in a directed acyclic graph, $\RV{H}$ and $\RV{H}'$ cannot have a causal relationship (this example is due to \citet{eberhardt_contemporary_2022}).

Second, a random variable $\RV{X}$ fails to be a causal variable with respect to $\RV{Y}$ -- and fails to have corresponding potential outcomes $\RV{Y}^X$ -- when there are multiple plausible actions that affect the value of $\RV{X}$ that are likely to have different consequences with respect to $\RV{Y}$. \citet{hernan_does_2008} observed that many epidemiological papers have been published estimating the ``causal effect'' of body mass index $\RV{B}$ on mortality $\RV{M}$. However, as Hernán and Taubman point out, body mass index may be altered by diet, exercise or surgery, and all three different choices are likely to have different consequences with respect to mortality $\RV{M}$. That is, the consequences with regard to $\RV{M}$ are underdetermined by simply stipulating that an action has some effect on $\RV{B}$. A very similar example is explored by  \citet{spirtes_causal_2004,eberhardt_contemporary_2022} who discuss discuss the effect of cholesterol on heart disease, which they argue is similarly underdetermined.

% One challenge for both of these approaches is understanding how their causal primitives -- interventions and potential outcome variables respectively -- relate to the causal questions we are interested in. This challenge is related to the distinction, first drawn by \citep{korzybski_science_1933}, between ``the map'' and ``the territory''. Causal models, like other models, are ``maps'' that purport to represent a ``territory'' that we are interested in understanding. Causal primitives are elements of the maps, and the things to which they refer are parts of the territory. The maps contain all the things that we can talk about unambiguously, so it is challenging to speak clearly about how parts of the maps relate to parts of the territory that fall outside of the maps.

In a response to Hernán and Taubman, \citet{shahar_association_2009} argued that a properly specified intervention on body mass index will yield the conclusion that any ``intervention on body mass index'' must have no effect at all on mortality, because the causal effects are ``fully attributable to confounding by weight and perhaps height''. This claim is supported by the use of a causal diagram in which weight $\RV{W}$ and height $\RV{H}$ are the causal parents of body mass index $\RV{B}$. However, this prescription runs afoul of the problem our first example illustrated: one cannot alter body mass index independently of weight and height. For questions like this, \citet{spirtes_causal_2004} suggest that we should say the effect of ambiguous manipulations cannot be resolved from the data, or to return multiple possible answers for this effect.

At least three responses to this problem can be found: \citet{spirtes_causal_2004,eberhardt_contemporary_2022,chalupka_causal_2017} all resolve the ambiguity by appealing to a fundamental set of manipulations, and posit that causal variable pairs are those whose probabilistic relationships do not depend (in a particular sense) on which intervention is chosen. \citet{woodward_causation_2016} acknowledges the difficulty and reports that he was unable to provide a general characterisation of ``well-defined interventions''. Finally, \citet{noauthor_does_2016} suggests that causal effects should be considered well-defined if sufficiently precise descriptions of an intervention are provided, as judged by consensus of experts.

\subsection{Our approach}

We tackle the problem of when ``causal effects'' exist. Our approach differs from one or both of the popular approaches discussed above in a number of ways:

\begin{enumerate}
  \item We assume that the objective analysis is to compare different choices available in a decision problem
  \item Variables are associated with measurement procedures, not generic ``kinds'' of measurement procedures
  \item Probability distributions represent uncertain knowledge about the results of measurement procedures
\end{enumerate}

We will explain these three features in some more detail. First, our approach is decision theoretic: as \citet{dawid_decision-theoretic_2020} and \citet{heckerman_decision-theoretic_1995} have observed, when we are faced with a decision problem there is automatically a presumptive set of ``elementary interventions'' -- namely, the different choices that we want to compare. This set is exactly the right size: we need to compare every choice available, and there is no comparison that we need to make involving anything but the choices available. This assumption sets our approach apart from variations of potential outcomes and causal graphical models in which causal relationships are tied to random variables.

Second, variables in our approach are associated with concrete measurement procedures. Interventional causal models typically model relationships between what \citet{dawid_decision-theoretic_2020} calls ``generic variables''. Generic variables represent ``types'' of things we can measure, not the results of particular measurements. In standard statistical analysis, generic variables ``$\RV{X}$'' and ``$\RV{Y}$'' might be used to refer to a model of an independent and identically distributed sequence of variables $(\RV{X}_1,\RV{Y}_1),(\RV{X}_2,\RV{Y}_2),...$. As we are interested in when such ``generic causal relationships'' exist, we take as a starting point variables that represent the results of particular measurements, not the results of ``types'' of measurement.

Thirdly, we regard probabilistic causal models as models of our uncertain knowledge of the outcomes of the different choices facing us. This differs from some approaches to causal graphical models that look for causal relationships ``in nature''. In Section \ref{ssec:assessing}, for example, we discuss how causal conclusions can be motivated by a judgement that, no matter which choice we make, our resulting model is indifferent to the ordering of certain ``index variables''.

These differences do not mean that our approach enables any formal results that cannot be found in any other approach. In fact, we speculate the opposite is true: probability functions underpin our approach, causal Bayesian networks, structural causal models, single world intervention graphs or any of various approaches to decision theoretic causal modelling are all probability functions, and there are a number of reasonable ways to extend potential outcomes models to probability functions. Thus, anything that can be said with probability functions in our approach can likely be said using probability functions in any of these other approaches. However, because we have a slightly different understanding of what these probability functions represent, we end up finding different results.


\subsection{Paper Outline}

The key results of this paper are in Section \ref{sec:response_functions}. In particular, Theorem \ref{th:iid_rep} establishes \emph{causal contractibility} as a necessary and sufficient condition for the existence of \emph{response functions}. Response functions are the name we use for the particular kind of ``probabilistic causal effects'' investigated in this paper. Theorem \ref{th:cc_ind_treat} is relevant to justifying causal contractibility in some cases of randomised experiments and active choice. To our knowledge, existing arguments about the identifiability of causal effects tend to be somewhat informal and do not also pertain to active choices. Theorem \ref{th:cc_ind_treat} is notably equally applicable to randomised experiments and active choice, and makes substantially different assumptions to existing results of this nature.

To prove these theorems, we need some standard probability theory, introduced in Section \ref{sec:vague_variables}. We also need to extend standard probability theory to a theory of \emph{probability sets}, which we introduce in Section \ref{sec:probability_sets}. The theory of probability sets is in many ways similar to standard probability theory, except instead of conditional probability distributions we talk about \emph{uniform conditional probability}, which does not always exist, and instead of conditional independence we use \emph{extended conditional independence} as introduced by \citet{constantinou_extended_2017}.

We also make use of a graphical language to represent probability sets. Our notation was created for reasoning about abstract Markov categories, and is somewhat different to existing graphical languages. The main difference is that in our notation wires represent variables and boxes (which are like nodes in directed acyclic graphs) represent probabilistic functions. Standard directed acyclic graphs annotate nodes with variable names and represent probabilistic functions implicitly. The advantage of explicitly representing probabilistic functions is that we can write equations involving graphics. This is not critical to understanding our approach, and we offer statements of all definitions and results in more standard notation, though some proofs depend on the graphical notation. This is introduced in Section \ref{sec:string_diagrams}.
% \end{abstract}

% \input{variables}
\input{seedo}
\input{probability}
\input{markov_string_diagrams}
\input{probability_sets}
\input{representation_repeatability}
\input{conclusion}
\input{appendix_bucket}
% \input{chapter_4_statistical_decision_theory}
% \input{chapter_5_interventions_counterfactuals}
% \input{chapter_6_imitability_inference}
% \input{chapter_7_godscomputer}

\bibliographystyle{plainnat}
\bibliography{references}

\appendix
\newpage
\section*{Appendix:}

% \input{appendix_AIstats}

\end{document}
