\documentclass{article}

% If your paper is accepted, change the options for the package
% aistats2020 as follows:
%
% \usepackage[accepted]{aistats2020}
%
% This option will print headings for the title of your paper and
% headings for the authors names, plus a copyright note at the end of
% the first column of the first page.

% If you set papersize explicitly, activate the following three lines:
%\special{papersize = 8.5in, 11in}
%\setlength{\pdfpageheight}{11in}
%\setlength{\pdfpagewidth}{8.5in}

% If you use natbib package, activate the following three lines:
\usepackage[round]{natbib}
\renewcommand{\bibname}{References}
\renewcommand{\bibsection}{\subsubsection*{\bibname}}

% If you use BibTeX in apalike style, activate the following line:
%\bibliographystyle{apalike}

\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

% My packages
\usepackage{tikzit}
\input{diagrams.tikzstyles}
\usepackage[mathscr]{euscript}
\usepackage{graphicx}
\usepackage {tikz}
\usetikzlibrary {positioning}
\usetikzlibrary{shapes.misc}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{calc}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{intersections}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{dsfont}
\usepackage{stmaryrd }
\usepackage{csquotes}
\usepackage{wasysym}
\usepackage[]{todonotes}
\usepackage[shortlabels]{enumitem}
\usepackage{bm}
\usepackage{isomath}
\usepackage{mathtools}
\usepackage{algpseudocode}
\usepackage{algorithm}

\makeatletter
\newcommand{\newreptheorem}[2]
  {\newtheorem*{rep@#1}{\rep@title}\newenvironment{rep#1}[1]
  {\def\rep@title{#2 \ref*{##1}}\begin{rep@#1}}{\end{rep@#1}}}
\makeatother

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newreptheorem{theorem}{Theorem}

\newtheorem{innercustomthm}{Theorem}
\newenvironment{customthm}[1]
  {\renewcommand\theinnercustomthm{#1}\innercustomthm}
  {\endinnercustomthm}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}

\DeclareMathAlphabet{\mathsfit}{T1}{\sfdefault}{\mddefault}{\sldefault}

\newcommand{\CI}{\mathrel{\text{\scalebox{1.07}{$\perp\mkern-10mu\perp$}}}}
\newcommand{\CII}{\mathrel{\text{\scalebox{1.07}{$\perp\mkern-10mu\perp\mkern-10mu\perp$}}}}
\newcommand{\RV}[1]{\ensuremath{\mathsf{#1}}}
\newcommand{\URV}[1]{\ensuremath{\underline{\RV{#1}}}}
\newcommand{\PA}[2]{\ensuremath{\text{Pa}_{#1}(#2)}}
\newcommand{\ND}[2]{\ensuremath{\text{ND}_{#1}(#2)}}
\newcommand{\CH}[2]{\ensuremath{\text{Ch}_{#1}(#2)}}
\newcommand{\DE}[2]{\ensuremath{\text{De}_{#1}(#2)}}
\newcommand{\ID}[1]{\ensuremath{\text{Id}_{#1}}}
\newcommand{\utimes}{\ensuremath{\underline{\otimes}}}
\newcommand{\prob}[1]{\ensuremath{\mathbb{#1}}}
\newcommand{\disint}[1]{\ensuremath{\overline{\prob{#1}}}}
\newcommand{\kernel}[1]{\ensuremath{\mathbb{#1}}}
\newcommand{\model}[1]{\ensuremath{\mathbb{#1}}}
\newcommand{\diagram}[1]{\ensuremath{\mathscr{#1}}}
\newcommand{\sigalg}[1]{\ensuremath{\mathcal{#1}}}
\newcommand{\vecRV}[1]{\ensuremath{\mathsfbfit{#1}}}
\newcommand{\vecVal}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\prodSet}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\indx}[1]{\ensuremath{\mathcal{#1}}}
\newcommand{\nod}[1]{\ensuremath{\mathsfit{#1}}}
\newcommand{\kto}{\ensuremath{\rightarrowtriangle}}
\newcommand{\proc}[1]{\ensuremath{\mathscr{#1}}}
\newcommand{\yields}{\ensuremath{\bowtie}}
\newcommand{\submodel}{\ensuremath{\sqsubset}}
\newcommand{\seedo}[5]{\ensuremath{\model{#1}^{\RV{#3}|\RV{#2}\square\RV{#5}|\RV{#4}}}}
\newcommand{\rseedo}[6]{\ensuremath{\model{#1}^{\RV{#3}|\RV{#2}\framebox{#6}\RV{#5}|\RV{#4}}}}
\newcommand{\set}{\ensuremath{\bowtie}}
\newcommand{\cprod}{\ensuremath{\odot}}
\newcommand{\bigcprod}{\ensuremath{\bigodot}}
\newcommand{\combprod}{\ensuremath{\underline{\cprod}}}
\newcommand{\combbreak}{\ensuremath{\wr}}
\newcommand{\bigcombprod}{\ensuremath{\underline{\bigcprod}}}
\algnewcommand\algorithmicassert{\texttt{assert}}
\algnewcommand\Assert[1]{\State \algorithmicassert(#1)}%


\providecommand\longrightarrowRHD{\relbar\joinrel\relbar\joinrel\mathrel\RHD}
\providecommand\longleftarrowRHD{\mathrel\LHD\joinrel\relbar\joinrel\relbar}

\makeatletter
\newcommand*\bigcdot{\mathpalette\bigcdot@{.5}}
\newcommand*\bigcdot@[2]{\mathbin{\vcenter{\hbox{\scalebox{#2}{$\m@th#1\bullet$}}}}}
\makeatother

\tikzset{
    triangle/.style = {regular polygon, regular polygon sides=3 },
    node rotated/.style = {rotate=90},
    border rotated/.style = {shape border rotate=90},
    dist/.style = {triangle,draw,border rotated, inner sep=0pt},
    smalldist/.style = {triangle,draw,border rotated},
    kernel/.style={rectangle,draw,inner sep = 2pt},
    expectation/.style = {triangle,draw,inner sep=0pt,shape border rotate=270},
    copymap/.style = {circle,fill,inner sep=1pt}}

\newcommand\DCI{
    \begin{tikzpicture}[scale=0.35]
    \draw[->] (1,0) -- (0,0);
    \draw (0.6,0) -- (0.6,0.75);
    \draw (0.4,0) -- (0.4,0.75);
    \end{tikzpicture}
}

\newcommand\splitter[1]{%
\begin{tikzpicture}[scale=#1]
\draw (0,-1) -- (0,0);
\draw (0,0) to [bend right] (1,1);
\draw (0,0) to [bend left] (-1,1);
\end{tikzpicture}
}

\newcommand\stopper[1]{%
\begin{tikzpicture}[scale=#1]
\draw[-{Rays [n=8]}] (0,-1) -- (0,0);
\end{tikzpicture}
}

\newcommand\swap[1]{%
\begin{tikzpicture}[scale=#1]
\draw (0,0) to [out=90, in=270] (0.5,1);
\draw (0.5,0) to [out=90,in=270] (0,1);
\end{tikzpicture}
}

\newcommand\source[1]{%
\begin{tikzpicture}[scale=#1]
\path (0,0) node[prob,fill=gray] (P) {};
\draw (P) -- ($(P.east) + (1,0)$);
\end{tikzpicture}
}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\arginf}{arg\,inf}
\DeclareMathOperator*{\argsup}{arg\,sup}

\newcommand{\cheng}[1]{ {\color{purple}[{\bf Cheng:~{#1}}]} }

\title{When does one variable have a probabilistic causal effect on another?}
\date{\today}

\author{ David Johnston, Robert C. Williamson, Cheng Soon Ong }

\begin{document}

\maketitle


% \begin{abstract}
\tableofcontents


\section{Introduction}

Two widely used approaches to causal modelling are \emph{graphical causal models} and \emph{potential outcomes models}. Graphical causal models, which include Causal Bayesian Networks and Structural Causal Models, provide a set of \emph{intervention} operations that take probability distributions and a graph and return a modified probability distribution \citep{pearl_causality:_2009}. Potential outcomes models feature \emph{potential outcome variables} that represent the ``potential'' value that a quantity of interest would take under particular circumstances, a potential that may be realised if the circumstances actually arise, but will otherwise remain only a potential or \emph{counterfactual} value \citep{rubin_causal_2005}.

Causal inference work is often directed towards comparing the likely effects of different actions that could be taken. Furthermore, terms like ``intervention'', ``manipulation'' and ``treatment effect'' are used to describe fundamental features of the mathematical frameworks of causal inference. The fact that we regular encounter problems in which different actions can be decided upon and different results are expected on the basis of the decision may be the reason that formal causal inference frameworks exist at all. If we want to understand causal models, or even if we just want to use data to inform choices between different actions, we need to understand how we can mathematically model action selection.

A common aim of causal inference research is to propose methods for discovering causal relationships between variables, and showing that, given certain assumptions, these methods work. A common assumption in the background of this research project is that, in general, there are causal relationships between ``variables'', though we may not always be able to discover them. However, ``variables'' in this proposition cannot be variables in the way that they are usually understood by statistical theory.

% One challenge for both of these approaches is understanding how their causal primitives -- interventions and potential outcome variables respectively -- relate to the causal questions we are interested in. This challenge is related to the distinction, first drawn by \citep{korzybski_science_1933}, between ``the map'' and ``the territory''. Causal models, like other models, are ``maps'' that purport to represent a ``territory'' that we are interested in understanding. Causal primitives are elements of the maps, and the things to which they refer are parts of the territory. The maps contain all the things that we can talk about unambiguously, so it is challenging to speak clearly about how parts of the maps relate to parts of the territory that fall outside of the maps.



As a motivating example for our contribution, \citet{hernan_does_2008} observed that many epidemiological papers have been published estimating the ``causal effect'' of body mass index. However, Hernán argued, because there are many different \emph{actions} that might affect body mass index, the potential outcomes associated with body mass index themselves are ill-defined. This would not be particularly problematic if we regarded the search for treatment effects as an endeavour entirely separate from questions of choosing actions -- it's only because we want potential outcomes to tell us something about effects of actions that a many-to-one relationship between ``actions'' and ``causal effects'' becomes troublesome.

In a response to Hernán and Taubman's observation, \citet{pearl_does_2018} argues that \emph{interventions} (by which we mean the operation defined by a causal graphical model) are well defined, but by default they could be described as ``virtual interventions'' or ``ideal, atomic interventions'', and real actions may instead be described by some more complicated variety of operation. Even with this clarification, the relationship between interventions and actions is not straightforward. In particular, one might wonder what standard we can use to determine if an action is ``ideal'' and ``atomic'', apart from the question begging standard of agreement with interventions in a given causal graphical model.

In another response, \citet{shahar_association_2009} argued that a properly specified intervention on body mass index will necessarily yield a conclusion that intervention on body mass index has no effect at all on anything apart from body mass index itself. If this is accepted, then it might seem that there is a whole body of literature devoted to estimating a ``causal effect'' that is necessarily equal to zero! It seems that there is a need to clarify the relationship between actions and causal effects.

\subsection{Our approach}

Instead of assuming causal effects and trying to explain how actions are related to them, we assume that at the outset, our task is to decide on one of several possible choices, and that each choice has different consequences. This has been called the \emph{decision theoretic approach to causal inference}, and has been explored by other researchers \citep{dawid_decision-theoretic_2020,heckerman_decision-theoretic_1995,lattimore_causal_2019}.

The question we focus on here is, from the decision theoretic starting point, when can we talk in the usual manner about ``the causal effect'' of one variable $\RV{X}$ on another variable $\RV{Y}$? In order to answer a question like this, we need to be more specific about what a ``causal effect'' is. Our provisional definition of a causal effect is similar to an earlier analysis by Bruno De Finetti; De Finetti asked what we could possibly mean when we said a sequence of coin flips was distributed according to a ``constant but unknown probability $\prob{Q}$''\citet{de_finetti_foresight_1992}. Similarly, we take ``a causal effect of $\RV{X}$ on $\RV{Y}$'' to be

\begin{itemize}
  \item A feature of a probabilistic model of a decision problem
  \item A probabilistic function from the range of $\RV{X}$ to the range of $\RV{Y}$
  \item That is not known prior to seeing any data
  \item And that represents the ``distribution of $\RV{Y}$, given $\RV{X}$'' no matter which decision is made
\end{itemize}

For an example, consider a collection of ``interventional probabilities'' $\prob{P}(\RV{Y}|do(\RV{X}=x))$ \citep[chap. 1.3]{pearl_causality:_2009}. Such a collection may or may not be a model of a decision problem. As is typically understood, $\prob{P}(\RV{Y}|do(\RV{X}=x))$ is not known prior to seeing data, and may not even be known after seeing a large amount of data. Finally, $\prob{P}(\RV{Y}|do(\RV{X}=x))$ is often interpreted as ``the probability distribution of $\RV{Y}$, if I were to take some action that sets $\RV{X}$ to be equal to $x$''. Usually implicit in this interpretation is that the model assigns $\RV{Y}$ the same probability distribution \emph{whatever} action is take that sets $\RV{X}$ equal to $x$. This principle is not always implicit -- \citet{chalupka_causal_2017} makes this an explicit requirement for a variable $\RV{X}$ to qualify as a ``causal'' variable with respect to $\RV{Y}$.

In a similar fashion, we observe that one can use a probabilistic model to help make a decision without any theory of what it means for some variable to have a causal effect on some other variable. Thus, like the constant but unknown probability $\prob{Q}$, a ``fixed but unknown causal effect $\RV{Q}(\RV{Y}|do(\RV{X}))$'' requires a theory of what it means for a causal effect to be correct in addition to a probabilistic model of the consequences of decisions. By analogy with De Finetti's reasoning, we propose a theory of causal effects as properties of probabilistic decision models that have a certain type of symmetry that we call \emph{response contractibility}.

As we have just mentioned, we aren't proposing that this is a compelling account of ``causal effects'' in every sense in which the phrase is ever used. However, many causal investigations involve analysing sequences of events that are in some sense repeatable with the aim of helping people interested in influencing similar events in the future to make good decisions. Our theory applies to analysis in this setting. We are studying a particular kind of causal effect which we call a \emph{repeatable response}. Thus, our motivating question is more precisely stated as ``when do probabilistic decision models entail the existence of fixed but unknown conditional probabilities representing repeatable responses?''

To answer this question, we introduce two different pieces of theory. Firstly, we present a mathematical theory of \emph{probability sets}, which extends the standard theory of probability by replacing individual probability measures with sets of probability measures. This extension allows us to model situations in which:
\begin{itemize}
  \item We are able to decide on one choice from a number of different possible choices
  \item The result of each decision is associated with a different probability measure
  \item There are some features of the resulting probability measures that are common to every choice available
\end{itemize}
We note that there are similarities between the theory of probability sets and \emph{imprecise probability} \citep{walley_statistical_1991}, but the precise connections between our theory and different theories of imprecise probability are an open question.

We use the theory of probability sets reason about models of decision problems. However, reasoning about a given model of a problem is only half the story -- we also need to be able to decide when a model is appropriate for a problem. This motivates the second piece of theory presented here: a theory of variables and measurement procedures. This theory is somewhat vague, and we don't see a way to avoid vagueness. We propose \emph{measurement procedures} that are function-like things whose ``domain'' is what we vaguely refer to as ``the real world'', and \emph{decision procedures} which are collections of measurement procedures indexed by the different possible choices we have available. Executing a measurement procedure involves interacting with the real world such that a unique element of a well-defined mathematical set is returned. Each measurement procedure in a decision procedure yields an element of the same set. 

Because measurement procedures have mathematical sets as their ``codomain'', functions can be composed with measurement procedures. Because their ``domain'' is the real world, we cannot perform composition in the reverse direction -- measurement procedures cannot be composed with functions. We would prefer to work with functions than with measurement procedures, so we invoke a single complete measurement procedure that includes all of the different measurements we're interested in for a particular problem. Individual measurements are obtained by composing functions with the complete measurement procedure. In this manner, each individual measurement is associated with a mathematical function, and these mathematical functions are our \emph{variables}.

This theory is suggested by many introductions to probability theory. For example, \citet{boole_theory_1862} discusses elements of ``the actual problem'', described in natural language, and a corresponding collection of ``ideal events'' which models the actual problem and also also obey postulates of probability theory. \citet{feller_introduction_1968} describes experiments and observations as ``things whose results take unique values in well-defined mathematical sets''. However, our theory is most informed by the theory of random variables presented by \citet{menger_random_2003}, whom we credit with many of the insights, although our terminology and notation differs somewhat.

\subsection{Contributions}

A secondary contribution of this paper is the notion of \emph{validity} of a model represented by a probability set. This is simply the requirement that the probability set is nonempty.  We discuss how an incautious attempt to build a model of ``interventions on body mass index'' can yield an invalid model.

There are two main contributions. The first is a formal result akin to De Finetti's representation theorem \citep{de_finetti_foresight_1992}. De Finetti's theorem shows that \emph{exchangeability} of a probability model is equivalent -- in a certain sense -- to the existence of a ``fixed but unknown'' probability distribution over a sequence of observations. We introduce a symmetry called \emph{causal contractibility} and show that it is -- in a similar sense -- equivalent to the existence of a ``fixed but unknown'' conditional probability representing the response of one variable to the value of another.

Our second contribution is to consider what kinds of measurement processes support a judgement of causal contractibility. We show that subtly different descriptions of measurement process can support or fail to support such a judgement. In particular, we examine how judgements of causal contractibility might be supported when a decision deterministically fixes a sequence of choices at a point in time when they all look equivalent to a decision maker, but not supported by a measurement process that is described identically except the choices are not deterministically fixed. We also discuss how causal contractibility for nondeterministic variables can follow from a prior judgement of causal contractibility in combination with a certain kind of conditional independence that we call \emph{proxy control}.

We consider it an open question whether judgements of causal contractibility are supported by any measurement procedure that isn't described either of the options we consider -- that is, by measurement procedures that don't involve deterministically selecting choices from a position of ``epistemic indifference'' or from proxy control in combination with a prior judgement of causal contractibility.
% \end{abstract}

\todo[inline]{Roadmap}

\input{variables}
\input{seedo}
\input{probability}
\input{markov_string_diagrams}
\input{probability_sets}
\input{representation_repeatability}
\input{conclusion}
\input{appendix_bucket}
% \input{chapter_4_statistical_decision_theory}
% \input{chapter_5_interventions_counterfactuals}
% \input{chapter_6_imitability_inference}
% \input{chapter_7_godscomputer}

\bibliographystyle{plainnat}
\bibliography{references}

\appendix
\newpage
\section*{Appendix:}

% \input{appendix_AIstats}

\end{document}
