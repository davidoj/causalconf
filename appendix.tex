%!TEX root = main.tex

\section{Appendix:see-do model representation}\label{sec:see-do-rep}

\todo[inline]{Modularise the treatment of probability}

\begin{theorem}[See-do model representation]\label{th:see_do_rep}
Suppose we have a decision problem that provides us with an observation $x\in X$, and in response to this we can select any decision or stochastic mixture of decisions from a set $D$; that is we can choose a ``strategy'' as any Markov kernel $\kernel{S}:X\to \Delta(D)$. We have a utility function $u:Y\to \mathbb{R}$ that models preferences over the potential consequences of our choice. Furthermore, suppose that we maintain a denumerable set of hypotheses $H$, and under each hypothesis $h\in H$ we model the result of choosing some strategy $\kernel{S}$ as a joint probability over observations, decisions and consequences $\prob{P}_{h,\kernel{S}}\in \Delta(X\times D\times Y)$.

Define $\RV{X},\RV{Y}$ and $\RV{D}$ such that $\RV{X}_{xdy} = x$, $\RV{Y}_{xdy}=y$ and $\RV{D}_{xdy} = d$. Then making the following additional assumptions:
\begin{enumerate}
    \item Holding the hypothesis $h$ fixed the observations as have the same distribution under any strategy: $\prob{P}_{h,\kernel{S}}[\RV{X}]=\prob{P}_{h,\kernel{S}''}[\RV{X}]$ for all $h,\kernel{S},\kernel{S}'$ (observations are given ``before'' our strategy has any effect)
    \item The chosen strategy is a version of the conditional probability of decisions given observations: $\kernel{S}=\prob{P}_{h,\kernel{S}}[\RV{D}|\RV{X}]$
    \item There exists some strategy $\kernel{S}$ that is strictly positive
    \item For any $h\in H$ and any two strategies $\kernel{Q}$ and $\kernel{S}$, we can find versions of each disintegration such that $\prob{P}_{h,\kernel{Q}}[\RV{Y}|\RV{D}\RV{X}]=\prob{P}_{h,\kernel{S}}[\RV{Y}|\RV{D}\RV{X}]$ (our strategy tells us nothing about the consequences that we don't already know from the observations and decisions)
\end{enumerate}

Then there exists a unique see-do model $(\kernel{T},\RV{H}',\RV{D}',\RV{X}',\RV{Y}')$ such that $\prob{P}_{h,\kernel{S}}[\RV{XDY}]^{ijk} = \kernel{T}[\RV{X'}|\RV{H'}]_{h}^{i} \kernel{S}_i^j  \kernel{T}[\RV{Y'}|\RV{X'H'D'}]_{ijk}^k$.
\end{theorem}

\begin{proof}
Consider some probability $\prob{P}\in \Delta(X\times D\times Y)$. By the definition of disintegration (section \ref{ssec:disintegration}), we can write

\begin{align}
 \prob{P}[\RV{XDY}]^{ijk} = \prob{P}[\RV{X}]^i\prob{P}[\RV{D}|\RV{X}]_i^{j} \prob{P}[\RV{Y}|\RV{XD}]_{ij}^{k} \label{eq:disint}
\end{align}

Fix some $h\in H$ and some strictly positive strategy $\kernel{S}$ and define $\kernel{T}:H\times D\to \Delta(X\times Y)$ by
\begin{align}
    \kernel{T}_{hj}^{kl} &= \prob{P}_{h,\kernel{S}}[\RV{X}]^k \prob{P}_{h,\kernel{S}}[\RV{Y}|\RV{X}\RV{D}]^l_{kj} \label{eq:comb_disint}
\end{align}

Note that because $\kernel{S}$ is strictly positive and by assumption $\kernel{S}=\prob{P}_{h,\kernel{S}}[\RV{D}|\RV{X}]$, $\prob{P}_{h,\kernel{S}}[\RV{D}]$ is also strictly positive. Therefore $\prob{P}_{h,\kernel{S}}[\RV{Y}|\RV{D}]$ is unique and therefore $\kernel{T}$ is also unique.

Define $\RV{X}'$ and $\RV{Y}'$ by $\RV{X}'_{xy}=x$ and $\RV{Y}'_{xy}=y$. Define $\RV{H}'$ and $\RV{D}'$ by $\RV{H}'_{hd} = h$ and $\RV{D}'_{hd} = d$.

We then have
\begin{align}
    \kernel{T}[\RV{X'}|\RV{H'D'}]_{hj}^{k} &= \kernel{T}\underline{\RV{X}'}_{hj}^k\\
                                           &= \sum_l \kernel{T}_{hj}^{kl} \\
                                           &= \prob{P}_{h,\kernel{S}}[\RV{X}]^k\\
                                           &= \kernel{T}[\RV{X'}|\RV{H'D'}]_{hj'}^{k}
\end{align}

Thus $\RV{X}'\CI_{\kernel{T}} \RV{D}'|\RV{H}'$ and so $\kernel{T}[\RV{X}'|\RV{H}']$ exists (section \ref{ssec:cond_indep}) and $(\kernel{T},\RV{H}',\RV{D}',\RV{X}',\RV{Y}')$ is a see-do model.

Applying Equation \ref{eq:disint} to $\prob{P}_{h,\kernel{S}}$:

\begin{align}
    \prob{P}_{h,\kernel{S}}[\RV{XDY}]^{ijk} &= \prob{P}_{h,\kernel{S}}[\RV{X}]^i\prob{P}_{h,\kernel{S}}[\RV{D}|\RV{X}]_i^{j} \prob{P}_{h,\kernel{S}}[\RV{Y}|\RV{XD}]_{ij}^{k}\label{eq:t_is_comb_disint_start}\\
     &=  \prob{P}_{h,\kernel{S}}[\RV{X}]^i\prob{P}_{h,\kernel{S}}[\RV{Y}|\RV{XD}]_{ij}^{k}\\
     &= \prob{P}_{h,\kernel{S}}[\RV{D}|\RV{X}]_i^{j} \kernel{T}[\RV{X'Y'}|\RV{H'D'}]_{hj}^{ik}\\
     &= \kernel{S}_i^j \kernel{T}[\RV{X'Y'}|\RV{H'D'}]_{hj}^{ik}\\
     &= \kernel{S}_i^j \kernel{T}[\RV{X'}|\RV{H'D'}]_{hj}^{i} \kernel{T}[\RV{Y'}|\RV{X'H'D'}]_{ihj}^k\\
     &= \kernel{T}[\RV{X'}|\RV{H'}]_{h}^{i} \kernel{S}_i^j  \kernel{T}[\RV{Y'}|\RV{X'H'D'}]_{ihj}^k\label{eq:t_is_comb_disint_end}
\end{align}

Consider some arbitrary alternative strategy $\kernel{Q}$. By assumption

\begin{align}
    \prob{P}_{h,\kernel{S}}[\RV{X}]^{i} &= \prob{P}_{h,\kernel{Q}}[\RV{X}]^{i}\\
    \prob{P}_{h,\kernel{S}}[\RV{Y}|\RV{XD}]_{ij}^k &= \prob{P}_{h,\kernel{Q}}[\RV{Y}|\RV{XD}]_{ij}^k\text{ for some version of }\prob{P}_{h,\kernel{Q}}[\RV{Y}|\RV{XD}]
\end{align}

It follows that, for some version of $\prob{P}_{h,\kernel{Q}}[\RV{Y}|\RV{XD}]$,
\begin{align}
    \kernel{T}_{hj}^{kl} &= \prob{P}_{h,\kernel{Q}}[\RV{X}]^k \prob{P}_{h,\kernel{Q}}[\RV{Y}|\RV{X}\RV{D}]^l_{kj} \label{eq:comb_disint_nonuniq}
\end{align}

Then by substitution of $\kernel{Q}$ for $\kernel{S}$ in Equation \ref{eq:t_is_comb_disint_start} and working through the same steps

\begin{align}
    \prob{P}_{h,\kernel{S}}[\RV{XDY}]^{ijk} &= \kernel{T}[\RV{X'}|\RV{H'}]_{h}^{i} \kernel{Q}_i^j  \kernel{T}[\RV{Y'}|\RV{X'H'D'}]_{ihj}^k
\end{align}

As $\kernel{Q}$ was arbitrary, this holds for all strategies.
\end{proof}

\section{Appendix: Connection is associative}\label{sec:connect_associative}

This will be proven with string diagrams, and consequently generalises to the operation defined by Equation \ref{eq:extn2} in other Markov kernel categories.

Define

\begin{align}
    \RV{I}_{K\cdot\cdot}&:=\RV{I}_K\setminus\RV{I}_L\setminus\RV{I}_J\\
    \RV{I}_{KL\cdot}&:=\RV{I}_K\cap\RV{I}_L\setminus\RV{I}_J\\
    \RV{I}_{K\cdot J}&:=\RV{I}_K\cap\RV{I}_J\setminus\RV{I}_L\\
    \RV{I}_{KL J}&:=\RV{I}_K\cap \RV{I}_L\cap\RV{I}_J\\
    \RV{I}_{\cdot L \cdot} &:= \RV{I}_L\setminus\RV{I}_K\setminus \RV{I}_J\\
    \RV{I}_{\cdot L J} &:= \RV{I}_L\cap \RV{I}_J\setminus \RV{I}_K\\
    \RV{I}_{\cdot\cdot J} &:= \RV{I}_J\setminus\RV{I}_K\setminus\RV{I}_L\\
    \RV{O}_{K\cdot\cdot} &:= \RV{O}_K\setminus\RV{I}_N\setminus\RV{I}_J\\
    \RV{O}_{KL\cdot} &:= \RV{O}_K\cap\RV{I}_L\setminus\RV{I}_J\\
    \RV{O}_{K\cdot J} &:= \RV{O}_K\cap\RV{I}_J\setminus\RV{I}_L\\
    \RV{O}_{KLJ} &:= \RV{O}_K\cap\RV{I}_L\cap\RV{I}_J\\
    \RV{O}_{L\cdot} &:= \RV{O}_L\setminus\RV{I}_J\\
    \RV{O}_{LJ} &:= \RV{O}_L\cap\RV{I}_J
\end{align}

Also define
\begin{align}
    (\kernel{P},\RV{I}_P,\RV{O}_P)&:=\kernel{K}\rightrightarrows \kernel{L}\\
    (\kernel{Q},\RV{I}_Q,\RV{O}_Q)&:=\kernel{L}\rightrightarrows \kernel{J}
\end{align}

Then

\begin{align}
    (\kernel{K}\rightrightarrows \kernel{L})\rightrightarrows \kernel{J} &= \kernel{P}\rightrightarrows \kernel{J}\\
                                                                         &= \begin{tikzpicture}[baseline={([yshift=-.2ex]current bounding box.center)}]
        \path (0,0) node (Y) {$\RV{I}_{P\cdot}$}
        + (0,-0.3) node (Q) {$\RV{I}_{PJ}$}
        + (0,-0.8) node (R) {$\RV{I}_{\cdot J}$}
        ++ (0.5,-0.3) node[copymap] (copy0) {}
        ++ (0.5,0.15) node[kernel] (K) {$\kernel{P}$}
        ++ (0.5,-0.15) node[copymap] (copy1) {}
        ++ (0.6,-0.5) node[kernel] (L) {$\kernel{J}$}
        ++ (0.6, 0.8) node (Z) {$\RV{O}_{P\cdot}$}
        + (0,-0.3) node (X) {$\RV{O}_{PJ}$}
        + (0,-0.8) node (W) {$\RV{O}_J$};
        \draw (Y) -- ($(K.west) + (0,0.15)$) (Q) -- ($(K.west) + (0,-0.15)$);
        \draw (copy0) to [out=-45,in=180] ($(L.west) + (0,0)$) (copy1) to [out=-60,in=180] ($(L.west) + (0,0.15)$);
        \draw (R) to [out=0,in=180] ($(L.west) + (0,-0.15)$);
        \draw ($(K.east) + (0,-0.15)$) to (copy1);
        \draw ($(K.east) + (0,0.15)$) -- (Z) (copy1) to [out=0,in=180] (X) (L) -- (W);
    \end{tikzpicture}\\
    &= \begin{tikzpicture}[baseline={([yshift=-.2ex]current bounding box.center)}] \path (0,0) node (IKdd) {$\RV{I}_{K\cdot\cdot}$}
        + (0,-0.4) node (IKLd) {$\RV{I}_{KL\cdot}$}
        + (0,-0.8) node (IdLd) {$\RV{I}_{\cdot L \cdot}$}
        + (0,-1.2) node (IKdJ) {$\RV{I}_{K\cdot J}$}
        + (0,-1.6) node (IKLJ) {$\RV{I}_{KLJ}$}
        + (0,-2) node (IdLJ) {$\RV{I}_{\cdot LJ}$}
        + (0,-2.4) node (IddJ) {$\RV{I}_{\cdot\cdot J}$}
        + (0.7,-0.4) node[copymap] (copyKL) {}
        + (0.7,-1.2) node[copymap] (copyKJ) {}
        + (0.7,-1.6) node[copymap] (copyKLJ) {}
        + (0.7,-2) node[copymap] (copyLJ) {}
        ++ (1.5,-0.3) node[kernel,inner sep=5pt] (K) {$\kernel{K}$}
        ++ (1.2,0.15) node[copymap] (copyOKL) {}
        +  (0,-0.3) node[copymap] (copyOKJ) {}
        + (0,-0.45) node[copymap] (copyOKLJ) {}
        ++ (1.2,-0.9) node[kernel,inner sep=6pt] (L) {$\kernel{L}$}
        ++ (1.2,-0.15) node[copymap] (copyOLJ) {}
        ++ (1.2,-0.9) node[kernel,inner sep=6pt] (J) {$\kernel{J}$}
        ++ (2.1, 2.1) node (OKdd) {$\RV{O}_{K\cdot\cdot}$}
        + (0,-0.4) node (OKLd) {$\RV{O}_{KL\cdot}$}
        + (0,-0.8) node (OKdJ) {$\RV{O}_{K\cdot J}$}
        + (0,-1.2) node (OKLJ) {$\RV{O}_{KLJ}$}
        + (0,-1.6) node (OLd) {$\RV{O}_{L\cdot}$}
        + (0,-2) node (OLJ) {$\RV{O}_{LJ}$}
        + (0,-2.4) node (OJ) {$\RV{O}_{J}$};
        \draw (IKdd) to [out=0,in=180] ($(K.west) + (0,0.25)$) ($(K.east) + (0,0.25)$) to [out=0,in=180] (OKdd);
        \draw (IKLd) -- (copyKL) to [out=-45,in=180] ($(L.west) + (0,0.1)$) (copyKL) to [out=55,in=180] ($(K.west) + (0,0.125)$)
        ($(K.east)+(0,0.125)$) to [out=0,in=180] (copyOKL) to [out=-90,in=180] ($(L.west) + (0,0.3)$)
        (copyOKL) to [out=0,in=180] (OKLd);
        \draw (IKLJ) to [out=0,in=180] (copyKLJ) to [out=40,in=180] ($(K.west) + (0,-0.25)$) 
        (copyKLJ) to [out=10,in=180] ($(L.west) + (0,0)$)
        (copyKLJ) to [out=-25,in=180] ($(J.west) + (0,-0.2)$);
        \draw (IKdJ) to [out=0,in=180] (copyKJ) to [out=65,in=180] ($(K.west) + (0,-0.125)$)
        (copyKJ) to [out=-30,in=180] ($(J.west) + (0,-0.1)$);
        \draw (IdLd) to [out=0,in=160] ($(IdLd)+(0.8,-0.1)$) to [out=-20,in=180] ($(L.west)+(0,-0.1)$);
        \draw (IdLJ) to [out=0,in=180] (copyLJ) to[out=15,in=180] ($(L.west)+(0,-0.2)$)
        (copyLJ) to [out=-10,in=180] ($(J.west) + (0,0.)$);
        \draw (IddJ) to [out=0,in=180] ($(IddJ)+ (0.5,0)$) to [out=-15,in=180] ($(J.west) + (0,-0.3)$);
        \draw ($(K.east)+(0,-0.125)$) to (copyOKJ) to [out=-75,in=180] ($(J.west) + (0,0.2)$)
        (copyOKJ) to [out=0,in=180] (OKdJ)
        (copyOKLJ) to [out=-80,in=180] ($(J.west) + (0,0.1)$);
        \draw ($(K.east) + (0,-0.25)$) to [out=0,in=180] (copyOKLJ) to [out=0,in=180] (OKLJ)
        (copyOKLJ) to [out=-35,in=180] ($(L.west) + (0,0.2)$);
        \draw ($(L.east) + (0,0.2)$) to [out=0,in=180] (OLd)
        ($(L.east) + (0,0)$) to [out=0,in=170] (copyOLJ) to [out=-10,in=180] (OLJ)
        (copyOLJ) to [out=-45,in=180] ($(J.west) + (0,0.3)$);
        \draw (J) to [out=0,in=180] (OJ);
    \end{tikzpicture}\\
    &\overset{perm}{=} \begin{tikzpicture}[baseline={([yshift=-.2ex]current bounding box.center)}] \path (0,0) node (IKdd) {$\RV{I}_{K\cdot\cdot}$}
        + (0,-0.4) node (IKLd) {$\RV{I}_{KL\cdot}$}
        + (0,-0.8) node (IKdJ) {$\RV{I}_{K\cdot J}$}
        + (0,-1.2) node (IKLJ) {$\RV{I}_{KLJ}$}
        + (0,-1.6) node (IdLd) {$\RV{I}_{\cdot L \cdot}$}
        + (0,-2) node (IdLJ) {$\RV{I}_{\cdot LJ}$}
        + (0,-2.4) node (IddJ) {$\RV{I}_{\cdot\cdot J}$}
        + (0.7,-0.4) node[copymap] (copyKL) {}
        + (0.7,-.8) node[copymap] (copyKJ) {}
        + (0.7,-1.2) node[copymap] (copyKLJ) {}
        + (0.7,-2) node[copymap] (copyLJ) {}
        ++ (1.5,-0.3) node[kernel,inner sep=5pt] (K) {$\kernel{K}$}
        ++ (1.2,0.15) node[copymap] (copyOKL) {}
        +  (0,-0.3) node[copymap] (copyOKJ) {}
        + (0,-0.45) node[copymap] (copyOKLJ) {}
        ++ (1.2,-0.9) node[kernel,inner sep=6pt] (L) {$\kernel{L}$}
        ++ (1.2,-0.15) node[copymap] (copyOLJ) {}
        ++ (1.2,-0.9) node[kernel,inner sep=6pt] (J) {$\kernel{J}$}
        ++ (2.1, 2.1) node (OKdd) {$\RV{O}_{K\cdot\cdot}$}
        + (0,-0.4) node (OKLd) {$\RV{O}_{KL\cdot}$}
        + (0,-0.8) node (OKdJ) {$\RV{O}_{K\cdot J}$}
        + (0,-1.2) node (OKLJ) {$\RV{O}_{KLJ}$}
        + (0,-1.6) node (OLd) {$\RV{O}_{L\cdot}$}
        + (0,-2) node (OLJ) {$\RV{O}_{LJ}$}
        + (0,-2.4) node (OJ) {$\RV{O}_{J}$};
        \draw (IKdd) to [out=0,in=180] ($(K.west) + (0,0.25)$) ($(K.east) + (0,0.25)$) to [out=0,in=180] (OKdd);
        \draw (IKLd) -- (copyKL) to [out=-45,in=180] ($(L.west) + (0,0.1)$) (copyKL) to [out=55,in=180] ($(K.west) + (0,0.125)$)
        ($(K.east)+(0,0.125)$) to [out=0,in=180] (copyOKL) to [out=-90,in=180] ($(L.west) + (0,0.3)$)
        (copyOKL) to [out=0,in=180] (OKLd);
        \draw (IKLJ) to [out=0,in=180] (copyKLJ) to [out=40,in=180] ($(K.west) + (0,-0.25)$) 
        (copyKLJ) to [out=10,in=180] ($(L.west) + (0,0)$)
        (copyKLJ) to [out=-25,in=180] ($(J.west) + (0,-0.2)$);
        \draw (IKdJ) to [out=0,in=180] (copyKJ) to [out=65,in=180] ($(K.west) + (0,-0.125)$)
        (copyKJ) to [out=-30,in=180] ($(J.west) + (0,-0.1)$);
        \draw (IdLd) to [out=0,in=180] ($(L.west)+(0,-0.1)$);
        \draw (IdLJ) to [out=0,in=180] (copyLJ) to[out=15,in=180] ($(L.west)+(0,-0.2)$)
        (copyLJ) to [out=-10,in=180] ($(J.west) + (0,0.)$);
        \draw (IddJ) to [out=0,in=180] ($(IddJ)+ (0.5,0)$) to [out=-15,in=180] ($(J.west) + (0,-0.3)$);
        \draw ($(K.east)+(0,-0.125)$) to (copyOKJ) to [out=-75,in=180] ($(J.west) + (0,0.2)$)
        (copyOKJ) to [out=0,in=180] (OKdJ)
        (copyOKLJ) to [out=-80,in=180] ($(J.west) + (0,0.1)$);
        \draw ($(K.east) + (0,-0.25)$) to [out=0,in=180] (copyOKLJ) to [out=0,in=180] (OKLJ)
        (copyOKLJ) to [out=-35,in=180] ($(L.west) + (0,0.2)$);
        \draw ($(L.east) + (0,0.2)$) to [out=0,in=180] (OLd)
        ($(L.east) + (0,0)$) to [out=0,in=170] (copyOLJ) to [out=-10,in=180] (OLJ)
        (copyOLJ) to [out=-45,in=180] ($(J.west) + (0,0.3)$);
        \draw (J) to [out=0,in=180] (OJ);
    \end{tikzpicture}\\
    &= \begin{tikzpicture}[baseline={([yshift=-.2ex]current bounding box.center)}]
        \path (0,0) node (Y) {$\RV{I}_{K\cdot}$}
        + (0,-0.3) node (Q) {$\RV{I}_{KQ}$}
        + (0,-0.8) node (R) {$\RV{I}_{\cdot Q}$}
        ++ (0.5,-0.3) node[copymap] (copy0) {}
        ++ (0.5,0.15) node[kernel] (K) {$\kernel{K}$}
        ++ (0.5,-0.15) node[copymap] (copy1) {}
        ++ (0.6,-0.5) node[kernel] (L) {$\kernel{Q}$}
        ++ (0.6, 0.8) node (Z) {$\RV{O}_{K\cdot}$}
        + (0,-0.3) node (X) {$\RV{O}_{KQ}$}
        + (0,-0.8) node (W) {$\RV{O}_Q$};
        \draw (Y) -- ($(K.west) + (0,0.15)$) (Q) -- ($(K.west) + (0,-0.15)$);
        \draw (copy0) to [out=-45,in=180] ($(L.west) + (0,0)$) (copy1) to [out=-60,in=180] ($(L.west) + (0,0.15)$);
        \draw (R) to [out=0,in=180] ($(L.west) + (0,-0.15)$);
        \draw ($(K.east) + (0,-0.15)$) to (copy1);
        \draw ($(K.east) + (0,0.15)$) -- (Z) (copy1) to [out=0,in=180] (X) (L) -- (W);
    \end{tikzpicture}\\
    &= \kernel{K}\rightrightarrows (\kernel{L}\rightrightarrows \kernel{J})
\end{align}

\section{Appendix: String Diagram Examples}

Recall the definition of \emph{connection}:
\begin{definition}[Connection]
\begin{align}
    \kernel{K}\rightrightarrows \kernel{L} &:=  \begin{tikzpicture}[baseline={([yshift=-.2ex]current bounding box.center)}]
        \path (0,0) node (Y) {$\RV{I}_{F\cdot}$}
        + (0,-0.3) node (Q) {$\RV{I}_{FS}$}
        + (0,-0.8) node (R) {$\RV{I}_{\cdot S}$}
        ++ (0.5,-0.3) node[copymap] (copy0) {}
        ++ (0.5,0.15) node[kernel] (K) {$\kernel{K}$}
        ++ (0.5,-0.15) node[copymap] (copy1) {}
        ++ (0.6,-0.5) node[kernel] (L) {$\kernel{L}$}
        ++ (0.6, 0.8) node (Z) {$\RV{O}_{F\cdot}$}
        + (0,-0.3) node (X) {$\RV{O}_{FS}$}
        + (0,-0.8) node (W) {$\RV{O}_S$};
        \draw (Y) -- ($(K.west) + (0,0.15)$) (Q) -- ($(K.west) + (0,-0.15)$);
        \draw (copy0) to [out=-45,in=180] ($(L.west) + (0,0)$) (copy1) to [out=-60,in=180] ($(L.west) + (0,0.15)$);
        \draw (R) to [out=0,in=180] ($(L.west) + (0,-0.15)$);
        \draw ($(K.east) + (0,-0.15)$) to (copy1);
        \draw ($(K.east) + (0,0.15)$) -- (Z) (copy1) to [out=0,in=180] (X) (L) -- (W);
    \end{tikzpicture}\label{eq:extn_definition1}\\
    &:= \kernel{J}\\
    \kernel{J}_{yqr}^{zxw} &= \kernel{K}_{yq}^{zx} \kernel{L}_{xqr}^{w}\label{eq:extn_definition2}
\end{align}
\end{definition}

Equation \ref{eq:extn_definition1} can be broken down to the product of four Markov kernels, each of which is itself a tensor product of a number of other Markov kernels:
\begin{align}
    (\kernel{J},(\RV{I}_{F\cdot},\RV{I}_{FS},\RV{I}_{\cdot S}), (\RV{O}_{F\cdot},\RV{O}_{FS},\RV{O}_S)) &= \left[ \begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
        \path (0,0) node (Y) {$\RV{I}_{F\cdot}$}
        + (0,-0.3) node (Q) {$\RV{I}_{FS}$}
        + (0,-0.75) node (R) {$\RV{I}_{\cdot S}$}
        ++ (0.5,-0.3) node[copymap] (copy1) {}
        ++ (0.5,0.3) node (Z) {}
        ++ (0,-0.15) node (Q1) {}
        ++ (0,-0.3) node (Q2) {}
        ++ (0,-0.3) node (R2) {};
        \draw (Y) -- (Z) (Q) -- (copy1) to [out=45,in=180] (Q1);
        \draw (copy1) to [out=-45,in=180] (Q2);
        \draw (R) -- (R2); \end{tikzpicture}\right]
        \left[\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
        \path (0,0)  node (Z) {}
        ++ (0,-0.15) node (Q1) {}
        ++ (0,-0.3) node (Q2) {}
        ++ (0,-0.3) node (R) {}
        ++ (0.5,0.65) node[kernel] (K) {$\model{K}$}
        ++ (0.5,0.1) node (Z1) {}
        +  (0,-0.15) node (W) {}
        + (0,-0.45) node (Q3) {}
        + (0,-0.75) node (R2) {};
        \draw (Z) -- ($(K.west) + (0,0.1)$) (Q1) -- ($(K.west) + (0,-0.05)$);
        \draw (Q2) -- (Q3) (R) -- (R2) ($(K.east) + (0,0.1)$) -- (Z1); 
        \draw ($(K.east) + (0,-0.05)$) -- (W);\end{tikzpicture}\right] 
        \left[ \begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
        \path (0,0) node (Z) {}
        + (0,-0.15) node (X) {}
        + (0,-0.45) node (Q) {}
        + (0,-0.75) node (R) {}
        ++ (0.5,-0.3) node[copymap] (copy1) {}
        ++ (0.5,0.3) node (Z1) {}
        ++ (0,-0.15) node (X1) {}
        ++ (0,-0.3) node (X2) {}
        ++ (0,-0.15) node (Q2) {}
        ++ (0,-0.15) node (R2) {};
        \draw (Z) -- (Z1) (X) to [out=0,in=180] (copy1) to [out=45,in=180] (X1);
        \draw (copy1) to [out=-45,in=180] (X2);
        \draw (Q) to [out=0,in=180] (Q2);
        \draw (R) -- (R2); \end{tikzpicture}\right]
        \left[\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
        \path (0,0) node (Z) {}
        ++ (0,-0.15) node (X1) {}
        ++ (0,-0.3) node (X2) {}
        ++ (0,-0.15) node (Q) {}
        ++ (0,-0.15) node (R) {}
        ++ (0.5,0.15) node[kernel] (L) {$\model{L}$}
        ++ (0.7,0) node (W) {$\RV{O}_{F\cdot}$}
        ++ (0,0.35) node (X3) {$\RV{O}_{FS}$}
        ++ (0,0.25) node (Z1) {$\RV{O}_S$};
        \draw (X1) to [out=0,in=180] (X3) (Z) -- (Z1);
        \draw (X2) to [out=0,in=180] ($(L.west) + (0,0.15)$);
        \draw (Q) to [out=0,in=180] ($(L.west) + (0,0)$);
        \draw (R) to [out=0,in=180] ($(L.west) + (0,-0.15)$);
        \draw (L) -- (W);\end{tikzpicture}\right]\\
\end{align}

\section{Markov variable maps and variables form a Markov category}\label{sec:app_mcat}

In the following, given \emph{arbitrary measurable sets} $(X,\sigalg{X})$ and $(Y,\sigalg{Y})$, a Markov kernel is a function $\kernel{K}:X\times\sigalg{Y}\to [0,1]$ such that

\begin{itemize}
    \item For every $A\in \sigalg{Y}$, the function $x\mapsto \kernel{K}(x,A)$ is $\sigalg{X}$-measurable
    \item For every $x\in X$, the function $A\mapsto \kernel{K}(x,A)$ is a probability measure on $(Y,\sigalg{Y})$
\end{itemize}

Note that this is a more general definition than the one used in the main paper; the version in the main paper is the restriction of this definition to finite sets.

The \emph{delta function} $\delta:X\to\Delta(\sigalg{X})$ is the Markov kernel defined by
\begin{align}
    \delta(x,A) = \begin{cases}
        1 & x\in A\\
        0 & \text{otherwise}
    \end{cases}
\end{align}

\citet{fritz_synthetic_2020} defines Markov categories in the following way:

\begin{definition}
A Markov category $C$ is a symmetric monoidal category in which every object $X \in C$ is equipped with a commutative comonoid structure given by a comultiplication $\text{copy}_X : X\to X\otimes X$ and a counit $\text{del}_X : X \to I$, depicted in string diagrams as
\begin{align}
    \text{del}_X&:=\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
    \path (0,0) ++ (1,0) node (B) {};
    \draw[-{Rays[n=8]}] (A) -- (B);
\end{tikzpicture}
    \text{copy}_X&:=\begin{tikzpicture}[baseline={([yshift=-.5ex]current bounding box.center)}]
    \path (0,0) node (A) {} 
    ++ (0.5,0) node[copymap] (copy0) {}
    ++ (0.5,0.15) node (B) {}
    + (0,-0.3) node (C) {};
    \draw (A) -- (copy0) to [out=45,in=180] (B) (copy0) to [out=-45, in=180] (C);
\end{tikzpicture}
\end{align}
and satisfying the commutative comonoid equations
\begin{align}
    \tikzfig{ccom_lhs} = \tikzfig{ccom_rhs}\label{eq:ccom_1}
\end{align}
\begin{align}
    \tikzfig{ccom2_lhs} = \tikzfig{ccom2_mhs} = \tikzfig{ccom2_rhs}
\end{align}
\begin{align}
    \tikzfig{ccom3_lhs} = \tikzfig{ccom3_rhs}
\end{align}
as well as compatibility with the monoidal structure
\begin{align}
    \tikzfig{mstruct1_lhs} &= \tikzfig{mstruct1_rhs}\\
    \tikzfig{mstruct2_lhs} &= \tikzfig{mstruct2_rhs}
\end{align}
and the naturality of \emph{del}, which means that
\begin{align}
    \tikzfig{naturality_lhs} &= \tikzfig{naturality_rhs}\label{eq:nat}
\end{align}
for every morphism $f$.
\end{definition}

The category of labeled Markov kernels is the category consisting of labeled measurable sets as objects and labeled Markov kernels as morphisms. Given $\kernel{K}:\RV{X}\to \Delta(\RV{Y})$ and $\kernel{L}:\RV{Y}\to \Delta(\RV{Z})$, sequential composition is given by

\begin{align}
    \kernel{K}\kernel{L}:\RV{X}\to \Delta(\RV{Z})\\
    \text{defined by } (\kernel{KL})(x,A) = \int_Y \kernel{L}(y,A)\kernel{K}(x,dy)
\end{align}

For $\kernel{K}:\RV{X}\to \Delta(\RV{Y})$ and $\kernel{L}:\RV{W}\to\Delta(\RV{Z})$, parallel composition is given by

\begin{align}
    \kernel{K}\otimes\kernel{L}: (\RV{X},\RV{W}) &\to \Delta(\RV{Y},\RV{Z})\\
    \text{defined by } \kernel{K}\otimes\kernel{L}(x,w,A\times B) = \kernel{K}(x,A)\kernel{L}(w,B)
\end{align}

The identity map is

\begin{align}
    \text{Id}_{\RV{X}}: \RV{X}&\to\Delta(\RV{X})\\
    \text{defined by} (\text{Id}_X) (x,A) &= \delta(x,A)
\end{align}

We take an arbitrary single element labeled set $I=(*,\{*\})$ to be the unit, which we note satisfies $I\otimes X=X\otimes I=X$ by Lemma \ref{lem:se_id}.

The swap map is given by

\begin{align}
    \text{swap}_{\RV{X},\RV{Y}}: (\RV{X},\RV{Y})&\to \Delta(\RV{Y},\RV{X})\\
    \text{defined by} (\text{swap}_{\RV{X},\RV{Y}})(x,y,A\times B) &= \delta(x,B)\delta(y,A)
\end{align}

And we use the standard associativity isomorphisms for Cartesian products such that $(A\times B)\times C\cong A\times (B\times C)$, which in turn implies $(\RV{X},(\RV{Y},\RV{Z}))\cong ((\RV{X},\RV{Y}),\RV{Z})$.

The copy map is given by

\begin{align}
    \text{copy}_{\RV{X}}: \RV{X}&\to \Delta(\RV{X},\RV{X})\\
    \text{defined by} (\text{copy}_X)(x,A\times B) &= \delta_x(A)\delta_x(B)
\end{align}

and the erase map by

\begin{align}
    \text{del}_{\RV{X}}: \RV{X}&\to \Delta(*)\\
    \text{defined by} (\text{del}_X)(x,A) &= \delta(*,A)\\
\end{align}

Note that the category formed by taking the underlying unlabeled sets and the underlying unlabeled morphisms is identical to the category of measurable sets and Markov kernels described in \citet{fong_causal_2013,cho_disintegration_2019,fritz_synthetic_2020}.

\begin{theorem}[The category of labeled Markov kernels and labeled measurable sets is a Markov category]
The category described above is a Markov category.
\end{theorem}

\begin{proof}

\todo[inline]{I'm not sure how to formally argue that it is monoidal and symmetric as the relevant texts I've checked all gloss over the functors with respect to which the relevant isomorphisms should be natural, but labels with products were intentionally made to act just like sets with cartesian products which are symmetric monoidal}

Equations \ref{eq:ccom_1} to \ref{eq:nat} are known to be satisfied for the underlying unlabeled Markov kernels. We need to show is that they hold given our stricter criterion of labeled Markov kernel equality; that the underlying kernels \emph{and the label sets} match. It is sufficient to check the label sets only.



\end{proof}