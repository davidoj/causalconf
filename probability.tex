%!TEX root = main.tex


\section{Probability prerequisites}\label{sec:vague_variables}

\todo[inline]{Notation table, including iverson bracket}

\subsection{Variables}

Our definition of variables is very similar to the standard definition given in many statistics textbooks. Suppose we have a measurement procedure where we interact with the real world somehow, and from this interaction we end up with a vector of numbers. Once we have this vector, we can apply functions to it -- project the first element, add the first to the second and so forth. We say that the set of elements that the measurement process can give, along with a $\sigma$-algebra of events, $(\Omega,\sigalg{F})$ is the \emph{sample space} associated with the measurement procedure, and each measurable function $f:\Omega\to Y$ for some measurable $(Y,\sigalg{Y})$ is a \emph{variable}. The measurement procedure plays the crucial role of translating the real world into numbers that we can operate on mathematically, and a \emph{model} is a probability measure on $(\Omega,\sigalg{F})$ that represents in the world of mathematics our understanding of the real world things addressed by the measurement process.

However, we assume here that we're actually interested in constructing models to help us make decisions. We consider this means we have a set of available choices $C$, and with each $\alpha\in C$ we may have a \emph{different} measurement procedure, though we hold that they all yield values in the same sample space $(\Omega,\sigalg{F})$. With each measurement procedure, we suppose we have a probability measure $\prob{P}_\alpha$ on $(\Omega,\sigalg{F})$, so all together we have a probability function $\alpha\mapsto \prob{P}_\alpha$. We are particularly interested in the set of all of the probability measures $\prob{P}_C:\{\prob{P}_\alpha|\alpha\in C\}$ -- anything that is true of every element of this set is true regardless of what we ultimately decide.

With probability sets we can define \emph{uniform conditional distributions} (Definition \ref{def:cprob_pset}) and \emph{extended conditional independence} (Definition \ref{def:eci}; see also \citet{constantinou_extended_2017}) which are similar but not identical to standard notions of conditional distributions and conditional independence.

Section \ref{sec:standard_prob} introduces standard probability theory, Section \ref{sec:string_diagrams} introduces the string diagram notation that we use to represent Markov kernels (or probabilistic functions) and Section \ref{sec:probability_sets} introduces additional theory specific to probability sets.

\subsection{Other decision theoretic causal models}

There have been a number of formalisations of decision theoretic foundations of causal inference. All share the feature that there is a basic set of choices/interventions/regimes that may be chosen from, and a probability distribution is associated with each element of this set, so they all induce probability sets. 

\citet{lattimore_causal_2019} and \citet{lattimore_replacing_2019} describe a method for reformulating causal Bayesian networks as a set of probability distributions indexed by an intervention set $T$. Their algorithm \emph{CausalBayesConstruct} is a method for translating directly from causal Bayesian networks with a specification of interventions to probability sets.

A key feature of the \emph{CausalBayesConstruct} algorithm is that every probability distribution in the set can be represented as a product of the same set of conditional probabilities - clearly, these must be uniform conditional probabilities. We posit, therefore, that d-separation in probabilistic graphical models corresponds to \emph{uniform conditional independence} given in Definition \ref{def:eci}, on the basis of Theorem \ref{th:uci_rep}.

An alternative decision theoretic foundation has been developed in \citet{dawid_decision-theoretic_2020,dawid_beware_2010,dawid_causal_2000}. A key contribution of this literature is the notion of extended conditional independence (formally described in \citet{constantinou_extended_2017}, see Section \ref{sec:eci}), and its application to probability sets. Many common causal models have been described as probability sets in which certain extended conditional independence statements hold. A second contribution of \citet{dawid_decision-theoretic_2020} is to develop a lower level justification for the use of probability sets modelling ``generic variables'' that appears in earlier work. Our work is an extension of this latter investigation.

\citet{heckerman_decision-theoretic_1995} also explore a decision theoretic approach to causal inference. Their approach differs from the previous two in two ways: first, they posit a set of choices and a set of unobserved states, and consider models that map $\mathrm{States}\times\mathrm{Choices}\to \mathrm{Outcomes}$, instead of mapping choices only to outcomes. Secondly, they consider only deterministic maps rather than general probability distribution valued maps. This approach is based on the decision theory of \citet{savage_foundations_1954}. They consider an alternative ``conditional independence-like'' property of these models that they call \emph{limited unresponsiveness}.


\subsection{Standard probability theory}\label{sec:standard_prob}

\begin{definition}[Measurable space]
A measurable space $(X,\sigalg{X})$ is a set $X$ along with a $\sigma$-algebra of subsets $\sigalg{X}$.
\end{definition}

We use a number of shorthands for measurable spaces:
\begin{itemize}
	\item Where the choice of $\sigma$-algebra is unambiguous, we will just use the set name $X$ to refer to $X$ along with a $\sigma$-algebra $\sigalg{X}$
	\item For a discrete set $X$, the sigma-algebra $\sigalg{X}$ referred to with the same letter is the discrete sigma-algebra
	\item For a continuous set $X$, the sigma-algebra $\sigalg{X}$ referred to with the same letter is the Borel sigma-algebra
\end{itemize}

\begin{definition}[Probability measure]
Given a measurable space $(X,\sigalg{X})$, a probability measure is a $\sigma$-additive function $\mu:\sigalg{X}\to [0,1]$ such that $\mu(\emptyset)=0$ and $\mu(X)=1$. We write $\Delta(X)$ for the set of all probability measures on $(X,\sigalg{X})$.
\end{definition}

\begin{definition}[Markov kernel]\label{def:mkern}
Given measurable spaces $(X,\sigalg{X})$ and $(Y,\sigalg{Y})$, a Markov kernel $\prob{Q}:X\kto Y$ is a map $Y\times \sigalg{X}\to [0,1]$ such that
\begin{enumerate}
	\item $y\mapsto \prob{Q}(A|y)$ is $\sigalg{Y}$-measurable for all $A\in \sigalg{X}$
	\item $A\mapsto \prob{Q}(A|y)$ is a probability measure on $(X,\sigalg{X})$ for all $y\in Y$
\end{enumerate}
\end{definition}

\begin{definition}[Delta measure]
Given a measurable space $(X,\sigalg{X})$ and $x\in X$, $\delta_x\in \Delta(X)$ is the measure defined by $\delta_x(A):=\llbracket x\in A \rrbracket$ for all $A\in \sigalg{X}$
\end{definition}

\begin{definition}[Probability space]
A probability space is a triple $(\mu,\Omega,\sigalg{F})$, where $\mu$ is a base measure on $\sigalg{F}$ and $(\Omega,\sigalg{F})$ is a measurable space.
\end{definition}

\begin{definition}[Variable]
Given a measurable space $(\Omega,\sigalg{F})$ and a measurable space of values $(X,\sigalg{X})$, an \emph{$X$-valued variable} is a measurable function $\RV{X}:(\Omega,\sigalg{F})\to (X,\sigalg{X})$.
\end{definition}

\begin{definition}[Sequence of variables]
Given a measurable space $(\Omega,\sigalg{F})$ and two variables $\RV{X}:(\Omega,\sigalg{F})\to (X,\sigalg{X})$, $\RV{Y}:(\Omega,\sigalg{F})\to (Y,\sigalg{Y})$, $(\RV{X},\RV{Y}):\Omega\to X\times Y$ is the variable $\omega\mapsto (\RV{X}(\omega),\RV{Y}(\omega))$.
\end{definition}

\begin{definition}[Marginal distribution with respect to a probability space]\label{def:pushforward}
Given a probability space $(\mu,\Omega,\sigalg{F})$ and a variable $\RV{X}:\Omega\to (X,\sigalg{X})$, we can define the \emph{marginal distribution} of $\RV{X}$ with respect to $\mu$, $\mu^{\RV{X}}:\sigalg{X}\to [0,1]$ by $\mu^{\RV{X}}(A):=\mu(\RV{X}^{-1}(A))$ for any $A\in \sigalg{X}$.
\end{definition}

\begin{definition}[Distribution-kernel products]
Given $(X,\sigalg{X})$, $(Y,\sigalg{Y})$ a probability distribution $\mu\in \Delta(X)$ and a Markov kernel $\kernel{K}:X\kto Y$, $\mu\kernel{K}$ is a probability distribution on $(Y,\sigalg{Y})$ defined by
\begin{align}
	\mu\kernel{K}(A):= \int_{X} \kernel{K}(A|x)\mu(\mathrm{d}x)
\end{align}
for all $A\in \sigalg{Y}$.
\end{definition}

\begin{definition}[Kernel-kernel products]
Given $(X,\sigalg{X})$, $(Y,\sigalg{Y})$, $(Z,\sigalg{Z})$ and Markov kernels $\kernel{K}:X\kto Y$ and $\kernel{L}:Y\kto Z$, $\kernel{K}\kernel{L}$ is a Markov kernel $X\kto Z$ defined by
\begin{align}
	\kernel{K}\kernel{L}(A|x):= \int_{Y} \kernel{L}(A|y)\kernel{K}(\mathrm{d}y|x)
\end{align}
for all $A\in \sigalg{Z}$.
\end{definition}

\begin{lemma}[Marginal distribution as a kernel product]\label{lem:pushf_kprod}
Given a probability space $(\mu,\Omega,\sigalg{F})$ and a variable $\RV{X}:\Omega\to (X,\sigalg{X})$, define $\kernel{F}_{\RV{X}}:\Omega\kto X$ by $\kernel{F}_{\RV{X}}(A|\omega)=\delta_{\RV{X}(\omega)}(A)$, then
\begin{align}
	\mu^{\RV{X}} = \mu\kernel{F}_{\RV{X}}
\end{align}
\end{lemma}

\begin{proof}
Consider any $A\in \sigalg{X}$.
\begin{align}
	\mu \kernel{F}_{\RV{X}}(A) &= \int_\Omega \delta_{\RV{X}(\omega)}(A) \mathrm{d}\mu(\omega)\\
	&= \int_{\RV{X}^{-1}(\omega)} \mathrm{d}\mu(\omega)\\
	&= \mu^{\RV{X}}(A)
\end{align}
\end{proof}

\begin{definition}[Conditional distribution]\label{def:disint}
Given a probability space $(\mu,\Omega,\sigalg{F})$ and variables $\RV{X}:\Omega\to X$, $\RV{Y}:\Omega\to Y$, the conditional distribution of $\RV{Y}$ given $\RV{X}$ is any Markov kernel $\mu^{\RV{Y}|\RV{X}}:X\kto Y$ such that
\begin{align}
	\mu^{\RV{XY}}(A\times B)&=\int_{A} \mu^{\RV{Y}|\RV{X}}(B|x) \mathrm{d}\mu^{\RV{X}}(x) &\forall A\in \sigalg{X}, B\in \sigalg{Y}\\
	&\iff\\
	\mu^{\RV{XY}}&= \tikzfig{disint_def}\label{eq:conditional} 
\end{align}
\end{definition}


% \subsection{Not quite standard probability theory}

% Instead of having probability distributions and Markov kernels as two different kinds of thing, we can identify probability distributions with Markov kernels whose domain is a one element set $\{*\}$. This will prove useful in further developments, as it means that we can treat probability distributions and Markov kernels as different varieties of the same kind of thing.

% \begin{definition}[Probability measures as Markov kernels]
% Given a measurable space $(X,\sigalg{X})$ and $\mu\in \Delta(X)$, the Markov kernel $\kernel{K}:\{*\}\kto X$ associated with $\mu$ is given by $\kernel{K}(A|*)=\mu(A)$ for all $A\in \sigalg{X}$.
% \end{definition}

% We will use probability measures and their associated Markov kernels interchangeably, as it is transparent how to get from one to another.

% Conditional probability distributions are ``Markov kernel annotated with variables''.


% We define higher order conditionals as ``conditionals of conditionals''.

