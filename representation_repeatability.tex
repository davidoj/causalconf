%!TEX root = main.tex

\section{When do response conditionals exist?}

\todo[inline]{Lemmas are intermediate steps}

Our approach is to model decision problems with probability sets $\prob{P}_C$ for some set of choices $C$. If we have a pair of variables $\RV{X}$ and $\RV{Y}$ such that $\prob{P}_C^{\RV{Y}|\RV{X}}$ exists, then the model says that the joint outcome $\prob{P}_\alpha^{\RV{XY}}$ of any choice $\alpha\in C$ can be computed from the marginal distribution $\prob{P}_\alpha^{\RV{X}}$ alone. We are going to ask the question: in which kind of probability sets do uniform conditionals of the form $\prob{P}_C^{\RV{Y}|\RV{X}\RV{H}}$ exist? Here $\RV{H}$ is a ``fixed but unknown'' hypothesis that becomes better known as more data is observed. Roughly speaking, $\prob{P}_C^{\RV{Y}|\RV{X}\RV{H}}$ represents the response of $\RV{Y}$ to $\RV{X}$ regardless of which choice is made.

A decision makers may be interested in a functions like $\prob{P}_C^{\RV{Y}|\RV{X}\RV{H}}$. Suppose they have substantial prior knowledge about how to control $\RV{X}$, less knowledge about controlling $\RV{Y}$ and access to a sequence of data points. If the data points can identify $\RV{H}$, then  If a decision maker has prior knowledge of how to control $\RV{X}$ and data that is informative about the value of $\RV{H}$, these pieces of knowledge together can help them to control $\RV{Y}$. We call a uniform conditional of the form $\prob{P}_C^{\RV{Y}|\RV{X}\RV{H}}$ a \emph{response conditional}.

If a model $\prob{P}_C$ supports $\prob{P}_C^{\RV{Y}|\RV{XH}}$, it also provides an answer to the concerns of HernÃ¡n and Taubman. Paraphrasing their argument without the use of potential outcomes: they were concerned that there may be different ways to achieve particular values or distributions over $\RV{X}$, and these may also lead to different distributions over $\RV{Y}$. In that case, they argued that there was no well-defined causal effect of $\RV{X}$ on $\RV{Y}$. However, if $\prob{P}_C^{\RV{Y}|\RV{XH}}$ then the model describes a situation where -- once we have enough data to pin down $\RV{H}$ -- it doesn't matter any more which particular choice leads to a given distribution over $\RV{X}$.

We consider first the question of what kind of probability sets $\prob{P}_C$ support uniform conditional distributions of the form $\prob{P}_C^{\RV{Y}|\RV{XH}}$. Secondly, we consider what kind of decision procedures can be modeled by probability sets of this type.

\subsection{Sequential decision models}

In order to pose this question, we need a setting in which we expect to observe sequential data. That is, our model is a probability set $\prob{P}_C$ on sample space $(\Omega,\sigalg{F})$ such that we have variables $\RV{Y}:=(\RV{Y}_i)_{i\in M}$ (the outcome sequence) and $\RV{D}:=(\RV{D}_i)_{i\in M}$ (the action sequence) for some index set $M\subset\mathbb{N}$. We say $\RV{Y}_i$ corresponds to $\RV{D}_i$. We are specifically looking for uniform conditionals of the form $\prob{P}_C^{\RV{Y}_i|\RV{D}_i\RV{H}}$ for all $i\in M$. $\RV{H}$ here is a hypothesis, and it must be fixed with respect to different choices -- i.e. $\RV{H}\CI^e_{\prob{P}_C} C$. 

We assume a starting point that $\prob{P}_C^{\RV{Y}|\RV{D}}$ exists. This could be guaranteed, for example, if each choice $\alpha$ corresponds to a unique deterministic distribution $\prob{P}_\alpha^{\RV{D}}$ (see Example \ref{ex:choice_var}).

There are two further assumptions relevant to the existence of response conditionals. The first is \emph{exchange commutativity}. This is the condition that we get the same result from applying a swap transformation to the input of $\prob{P}_C^{\RV{Y}|\RV{D}}$ as we get from applying the same swap transformation to its output.

The second is a condition of \emph{consequence locality}. This is the assumption that, for any $A\subset M$, $\prob{P}_C^{\RV{Y}_A|\RV{D}_A}$ exists and

\begin{align}
    \prob{P}_C^{\RV{Y}_A|\RV{D}_M} &= \tikzfig{consequence_locality}
\end{align}

In the language of extended conditional independence, it is the assumption $\RV{Y}_A\CI_{\prob{P}_C}^e C\RV{D}_{M\setminus A} |\RV{D}_A$.

Exchange commutativity is similar, but not identical, to a number of assumptions discussed in the literature. \emph{Post-treatment exchangeability} found in \citet{dawid_decision-theoretic_2020} is implied by exchange commutativity, but not the reverse. There are also notions of ``causal exchangeability'' found in \citet{greenland_identifiability_1986} and \citet{banerjee_chapter_2017}; a subtle difference between these notions and exchange commutativity is that these latter notions are symmetries of \emph{procedures} -- they involve actually swapping actions or individuals in an experiment -- while exchange commutativity is a symmetry of a probability set.

Consequence locality is similar to the stable unit treatment distribution assumption (SUTDA) in \citet{dawid_decision-theoretic_2020}. It is also related to the ``no interference'' part of the stable unit treatment value assumption (SUTVA). The stable unit treatment value assumption (SUTVA) is given as \citep{rubin_causal_2005}:

\begin{blockquote}
(SUTVA) comprises two sub-assumptions. First, it assumes that \emph{there is no interference between units (Cox 1958)}; that is, neither $Y_i(1)$ nor $Y_i(0)$ is affected by what action any other unit received. Second, it assumes that \emph{there are no hidden versions of treatments}; no matter how unit $i$ received treatment $1$, the outcome that would be observed would be $Y_i(1)$ and similarly for treatment $0$.
\end{blockquote}

Both SUTDA and SUTVA talk about how an outcome $\RV{Y}_i$ does not depend on, or is not affected by, any of the actions that do not correspond to it. Such statements would need to be made more precisely if we want to evaluate what precise relation they have to consequence locality.

\todo[inline]{Put the following in the discussion of decision procedures}

It is possible to have models in which commutativity to exchange holds but locality of consequences does not. Such a situation could arise in a model of stimulus payments to individuals in a nation; if exactly $n$ payments of \$10 000 are made, we might consider that it doesn't matter much exactly who receives the payments (this is a subtle question, though, we will return to it in more detail later). However, the amount of inflation induced depends on the number of payments; making 100 such payments will have a negligible effect on inflation, while making payments to everyone in the country is likely to have a substantial effect. \citet{dawid_causal_2000} discusses condition of \emph{post-treatment exchangeability} which is similar to exchange commutativity, and there he gives the example of herd immunity in vaccination campaigns as a situation where post-treatment exchangeability holds but locality of consequences does not.

\todo[inline]{Put the preceding in the discussion of decision procedures}

\todo[inline]{Not sure if or where I want to put this, I just think it helps to illustrate the difference}

The difference between exchangeability \citep{de_finetti_foresight_1992} and exchange commutativity is illustrated by the following pair of diagrams. Exchangeability is a symmetry of probability distributions -- a distribution is exchangeable if it is unchanged by swapping outputs. Exchange commutativity is a symmetry of Markov kernels -- a Markov kernel is exchange commutative if swapping inputs and swapping outputs gives the same result.

Exchangeability (swapping labels):

\begin{align}
    \tikzfig{exchangeability}
\end{align}

Exchange commutativity (swapping choices $\sim$ swapping labels):

\begin{align}
    \tikzfig{commutativity_of_exchange}
\end{align}

\todo[inline]{----end not sure where to put------}


% Another way to see where we are going is to consider graphical statements of our and De Finetti's result.

% Take $S=\{0,1\}$ and identify the space $\Delta(S)$ of probability measures on $S$ with the interval $[0,1]$. De Finetti showed that any infinite exchangeable probability measure $\prob{P}_\alpha$ on $\{0,1\}^\mathbb{N}$ can be represented by a prior $\prob{P}_\alpha^{\RV{H}}\in [0,1]$ for some $\RV{H}:\Omega\to H$ and a conditional probability $\prob{P}^{\RV{S}_0|\RV{H}}:[0,1]\kto \{0,1\}$ such that

% \begin{align}
%     \prob{P}_\alpha &= \tikzfig{de_finetti_rep0}\label{eq:definettirep}
% \end{align}

% Here $\prob{P}^{\RV{S}_0|\RV{H}}$ can be defined concretely by $\prob{P}^{\RV{S}_0|\RV{H}}(1|h)=h$. Equivalently, the probability gap model on $S^\mathbb{N}$ defined by the assumption of exchangeability is equivalent to the probability gap model defined by the conditional probability

% \begin{align}
%     \prob{P}^{\RV{S}|\RV{H}} = \tikzfig{de_finetti_conditional}
% \end{align}

% That is, there is some hypothesis $\RV{H}$ and conditional on $\RV{H}$ the measurements are independent and identically distributed. The proof of this is constructive -- $\RV{H}$ is a function of $\RV{S}$.



% \begin{align}
%     \prob{P}^{\RV{Y}|\RV{HD}} = \tikzfig{do_model_representation}
% \end{align}

% We will further argue that the class of see-do models considered in CBN and potential outcomes literature is equivalent to the family of causally contractible and exchangeable do-models where the decision rule for the first $n$ places is fixed to an unknown value, and may be freely chosen thereafter.

% \begin{theorem}[Existence of conditional in do models]
% Given a do model $(\prob{P}_{\square}^{\RV{Y}\|\RV{D}},R)$, for all $\alpha\in R$, $n\in\mathbb{N}$
% \begin{align}
%     \prob{P}_\alpha^{\RV{Y}_{[n]}\RV{D}_i} = \prob{P}_\alpha^{\RV{D}_{[n]}}\odot \prob{P}_\square^{\RV{Y}_{[n]}\|\RV{D}_{[n]}}
% \end{align}
% That is, $\prob{P}_\square^{\RV{Y}_{[n]}\|\RV{D}_{[n]}}\cong \prob{P}_\square^{\RV{Y}_{[n]}|\RV{D}_{[n]}}$
% \end{theorem}

% \begin{proof}
% For any $n>1\in \mathbb{N}$, $\alpha\in R$

% \begin{align}
%     \prob{P}_\alpha^{\RV{Y}_{[n]}\RV{D}_{[n]}} &= \tikzfig{do_model_1}\\
%     &= \tikzfig{do_model_2}\\
%     &= \tikzfig{do_model_3}\\
%     &= \tikzfig{do_model_4}\\
%     \implies \prob{P}_\alpha^{\RV{Y}_{[n]}|\RV{D}_{[n]}} &= \tikzfig{do_model_5}\\
%     &= \prob{P}_\alpha^{\RV{Y}_{[n-1]}|\RV{D}_{[n-1]}}\combprod \prob{P}_\square^{\RV{Y}_n|\RV{Y}_{[n-1]}\RV{D}_n}
% \end{align}

% Applying this recursively with $\prob{P}_\alpha^{\RV{Y}_{[1]}|\RV{D}_{[1]}}=\prob{P}_\square^{\RV{Y}_{[1]}|\RV{D}_{[1]}}$ yields

% \begin{align}
%     \prob{P}_\alpha^{\RV{Y}_{[n]}|\RV{D}_{[n]}} = \prob{P}_\square^{\RV{Y}_{[n]}\|\RV{D}_{[n]}}
% \end{align}
% as desired.
% \end{proof}
\subsection{Causal contractibility}

Here we set out formal definitions of exchange commutativity and locality of consequences, as well as ``consequence contractibility'', which is the conjunction of both conditions.

\begin{definition}[Swap map]
Given $M\subset \mathbb{N}$ a finite permutation $\rho:M\to M$ and a variable $\RV{X}:\Omega\to X^M$ such that $\RV{X}=(\RV{X}_i)_{i\in M}$, define the Markov kernel $\text{swap}_{\rho(\RV{X})}:X^M\kto X^M$ by $(d_i)_{i\in\mathbb{N}}\mapsto \delta_{(d_{\rho(i)})_{i\in\mathbb{N}}}$.
\end{definition}

\begin{definition}[Exchange commutativity]\label{def:caus_exch}
Suppose we have a sample space $(\Omega,\sigalg{F})$ and a probability set $\prob{P}_C$ with uniform conditional probability $\prob{P}_C^{\RV{Y}|\RV{D}}$ where $\RV{Y}:=\RV{Y}:=(\RV{Y}_i)_{M}$, $\RV{D}:=\RV{D}_M:=(\RV{D}_i)_M$, $M\subseteq \mathbb{N}$. If for any finite permutation $\rho:M\to M$
\begin{align}
    \text{swap}_{\rho(\RV{D})} \prob{P}_{C}^{\RV{Y}|\RV{D}} &\overset{\prob{P}_C}{\cong} \prob{P}_{C}^{\RV{Y}|\RV{D}}\text{swap}_{\rho(\RV{Y})}
\end{align}
Then $\prob{P}_C^{\RV{Y}|\RV{D}}$ \emph{commutes with exchange}.
\end{definition}

If $\prob{P}_C^{\RV{Y}|\RV{D}}$ commutes with exchange and we have $\alpha,\alpha'\in C$ such that $\prob{P}_\alpha^{\RV{C}} = \prob{P}_{\alpha'}^{\RV{C}}\text{swap}_{\rho(\RV{D})}$, then $\prob{P}_\alpha^{\RV{Y}} = \prob{P}_{\alpha'}^{\RV{Y}}\text{swap}_{\rho(\RV{Y})}$. However, $\prob{P}_C^{\RV{Y}|\RV{D}}$ may commute with exchange even if there are no such $\alpha$ and $\alpha'\in C$.

\begin{definition}[Locality of consequences]\label{def:caus_cont}
Suppose we have a sample space $(\Omega,\sigalg{F})$ and a probability set $\prob{P}_C$ with uniform conditional probability $\prob{P}_C^{\RV{Y}|\RV{D}}$ where $\RV{Y}:=\RV{Y}:=(\RV{Y}_i)_{M}$, $\RV{D}:=\RV{D}_M:=(\RV{D}_i)_M$, $M\subseteq \mathbb{N}$. If for any $A\subset M$
\begin{align}
    \prob{P}_S^{\RV{Y}_A|\RV{D}_M} &\overset{\prob{P}_C}{\cong} \tikzfig{consequence_locality}
\end{align}
then $\prob{P}_C^{\RV{Y}|\RV{D}}$ exhibits \emph{consequence locality}.
\end{definition}

If $\prob{P}_C^{\RV{Y}|\RV{D}}$ exhibits consequence locality then,given two different choices $\alpha$ and $\alpha'$ such that $\prob{P}_\alpha^{\RV{D}_A}=\prob{P}_{\alpha'}^{\RV{D}_A}$ then $\prob{P}_\alpha^{\RV{Y}_A}=\prob{P}_{\alpha'}^{\RV{Y}_A}$. However, once again, $\prob{P}_C^{\RV{Y}|\RV{D}}$ may exhibit consequence locality even if no such pair of choices exists.

Neither condition implies the other. 

\begin{theorem}
Exchange commutativity does not imply locality of consequences or vise versa.
\end{theorem}

\begin{proof}
A conditional probability model that exhibits exchange commutativity but some choices have non-local consequences:

Suppose $D=Y=\{0,1\}$ and we have a probability set $\prob{P}_C$ with uniform conditional $\prob{P}_C^{\RV{Y}|\RV{D}}$, where $\RV{D}=(\RV{D}_1,\RV{D}_2)$, $\RV{Y}=(\RV{Y}_1,\RV{Y}_2)$.

Suppose the unique version of $\prob{P}_C^{\RV{Y}|\RV{D}}$ is
\begin{align}
    \prob{P}_C^{\RV{Y}|\RV{D}}(y_1,y_2|d_1,d_2) &= \llbracket (y_1,y_2)= (d_1+d_2,d_1+d_2) \rrbracket
\end{align}
then 
\begin{align}
    \prob{P}_C^{\RV{Y}_1|\RV{D}}(y_1|d_1,d_2) &= \llbracket y_1 = d_1+d_2 \rrbracket
\end{align}
and there is no function depending on $y_1$ and $d_1$ only that is equal to this. Thus $\prob{P}_C$ exhibits non-local consequences. 

However, taking $\rho$ to be the unique nontrivial swap $\{0,1\}\to \{0,1\}$
\begin{align}
    \text{swap}_{\rho(\RV{D})}\prob{P}_{C}^{\RV{Y}|\RV{D}}(y_1,y_2|d_1,d_2) &= \prob{P}_{C}^{\RV{Y}|\RV{D}}(y_1,y_2|d_2,d_1)\\
    &= \llbracket (y_1,y_2)= (d_2+d_1,d_2+d_1) \rrbracket\\
    &= \llbracket (y_1,y_2)= (d_1+d_2,d_1+d_2) \rrbracket\\
    &= \llbracket (y_2,y_1)= (d_1+d_2,d_1+d_2) \rrbracket\\
    &= \prob{P}_{C}^{\RV{Y}|\RV{D}}\text{swap}_{\rho(\RV{Y})}(y_1,y_2|d_1,d_2)
\end{align}
so $\prob{P}_\square$ commutes with exchange.

A conditional probability model that exhibits locality of consequences but does not commute with exchange follows. Suppose again $D=Y=\{0,1\}$ and we have a probability set $\prob{P}_C$ with uniform conditional $\prob{P}_C^{\RV{Y}|\RV{D}}$, where $\RV{D}=(\RV{D}_1,\RV{D}_2)$, $\RV{Y}=(\RV{Y}_1,\RV{Y}_2)$. This time, suppose the unique version of $\prob{P}_C^{\RV{Y}|\RV{D}}$ is
\begin{align}
    \prob{P}_C{\RV{Y}|\RV{D}}(y_1,y_2|d_1,d_2) &= \llbracket (y_1,y_2)= (0,1) \rrbracket
\end{align}

Then  If $\prob{P}_\alpha^{\RV{D}_S}=\prob{P}_\beta^{\RV{D}_S}$ for $S\subset\{0,1\}$ then:
\begin{align}
    \prob{P}_C^{\RV{Y}_1|\RV{D}}(y_1|d_1,d_2) &= \llbracket y_1= 0 \rrbracket\\
    &= \prob{P}_C^{\RV{Y}_1|\RV{D}_1}(y_1|d_1)\\
    \prob{P}_C^{\RV{Y}_2|\RV{D}}(y_2|d_1,d_2)&= \llbracket y_2= 1 \rrbracket\\
    &= \prob{P}_C^{\RV{Y}_2|\RV{D}_2}(y_2|d_2)
\end{align}
so $\prob{P}_C^{\RV{Y}|\RV{D}}$ exhibits consequence locality.

However, $\prob{P}_C$ does not commute with exchange.
\begin{align}
    \text{swap}_{\rho(\RV{D})} \prob{P}_C^{\RV{Y}|\RV{D}}(y_1,y_2|d_1,d_2) &= \prob{P}_C^{\RV{Y}|\RV{D}}(y_1,y_2|d_2,d_1)\\
    &=\llbracket (y_1,y_2)= (0,1) \rrbracket\\
    &\neq \llbracket (y_2,y_1)= (0,1) \rrbracket\\
    &= \prob{P}_C^{\RV{Y}|\RV{D}}\text{swap}_{\rho(\RV{D})}(y_1,y_2|d_1,d_2)
\end{align}
\end{proof}

Although locality of consequences has a lot in common with an assumption non-interference, it still allows for some models in which exhibit certain kinds of interference between actions and outcomes of different indices. For example: I have an experiment where I first flip a coin and record the results of this flip as the outcome of the first step of the experiment, but I can choose either to record this same outcome as the provisional result of the second step (this is the choice $\RV{D}_1=0$), or choose to flip a second coin and record the result of that as the provisional result of the second step of the experiment (this is the choice $\RV{D}_1=1$). At the second step, I may further choose to copy the provisional results ($\RV{D}_2=0$) or invert them ($\RV{D}_2=1$). Then

\begin{align}
    \prob{P}_S^{\RV{Y}_1|\RV{D}}(y_1|d_1,d_2) &= 0.5\\
    \prob{P}_S^{\RV{Y}_2|\RV{D}}(y_2|d_1,d_2) &= 0.5
\end{align}
\begin{itemize}
    \item The marginal distribution of both experiments in isolation is $\text{Bernoulli}(0.5)$ no matter what choices I make, so a model of this experiment would satisfies Definition \ref{def:caus_cont}
    \item Nevertheless, the choice for the first experiment affects the result of the second experiment
\end{itemize}

Note that this example would not satisfy exchange commutativity.

We call the conjunction of exchange commutativity and consequence locality \emph{causal contractibility}.

\begin{definition}[Causal contractibility]
A probability set $\prob{P}_C$ with uniform conditional $\prob{P}_C^{\RV{Y}|\RV{D}}$ is $(\RV{D};\RV{Y})$ causally contractible if it is both exchange commutative and exhibits consequence locality.
\end{definition}

\begin{theorem}[Equality of conditionals]\label{th:equal_of_condits}
A probability set $\prob{P}_C$ that is $(\RV{D},\RV{Y})$-causally contractible has, for any $A,B\subset M$ with $|A|=|B|$
\begin{align}
    \prob{P}_C^{\RV{Y}_A|\RV{D}_A} \overset{\prob{P}_C}{\cong} \prob{P}_C^{\RV{Y}_B|\RV{D}_B}
\end{align}

\end{theorem}

\begin{proof}
Only if:
For any $A,B\subset M$, let $\text{s}_{BA}:D^M\kto D^M$ be the swap map that sends the $B$ indices to $A$ indices and $\text{s}_{AB}:Y^M\kto Y^M$ be the swap map that sends $A$ indices to $B$ indices.
\begin{align}
    \tikzfig{consequence_locality} &= \tikzfig{contractibility_from_exchange_1}\\
    &= \tikzfig{contractibility_from_exchange_2}\\
    &= \tikzfig{contractibility_from_exchange_3}
\end{align}
Thus
\begin{align}
    \prob{P}_C^{\RV{Y}_A|\RV{D}_A\RV{D}_{M\setminus A}} &\overset{\prob{P}_C}{\cong} \prob{P}_C^{\RV{Y}_B|\RV{D}_B\RV{D}_{M\setminus B}}\\
    &\overset{\prob{P}_C}{\cong} \tikzfig{consequence_locality}\label{eq:cons_local}\\
    \implies \prob{P}_C^{\RV{Y}_A|\RV{D}_A} \overset{\prob{P}_C}{\cong} \prob{P}_C^{\RV{Y}_B|\RV{D}_B}
\end{align}
\end{proof}



% \begin{proposition}[Representation of do-models that commute with exchange]
% Suppose we have a fundamental probability set $\Omega$ and a do model $(\prob{P},\RV{D},\RV{Y},R)$ such that $\RV{D}:=(\RV{D}_i)_{i\in \mathbb{N}}$ and $\RV{Y}:=(\RV{Y}_i)_{i\in\mathbb{N}}$ where $\prob{P}$ commutes with exchange and there is some $\alpha^*\in R$ such that $\prob{P}^{\alpha^*}\gg\prob{P}_\beta$ for all $\beta in R$. Then there exists a symmetric function $\RV{H}:(Y\times D)^\mathbb{N}\to H$ such that  $\prob{P}^{\RV{Y}|\RV{DH}}$ exists and $\RV{Y}_i\CI_{\prob{P}}(\RV{D}_j,\RV{Y}_j)_{j\in \mathbb{N}}\setminus \{i\}|\RV{H}\RV{D}_i$, or equivalently 
% \begin{align}
%     \prob{P}^{\RV{Y}} &= \tikzfig{do_model_representation}
% \end{align}
% \end{proposition}

% % \begin{lemma}[Contraction and independence]
% % Let $\RV{J}$, $\RV{K}$ and $\RV{L}$ be variables on $\Omega$ and $\prob{Q}\in \Delta(\Omega)$ a base measure such that $\prob{Q}^{\RV{JK}}=\prob{Q}^{\RV{JL}}$ and $\sigma{K}\subset \sigma{L}$. Then $\RV{J}\CI\RV{L}|\RV{K}$. 
% % \end{lemma}

% % \begin{proof}
% % From Lemma 1.3 in \citet{kallenberg_basic_2005}.
% % \end{proof}

% \begin{proof}
% If $\prob{P}$ commutes with exchange, then for any $\alpha\in R$ such that $\prob{P}_\alpha^{\RV{D}}$ is exchangeable then $\prob{P}_\alpha$ is also exchangeable. Then there exists $\RV{H}$ a symmetric function of $(\RV{Y}_i,\RV{D}_i)_{i\in\mathbb{N}}$ such that $\RV{Y}_i\CI_{\prob{P}}(\RV{D}_j,\RV{Y}_j)_{j\in \mathbb{N}}\setminus \{i\}|\RV{H}\RV{D}_i$. This is De Finetti's representation theorem, and many proofs exists, see for example \citep{kallenberg_basic_2005}.

% In particular, let 

% \begin{align}
%     \RV{H}:=A\times B\mapsto \lim_{n\to\infty} \frac{1}{n}\sum_{i\in n} \mathds{1}_{A\times B}((\RV{Y}_i, \RV{D}_i))
% \end{align}

% Then for all $\alpha\in R$,
% \begin{align}
%     \prob{P}_\alpha^{(\RV{Y}_i,\RV{D}_i)_{i\in\mathbb{N}}|\RV{H}}(A\times B|h) \overset{a.s.}{=} h(A\times B)\label{eq:given_h}
% \end{align}

% The proof that the limit exists and the above equality holds can again be found int \citep{kallenberg_basic_2005}.
% \end{proof}

\subsection{Existence of response conditionals}

The main result in this section is Theorem \ref{th:iid_rep} which shows that a probability set $\prob{P}_C$ is causally contractible if and only if it can be represented as the product of a distribution over hypotheses $\prob{P}_\square^{\RV{H}}$ and a collection of identical uniform conditionals $\prob{P}_C^{\RV{Y}_1|\RV{D}_1\RV{H}}$. Note the hypothesis $\RV{H}$ that appears in this conditional; it can be given the interpretation of a random variable that expresses the ``true but initially unknown'' $\RV{Y}_1|\RV{D}_1$ conditional probability.

\begin{lemma}\label{th:table_rep}
Given a probability set $\prob{P}_C^{\RV{Y}|\RV{D}}$ such that $\RV{D}:=(\RV{D}_i)_{i\in \mathbb{N}}$ and $\RV{Y}:=(\RV{Y}_i)_{i\in \mathbb{N}}$, $\prob{P}_\square$ is consequence contractible if and only if there exists a column exchangeable probability distribution $\mu^{\RV{Y}^D}\in \Delta(Y^{|D|\times \mathbb{N}})$ such that
\begin{align}
    \prob{P}_C^{\RV{Y}|\RV{D}} &= \tikzfig{lookup_representation}\label{eq:lup_rep}\\
    &\iff\\
    \prob{P}_C^{\RV{Y}|\RV{D}}(y|(d_i)_{i\in \mathbb{N}}) &= \mu^{\RV{Y}^D} \Pi_{(d_i i)_{i\in\mathbb{N}}}(y)
\end{align}
Where $\Pi_{(d_i i)_{i\in\mathbb{N}}}:Y^{|D|\times \mathbb{N}}\to Y^{\mathbb{N}}$ is the function that projects the $(d_i,i)$ indices for all $i\in \mathbb{N}$ and $\prob{F}_{\text{ev}}$ is the Markov kernel associated with the evaluation map
\begin{align}
    \text{ev}:D^\mathbb{N}\times Y^{D\times \mathbb{N}}&\to Y\\
    ((d_i)_\mathbb{N},(y_{ij})_{i\in D,j\in \mathbb{N}})&\mapsto (y_{d_i i})_{i\in \mathbb{N}}
\end{align}
\end{lemma}

\begin{proof}
Only if:
Consider a probability set $\prob{P}_{C'}$ where $C'\supset C$ contains all $\alpha$ such that $\prob{P}_\alpha^{\RV{D}}$ is deterministic and $\prob{P}_{C'}^{\RV{Y}|\RV{D}}\overset{P_C}{\cong}\prob{P}_C^{\RV{Y}|\RV{D}}$. It can be constructed by adding to $\prob{P}_C$ probability sets with marginals $\delta_d\odot \prob{P}_{C'}^{\RV{Y}|\RV{D}}$ for all $d\in D$.

We will prove the result holds for $\prob{P}_{C'}$, and it will therefore also hold for $\prob{P}_C$.

For all $d\in D$, abuse notation to say that $\prob{P}_d$ is a probability set in $C'$ such that $\prob{P}_d^{\RV{D}}=\delta_d$. For any $\alpha\in C'$, we have

\begin{align}
    \prob{P}_\alpha^{\RV{DY}}(B\times C) &= \int_B \prob{P}_C^{\RV{Y}|\RV{D}}(C|d)\prob{P}_\alpha^{\RV{D}}(\mathrm{d}d)\\
                                &= \int_B \int_D \prob{P}_C^{\RV{Y}|\RV{D}}(C|d')\prob{P}_d^{\RV{D}}(\mathrm{d}d')\prob{P}_\alpha^{\RV{D}}(\mathrm{d}d)\\
                                &= \int_B \prob{P}_d^{\RV{Y}}(C)\prob{P}_\alpha^{\RV{D}}(\mathrm{d}d)
\end{align}

Thus $d\mapsto \prob{P}_d^{\RV{Y}}$ is a version of $\prob{P}_C^{\RV{Y}|\RV{C}}$.

Choose $e:=(e_i)_{i\in\mathbb{N}}$ such that $e_{|D|i+j}$ is the $i$th element of $D$ for all $i,j\in \mathbb{N}$.

Define
\begin{align}
    \mu^{\RV{Y}^D}((y_{ij})_{D\times \mathbb{N}}):=\prob{P}_e^{\RV{Y}}((y_{|D|i+j})_{i\in D, j\in \mathbb{N}})
\end{align}

Now consider any $d:=(d_i)_{i\in \mathbb{N}}\in D^{\mathbb{N}}$. By definition of $e$, $e_{|D|d_i + i}=d_i$ for any $i,j\in \mathbb{N}$.

Define
\begin{align}
    \prob{Q}:D\kto Y\\
    \prob{Q}:= \tikzfig{lookup_representation}
\end{align}

and consider some ordered sequence $A\subset \mathbb{N}$ and $B:= ((|D|d_i+i))_{i\in A}$. Note that $e_B:=(e_{|D|d_i +i})_{i\in B}=d_A=(d_i)_{i\in A}$. Then 

\begin{align}
    \sum_{y\in \RV{Y}^{-1}(y_A)} \prob{Q}(y|d) &= \sum_{y\in \RV{Y}^{-1}(y_A)} \mu^{(\RV{Y}^{D}_{d_ii})_{A}}(y) \\
    &= \sum_{y\in \RV{Y}^{-1}(y_A)} \prob{P}_e^{(\RV{Y}_{|D|d_i+i})_{A}}(y)\\
    &= \prob{P}_e^{\RV{Y}_{B}}(y_A)\\
    &= \prob{P}_{d}^{\RV{Y}_A}(y_A)&\text{by causal contractibility}
\end{align}

Because this holds for all $A\subset\mathbb{N}$, by the Kolmogorov extension theorem

\begin{align}
    \prob{Q}(y|d) &= \prob{P}_d^{\RV{Y}}(y)
\end{align}

And so $\prob{Q}$ is also a version of $\prob{P}_\square^{\RV{Y}|\RV{C}}$.

Next we will show $\mu^{\RV{Y}^D}$ is exchangeable. Consider any subsequences $\RV{Y}^D_S$ and $\RV{Y}^D_T$ of $\RV{Y}^D$ with $|S|=|T|$. Let $\rho(S)$ be the ``expansion'' of the indices $S$, i.e. $\rho(S)=(|D|i+j)_{i\in S,j\in D}$. Then by construction of $e$, $e_{\rho(S)}=e_{\rho(T)}$ and therefore

\begin{align}
    \mu^{\RV{Y}^D}\Pi_S&= \prob{P}_e^{\RV{Y}_{\rho(S)}})\\
    &= \prob{P}_e^{\RV{Y}_{\rho(T)}})&\text{by contractibility of }\prob{P}_C\text{ and the equality } e_{\rho(S)}=e_{\rho(T)}\\
    &= \mu^{\RV{Y}^D}\Pi_T
\end{align}


If:
Suppose 
\begin{align}
    \prob{P}_C^{\RV{Y}|\RV{D}} &= \tikzfig{lookup_representation}
\end{align}

and consider any two deterministic decision functions $d,d'\in D^{\mathbb{N}}$ such that some subsequences are equal $d_S=d'_T$.

Let $\RV{Y}^{d_S}=(\RV{Y}_{d_i i})_{i\in S}$.

By definition,

\begin{align}
    \prob{P}_C^{\RV{Y}_S|\RV{D}}(y_S|d) &= \sum_{y^D_S\in Y^{|D|\times |S|}}\mu^{\RV{Y}^D} \Pi_S(y^D_S)\prob{F}_{\text{ev}}(y_S|d,y^D_S)\\
    &= \sum_{y^D_S\in Y^{|D|\times |T|}}\prob{P}_C^{\RV{Y}^D_T}(y^D_S)\prob{F}_{\text{ev}}(y_S|d,y^D_S)&\text{ by contractibility of }\mu^{\RV{Y}^D}\Pi_T \\
    &= \prob{P}_C^{\RV{Y}_T|\RV{D}}(y_S|d)
\end{align}
\end{proof}

It is useful to apply conventions established for discussing variables to the tabular distribution $\mu^{\RV{Y}^D}$ and the representation of $\prob{P}_C^{\RV{Y}|\RV{D}}$in Equation \ref{eq:lup_rep}. Thus we define an augmented causally contractible model as follows:

\begin{definition}[Augmented causally contractible model]
A $(\RV{D},\RV{Y})$-causally contractible probability set $\prob{P}_C$ on $(\Omega,\sigalg{F})$ is \emph{augmented} if there is an unobserved variable $\RV{Y}^D:\Omega\to Y^{|\mathbb{N}|\times |D|}$ such that $\prob{P}_C^{\RV{Y}^D}$ exists and
\begin{align}
    \prob{P}_C^{\RV{Y}|\RV{D}} &= \tikzfig{lookup_representation_variablised}
\end{align}
\end{definition}

An augmented causally contractible model looks in some respects similar to a potential outcomes model - both have a distribution over an unobserved tabular variable ($\RV{Y}^D$ or the potential outcomes respectively), and the value of $\RV{Y}_i$ is deterministically equal to the entry in the table corresponding to $(i,\RV{D})$. However, the $\RV{Y}^D$ in an augmented causally contractible model usually can't be interpreted as potential outcomes. For example, consider a series of bets on fair coin flips. Model the consequence $\RV{Y}_i$ as uniform on $\{0,1\}$ for any decision $\RV{D}_i$, for all $i$. Specifically, $D=Y=\{0,1\}$ and $\prob{P}_\alpha^{\RV{Y}_n}(y)=\prod_{i\in [n]} 0.5$ for all $n$, $y\in Y^n$, $\alpha\in R$. Then the construction of $\prob{P}^{\RV{Y}^D}$ following the method in Lemma \ref{th:table_rep} yields $\prob{P}^{Y^D_i}(y^D_i)=\prod_{j\in D} 0.5$ for all $y^D_i\in Y^D$. In this model $\RV{Y}^0_i$ and $\RV{Y}^1_i$ are independent and uniformly distributed. However, if we wanted $\RV{Y}^0_i$ to be interpretable as ``what would happen if I bet on outcome 0 on turn $i$'' and $\RV{Y}^1$ to represent ``what would happen if I bet on outcome 1 on turn $i$'', then we ought to have $\RV{Y}^0_i = 1-\RV{Y}^1_i$.

The following is the main theorem of this section, that establishes the equivalence between causal contractibility and the existence of response conditionals. The argument in outline is: because $\prob{P}_C^{\RV{Y}^D}$ is a column exchangeable probability distribution we can apply De Finetti's theorem to show $\prob{P}_C^{\RV{Y}^D}$ is representable as a product of identical parallel copies of $\prob{P}_C^{\RV{Y}_1^D|\RV{H}}$ and a common prior $\prob{P}_C^{\RV{H}}$. This in turn can be used to show that $\prob{P}_C^{\RV{Y}|\RV{D}}$ can be represented as a product of identical parallel copies of $\prob{P}_C^{\RV{Y}_1|\RV{D}_1\RV{H}}$ and the same common prior $\prob{P}_C^{\RV{H}}$.

\begin{theorem}\label{th:iid_rep}
Suppose we have a sample space $(\Omega,\sigalg{F})$ and a probability set $\prob{P}_C$ with uniform conditional $\prob{P}_C^{\RV{Y}|\RV{D}}$ where $\RV{D}:=(\RV{D}_i)_{i\in \mathbb{N}}$ and $\RV{Y}:=(\RV{Y}_i)_{i\in \mathbb{N}}$. $\prob{P}_C$ is augmented $(\RV{D};\RV{Y})$-causally contractible if and only if there exists some $\RV{H}:\Omega\to H$ such that $\prob{P}^{\RV{H}}_C$ and $\prob{P}_C^{\RV{Y}_i|\RV{H}\RV{D}_i}$ exist for all $i\in \mathbb{N}$ and
\begin{align}
    \prob{P}_C^{\RV{Y}|\RV{D}} &= \tikzfig{do_model_representation}\\
    &\iff\\
    \RV{Y}_i&\CI^e_{\prob{P}_C} \RV{Y}_{\mathbb{N}\setminus i},\RV{D}_{\mathbb{N}\setminus i}C|\RV{H}\RV{D}_i&\forall i\in \mathbb{N}\\
    \land \RV{H} \CI^e_{\prob{P}_C} \RV{D} C\\
    \land \prob{P}_C^{\RV{Y}_i|\RV{H}\RV{D}_i} &= \prob{P}^{\RV{Y}_0|\RV{H}\RV{D}_0} & \forall i\in \mathbb{N}
\end{align}
Where $\Pi_{D,i}:D^\mathbb{N}\kto D$ is the $i$th projection map.
\end{theorem}

\begin{proof}
We make use of Lemma \ref{th:table_rep} to show that we can represent the conditional probability $\prob{P}_C^{\RV{Y}|\RV{D}}$ as
\begin{align}
        \prob{P}_C^{\RV{Y}|\RV{D}} &= \tikzfig{lookup_representation}\\
\end{align}

As a preliminary, we will show
\begin{align}
    \kernel{F}_{\mathrm{ev}} &= \tikzfig{lookup_rep_intermediate}\label{eq:ev_alternate_rep}
\end{align}

Where $\Pi_{Y^D,i}:Y^{D\times\mathbb{N}}\kto Y^D$ is the $i$th column projection map on $\RV{Y}^{D\times \mathbb{N}}$ and $\mathrm{ev}_{Y^D\times D}:Y^D\times D\to Y$ is the evaluation function
\begin{align}
    ((y_i)_{i\in D},d)\mapsto y_d
\end{align}

Recall that $\mathrm{ev}$ is the function

\begin{align}
    ((d_i)_\mathbb{N},(y_{ij})_{i\in D,j\in \mathbb{N}})&\mapsto (y_{d_i i})_{i\in \mathbb{N}}
\end{align}

By definition, for any $\{A_i\in\sigalg{Y}|i\in \mathbb{N}\}$

\begin{align}
    \kernel{F}_{\mathrm{ev}}(\prod_{i\in \mathbb{N}}A_i|(d_i)_\mathbb{N},(y_{ij})_{i\in D,j\in \mathbb{N}}) &= \delta_{(y_{d_i i})_{i\in \mathbb{N}}}(\prod_{i\in \mathbb{N}}A_i)\\
        &= \prod_{i\in \mathbb{N}} \delta_{y_{d_i i}} (A_i)\\
        &= \mathrm{copy}^{\mathbb{N}}\prod_{i\in \mathbb{N}}( \Pi_{D,i}\otimes \Pi_{Y,i})\kernel{F}_{\mathrm{ev}_{Y^D\times D}}
\end{align}

Which is what we wanted to show.

Only if:
As we have an augmented causally contractible model, we have a variable $\RV{Y}^D=(\RV{Y}^D_i)_{i\in \mathbb{N}}$ exchangeable with respect to $\prob{P}^{\RV{Y}^D}_C$ (Lemma \ref{th:table_rep}). From \citet{kallenberg_basic_2005} we have a directing random measure $\RV{H}$ such that
\begin{align}
    \prob{P}_C^{\RV{Y}^D|\RV{H}} &= \tikzfig{de_finetti_representation}\\
    &\iff\\
    \prob{P}_C^{\RV{Y}^D|\RV{H}}(\prod_{i\in \mathbb{N}} A_i|h) &= \prod_{i\in \mathbb{N}} \prob{P}_C^{\RV{Y}_0^D|\RV{H}}(A_i|h)
\end{align}

Furthermore, because $\RV{Y}$ is a deterministic function of $\RV{D}$ and $\RV{Y}^D$, $\RV{Y}\CI_{\prob{P}_C} \RV{H}|(\RV{D},\RV{Y}^D)$ and by definition of $\RV{Y}^D$, $\RV{Y}^D\CI_{\prob{P}_C}\RV{D}$ and so

\begin{align}
    \prob{P}_C^{\RV{Y}|\RV{HD}} &= \prob{P}_C^{\RV{Y}^D|\RV{HD}}\odot \prob{P}_C^{\RV{Y}|\RV{Y}^D\RV{HD}}\\
                                      &= \tikzfig{Y_pushback_factorisation}
                                      &= \tikzfig{do_model_representation}
\end{align}

If:
By assumption
\begin{align}
    \prob{P}_C^{\RV{Y}|\RV{D}}(\prod_{i\in \mathbb{N}} A_i|h,(d_i)_{i\in \mathbb{N}}) &= \int_H \prod_{i\in \mathbb{N}}\prob{P}_C^{\RV{Y}_1|\RV{HD}_1}(A_i|h,d_i)\prob{P}_C^{\RV{H}}(\mathrm{d}h)
\end{align}

Consider $\alpha,\alpha'$ such that $\prob{P}^{\RV{D}_M}_\alpha = \prob{P}^{\RV{D}_L}_{\alpha'}$ for $L,M\subset \mathbb{N}$ with $|M|=|L|$, both finite. Then

\begin{align}
    \prob{P}_\alpha^{\RV{Y}_M}(A) &= \int_{D^{\mathbb{N}}} \prob{P}_\alpha^{\RV{Y}_M|\RV{D}}(A|d)\prob{P}_\alpha^{\RV{D}}(\mathrm{d}d)\\
                                  &= \int_H\int_{D^{\mathbb{N}}} \prod_{i\in M}\prob{P}_C^{\RV{Y}_1|\RV{HD}_1}(A_i|h,d_i)\prob{P}_\alpha^{\RV{D}}(\mathrm{d}d)\prob{P}_C^{\RV{H}}(\mathrm{d}h)\\
                                  &= \int_H\int_{D^{|M|}} \prod_{i\in M}\prob{P}_C^{\RV{Y}_1|\RV{HD}_1}(A_i|h,d_i)\prob{P}_\alpha^{\RV{D}_M}(\mathrm{d}d_M)\prob{P}_C^{\RV{H}}(\mathrm{d}h)\\
                                  &= \int_H\int_{D^{|M|}} \prod_{i\in M}\prob{P}_C^{\RV{Y}_1|\RV{HD}_1}(A_i|h,d_i)\prob{P}_{\alpha'}^{\RV{D}_N}(\mathrm{d}d_N)\prob{P}_C^{\RV{H}}(\mathrm{d}h)\\
                                  &= \int_H\int_{D^{\mathbb{N}}} \prod_{i\in M}\prob{P}_C^{\RV{Y}_1|\RV{HD}_1}(A_i|h,d_i)\prob{P}_{\alpha'}^{\RV{D}}(\mathrm{d}d)\prob{P}_C^{\RV{H}}(\mathrm{d}h)\\
                                  &= \prob{P}_{\alpha'}^{\RV{Y}_M}(A)
\end{align}

\end{proof}


\subsection{Example: backdoor adjustment}

Suppose a probability set $\prob{P}_C$ is $(\RV{D},\RV{X};\RV{Y})$-causally contractible and $\RV{X}_{i}\CI^e_{\prob{P}_C}\RV{D}_{i}C|\RV{H}$. Then
\begin{align}
    \prob{P}_\alpha^{\RV{Y}_{i}|\RV{D}_{i}\RV{H}}(A|d,h) &= \int_X \prob{P}_\alpha^{\RV{Y}_{i}|\RV{X}_{i}\RV{D}_{i}\RV{H}}(A|d,x,h)\prob{P}_\alpha^{\RV{X}_{i}|\RV{D}_{i}\RV{H}}(\mathrm{d}x|d,h)\\
    &= \int_X \prob{P}_C^{\RV{Y}_{1}|\RV{X}_{1}\RV{D}_{1}\RV{H}}(A|d,x,h)\prob{P}_C^{\RV{X}_{i}|\RV{H}}(\mathrm{d}x|h)
\end{align}

If we additionally assume $\prob{P}_C^{\RV{X}_{i}|\RV{H}}\cong \prob{P}_C^{\RV{X}_{1}|\RV{H}}$ then 

\begin{align}
    \prob{P}_\alpha^{\RV{Y}_{i}|\RV{D}_{i}\RV{H}}(A|d,h) &= \int_X \prob{P}_C^{\RV{Y}_{1}|\RV{X}_{1}\RV{D}_{1}\RV{H}}(A|d,x,h)\prob{P}_C^{\RV{X}_{1}|\RV{H}}(\mathrm{d}x|h)\label{eq:backdoor}
\end{align}

Equation \ref{eq:backdoor} is structurally identical to the backdoor adjustment formula for an intervention on $\RV{D}_1$ targeting $\RV{Y}_1$ where $\RV{X}_1$ is a common cause of both. Note that we have not assumed that $\prob{P}_C^{\RV{D}_i}$ exists for any $i$; the only assumptions are the extended independence $\RV{X}_{i}\CI^e_{\prob{P}_C}\RV{D}_{i}C|\RV{H}$ and the equality in distribution between the first and $i$th ``$\RV{X}$''.

\subsection{Assessing causal contractibility}

We have a formal condition -- causal contractibility -- equivalent to the existence of response conditionals. However, a key challenge is to evaluate when a decision procedure is appropriately modeled with a probability set causally contractible with respect to some pair of variables. This is an opaque problem, and we don't expect that this can be avoided entirely. 

Causal contractibility is a very strong assumption. Suppose we have a decision procedure in which $M$ observations are made $(\proc{X}_M,\proc{Y}_M)$ that are unaffected by the choice $\alpha$, followed by $M$ repetitions $(\proc{X}_{(M,2M]},\proc{Y}_{(M,2M]})$ which are responsive to the choice $\alpha$. We model this with a probability set $\prob{P}_C$ where $\RV{X}_M$ corresponds to $\proc{X}_M$ and so forth. If $\prob{P}_C$ is $(\RV{X}_{2M},\RV{Y}_{2M})$-causally contractible model then the following holds (see corollary \ref{th:equal_of_condits}):
\begin{align}
    \prob{P}^{\RV{Y}_{[2,M+1]}|\RV{X}_{[2,M+1]}}_C &= \prob{P}^{\RV{Y}_{(M,2M]}|\RV{X}_{(M,2M]}}\\
    \implies \prob{P}^{\RV{Y}_{M+1}|\RV{X}_{[2,M+1]}\RV{Y}_{[2,M]}}_C &= \prob{P}^{\RV{Y}_{M+1}|\RV{X}_{(M,2M]}\RV{Y}_{(M+1,2M]}}
\end{align}
That is, causal contractibility implies that there is no difference between conditioning on observational results or on the results of active choices; active choices are as good for predicting observations as vise-versa.

When can such a strong assumption be accepted? Like exchangeability, one option for justifying judgements of causal contractibility is to compare different measurement procedures and argue that they should be \emph{indistinguishable} -- that is, they should be modeled with exactly the same model. In the case of exchangeability, this is sometimes called ``symmetric ignorance'' \citet[chap. ~5]{gelman_bayesian_2013}. More specifically, if we are committed to modelling uncertainty with a single probability distribution and we consider the following two measurement procedures indistinguishable:
\begin{itemize}
    \item The original measurement procedure
    \item The original measurement procedure, composed with a function permuting the labels
\end{itemize}
then we should use an exchangeable probability distribution to model the original measurement procedure.

We can make a similar argument for causal contractibility, although it is a substantially more complicated one. We will focus only on commutativity of exchange here. There is some discussion in literature of procedural assumptions that imply properties similar to commutativity of exchange. For example, \citet{greenland_identifiability_1986} explain

\begin{quote}
    Equivalence of response type may be thought of in terms of exchangeability of individuals: if the exposure states of the two individuals had been exchanged, the same data distribution would have resulted.
\end{quote}

Along similar lines, \citet{dawid_decision-theoretic_2020} explains exchangeability of responses to headache treatment in terms of

\begin{quote}
    A group of individuals whom I can regard, in an intuitive sense, as similar to myself, with headaches similar to my own.
\end{quote}

In Appendix \ref{sec:exchange_commutativity} we offer a more detailed argument for accepting exchange commutativity for an example decision procedure. Suppose we are in the position of a doctor who will be seeing patients in the future, and resolves to follow a procedure of the form

\begin{algorithmic}
    \Procedure{$\proc{S}_\alpha$}{}
    \State $(d_1,d_2) \gets c(\alpha)$
    \State $y_1\gets \mathrm{apply}(d_1,\mathrm{patient\;A})$
    \State $y_2\gets \mathrm{apply}(d_2,\mathrm{patient\;B})$
    \State \Return $(d_1,d_2,y_1,y_2)$
    \EndProcedure
\end{algorithmic}

for some treatment policy $\alpha\in A$. Define $\RV{D}:=(\RV{D}_1,\RV{D}_2)$ where $\RV{D}:(d_1,d_2,y_1,y_2)\mapsto (d_1,d_2)$ and $\RV{Y}:=(\RV{Y}_1,\RV{Y}_2)$ with $\RV{Y}:(d_1,d_2,y_1,y_2)\mapsto (y_1,y_2)$. $\proc{D}$ is the procedure associated with $\RV{D}$.

We argue that the following conditions are sufficient to support a judgement of $(\RV{D};\RV{Y})$-exchange commutativity:

\begin{enumerate}
    \item Two procedures $\proc{S}_\alpha$ and $\proc{S}_{\alpha'}$ are indistinguishable if the description of one can be obtained by permuting patients in the description of the other (\emph{patient indistinguishability})
    \item Two procedures $\proc{S}_\alpha$ and $\proc{S}_{\alpha'}$ are indistinguishable if the description of one can be obtained by permuting the order of treatment administration in the description of the other (\emph{order indistinguishability})
    \item $c:A\to D^2$ is an invertible function
\end{enumerate}

A typical condition given for the identifiability of treatment effects or interventional conditionals is that the treatment subprocedures $(\proc{D}_1,\proc{D}_2)$) are random \citep{rubin_causal_2005}. Our third condition -- that $\proc{D}$ is a deterministic and invertible function of $\alpha$ -- is somewhat different to this. A rough explanation of this condition is: the model represents the doctor's knowledge at the time they choose $\alpha$, and assumptions 1 and 2 imply that given their knowledge at the time, the two treatment episodes are indistinguishable. A deterministic choice of $\proc{D}$ ensures that the result of $\proc{D}$ cannot reflect anything new that is learned after the fact.

This rough story can be extended to a randomised $\proc{D}$. We could say that $\proc{D}$ is ``randomised'' if it is chosen according to $c'(\alpha,\proc{R})$ for some function $c':A\times R\to D^2$ and some ``random'' $\proc{R}$. Then $\proc{D}$ again cannot reflect anything not known when $\alpha$ was chosen, because we assume that the results of random procedures carry no useful information.

This story depends crucially on the state of knowledge of the decision maker when they make their choice. It seems difficult to state the assumption of deterministic $\proc{D}$ without the decision theoretic approach we adopt here.


\subsection{Body mass index revisited}

If we have a probability set $\prob{P}_C$ with $\RV{B}:=(\RV{B}_i)_{i\in M}$ representing body mass index and $\RV{Y}:=(\RV{Y}_i)_{i\in M}$ representing health outcomes of interest, the justifications for causal effects in the previous section do not apply. The reason is that we are interested in evaluating actions that do not set body mass deterministically, whether directly or on the basis of a random signal.

However, it is still possible that $\prob{P}_C$ could be $(\RV{B};\RV{Y})$-causally contractible. The key is Theorem \ref{th:cons_ci} -- if we start with $\prob{P}_C$ that is $(\RV{D};\RV{Y})$-causally contractible, and we find for a suitable $\alpha$ that $\RV{Y}_i\CI_{\prob{P}_\alpha} \RV{D}_i |\RV{H}\RV{B}_i$ for all $i$, then we can conclude that $\RV{Y}_i\CI_{\prob{P}_C}^e \RV{D}_i C|\RV{H}\RV{B}_i$ for all $i$, and that $\prob{P}_C$ is $(\RV{B};\RV{Y})$-causally contractible (Theorem \ref{lem:proxy_control}). There are two important things to bear in mind:

\begin{itemize}
    \item Causal contractibility is always relative to a set of choices $C$; our theory provides no way to assess the existence of ``causal effects'' independent of such a set
    \item Whether or not $\RV{Y}_i\CI_{\prob{P}_\alpha} \RV{D}_i |\RV{H}\RV{B}_i$ holds for a suitable choice $\alpha$ is a testable question, so it may be inappropriate to assume it does by asking at the outset about ``the causal effect of $\RV{B}$''
\end{itemize}

Thus it is possible in principle to have a ``causal effect of body mass index'', but our analysis suggests that it should be demonstrated rather than assumed.

\begin{theorem}\label{lem:proxy_control}
Suppose we have a probability set $\prob{P}_C$ that is $(\RV{D};\RV{X},\RV{Y})$-causally contractible, where $\RV{D}:=(\RV{D}_i)_{i\in M}$ and likewise for $\RV{X}$ and $\RV{Y}$. If there exists $\alpha\in C$ such that $\prob{P}_\alpha^{\RV{D}}\gg \{\prob{P}_\beta^{\RV{D}}|\beta\in C\}$ and $\RV{Y}_i\CI_{\prob{P}_\alpha} \RV{D}_i|\RV{HX}_i$ for all $i\in M$, then $\prob{P}_C$ is also $(\RV{Y};\RV{X})$-causally contractible.
\end{theorem}

\begin{proof}
See Appendix \ref{sec:bmi_revis}
\end{proof}

\subsection{Weakening causal contractibility}

We have pointed out that causal contractibility is a very strong assumption, and will usually be unacceptable. We proposed three assumptions that could justify causal contractibility for some decision procedures:

\begin{enumerate}
    \item Two procedures $\proc{S}_\alpha$ and $\proc{S}_{\alpha'}$ are indistinguishable if the description of one can be obtained by permuting patients in the description of the other (\emph{patient indistinguishability})
    \item Two procedures $\proc{S}_\alpha$ and $\proc{S}_{\alpha'}$ are indistinguishable if the description of one can be obtained by permuting the order of treatment administration in the description of the other (\emph{order indistinguishability})
    \item $c:A\to D^2$ is an invertible function
\end{enumerate}

We can imagine that many decision procedures involving patient treatment might satisfy the first two properties, but not the third. A question to explore is: is there a representation theorem relevant to a decision procedure in which the third assumption is removed or weakened? A common assumption in other causal frameworks for procedures like this is to assume that there is some variable $(\RV{X},\RV{Z})$ that is ``causally sufficent'' for $\RV{Y}$, but $\RV{Z}$ is not observed. In our framework, this would amount to $\prob{P}_C$ being $((\RV{X},\RV{Z});\RV{Y})$-causally contractible, with $\RV{Z}$ unobserved. However, at this point we do not know of a relevant representation theorem for unobservable causal contractibility like this, nor of an argument that connects the representation with a particular family of decision procedures.