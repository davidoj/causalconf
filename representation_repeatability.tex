%!TEX root = main.tex

\section{When do response functions exist?}\label{sec:response_functions}

We model decision problems with probability sets $\prob{P}_C$ for some set of choices $C$. If we have a pair of variables $\RV{X}$ and $\RV{Y}$ such that the uniform conditional $\prob{P}_C^{\RV{Y}|\RV{X}}$ exists (Definition \ref{def:cprob_pset}), then the joint outcome $\prob{P}_\alpha^{\RV{XY}}$ of any choice $\alpha\in C$ can be computed from the marginal distribution $\prob{P}_\alpha^{\RV{X}}$ alone.

We're interested in models that feature a particular kind of ``causal effect'' that we call a \emph{conditionally independent and identical response functions}, or just ``response functions'' for short\todo{is that OK?}. They are a causal analogue of conditionally independent and identical sequences of random variables. Concretely, a model with response functions is a probability set $\prob{P}_C$ with variables $\RV{Y}:=(\RV{Y}_i)_{i\in M}$, $(\RV{X}_i)_{i\in M}$ for some index set $M$ and some $\RV{H}$ such that $\RV{Y} \CI_{\prob{P}_C}^e C|\RV{X}_i\RV{H}$ and $\RV{H}\CI_{\prob{P}_C}^e \RV{X}_i C$ (see Section \ref{sec:eci} for extended conditional independence) and $\prob{P}_C^{\RV{Y}_i|\RV{X}_i\RV{H}}=\prob{P}_C^{\RV{Y}_j|\RV{X}_j\RV{H}}$ for all $i,j\in M$ (the identical response conditional requirement).

We will focus on the case where $\prob{P}_\alpha^{\RV{H}|\RV{Y}_A\RV{X}_A}$ approaches a deterministic distribution as $|A|\to \infty$, for appropriate $\alpha\in C$. We could say this is the case of ``identifiable'' response conditionals.

Put together, these conditions say: in the limit of infinite samples under an appropriate sampling regime $\alpha\in C$, the model converges to a probabilistic function $X\kto Y$ that represents ``the probability of $\RV{Y}_i$ given $\RV{X}_i$'' for any unobserved $(\RV{X}_i,\RV{Y}_i)$. For arbitrary $\alpha'\in C$, we may instead converge to a set containing this limiting distribution. We think -- although it usually isn't stated in these terms -- that given a causal Bayesian network, if the function ``$x\mapsto \prob{P}(\RV{Y}|\mathrm{do}(\RV{X}=x))$'' is identifiable, then it is an instance of the kind of function that we described in the previous sentences.

We prove our result under the simplifying assumption that $\RV{X}_i\CI_{\prob{P}_C}^e \RV{Y}_{<i} C|\RV{X}_{<i}$. This is a limiting assumption -- for example, it excludes cases where $\RV{X}_i$ depends on $(\RV{X}_{<i},\RV{Y}_{<i})$. In the more general case where this does not hold, the conditions we provide must still hold for any $C'\subset C$ such that $\RV{X}_i\CI_{\prob{P}_C}^e \RV{Y}_{<i>} C|\RV{X}_{<i}$, but providing sufficient conditions in this case is the topic of further work.

Under this assumption, we show that \emph{causal contractibility} is necessary and sufficient for the existence of response conditionals. Causal contractibility can be broken down into two sub-assumptions: \emph{exchange commutativity} and \emph{consequence locality}. The first is the assumption that the uniform conditional probability $\prob{P}_C^{\RV{Y}|\RV{X}}$ ``commutes'' with the permutation operation, and the second is the assumption that $\RV{X}_i$ ``has no effect'' on any $\RV{Y}_j$ for $j\neq i$.

\subsection{Relevance to previous work}

Both sub-assumptions have precedent in existing literature, but these precedents tend to have been stated at somewhat informally.

\emph{Post-treatment exchangeability} found in \citet{dawid_decision-theoretic_2020} is implied by exchange commutativity, but not the reverse. ``Causal exchangeability'' notions are also found in \citet{greenland_identifiability_1986} and \citet{banerjee_chapter_2017}; a subtle difference between these notions and exchange commutativity is that these latter notions are given as symmetries of \emph{decision procedures} -- they involve actually swapping actions taken or individuals in an experiment -- while exchange commutativity is a symmetry of probability sets.

Consequence locality is similar to the stable unit treatment distribution assumption (SUTDA) in \citet{dawid_decision-theoretic_2020}, although consequence locality is distinguished by being a concrete extended conditional independence (Definition \ref{def:caus_cont}) while SUTDA is given as the assumption that $\RV{Y}_i$ ``depends only on'' $\RV{X}_i$.  Consequence locality is also similar to stable unit treatment value assumption (SUTVA). The stable unit treatment value assumption (SUTVA) is given as \citep{rubin_causal_2005}:

\begin{blockquote}
(SUTVA) comprises two sub-assumptions. First, it assumes that \emph{there is no interference between units (Cox 1958)}; that is, neither $Y_i(1)$ nor $Y_i(0)$ is affected by what action any other unit received. Second, it assumes that \emph{there are no hidden versions of treatments}; no matter how unit $i$ received treatment $1$, the outcome that would be observed would be $Y_i(1)$ and similarly for treatment $0$.
\end{blockquote}

String diagram statements of both sub-assumptions can give some intuition about what they mean. For clarity, these diagrams illustrate the assumptions with exactly two inputs and two outputs, while the general definitions are for any countable number of inputs and outputs.

Exchange commutativity for two inputs and outputs is given by the following equality:

\begin{align}
    \tikzfig{commutativity_of_exchange}
\end{align}

While consequence locality for two inputs and outputs is given by the following pair of equalities:

\begin{align}
    \tikzfig{cons_locality_1}\\
    \tikzfig{cons_locality_2}
\end{align}

% Another way to see where we are going is to consider graphical statements of our and De Finetti's result.

% Take $S=\{0,1\}$ and identify the space $\Delta(S)$ of probability measures on $S$ with the interval $[0,1]$. De Finetti showed that any infinite exchangeable probability measure $\prob{P}_\alpha$ on $\{0,1\}^\mathbb{N}$ can be represented by a prior $\prob{P}_\alpha^{\RV{H}}\in [0,1]$ for some $\RV{H}:\Omega\to H$ and a conditional probability $\prob{P}^{\RV{S}_0|\RV{H}}:[0,1]\kto \{0,1\}$ such that

% \begin{align}
%     \prob{P}_\alpha &= \tikzfig{de_finetti_rep0}\label{eq:definettirep}
% \end{align}

% Here $\prob{P}^{\RV{S}_0|\RV{H}}$ can be defined concretely by $\prob{P}^{\RV{S}_0|\RV{H}}(1|h)=h$. Equivalently, the probability gap model on $S^\mathbb{N}$ defined by the assumption of exchangeability is equivalent to the probability gap model defined by the conditional probability

% \begin{align}
%     \prob{P}^{\RV{S}|\RV{H}} = \tikzfig{de_finetti_conditional}
% \end{align}

% That is, there is some hypothesis $\RV{H}$ and conditional on $\RV{H}$ the measurements are independent and identically distributed. The proof of this is constructive -- $\RV{H}$ is a function of $\RV{S}$.



% \begin{align}
%     \prob{P}^{\RV{Y}|\RV{HD}} = \tikzfig{do_model_representation}
% \end{align}

% We will further argue that the class of see-do models considered in CBN and potential outcomes literature is equivalent to the family of causally contractible and exchangeable do-models where the decision rule for the first $n$ places is fixed to an unknown value, and may be freely chosen thereafter.

% \begin{theorem}[Existence of conditional in do models]
% Given a do model $(\prob{P}_{\square}^{\RV{Y}\|\RV{D}},R)$, for all $\alpha\in R$, $n\in\mathbb{N}$
% \begin{align}
%     \prob{P}_\alpha^{\RV{Y}_{[n]}\RV{D}_i} = \prob{P}_\alpha^{\RV{D}_{[n]}}\odot \prob{P}_\square^{\RV{Y}_{[n]}\|\RV{D}_{[n]}}
% \end{align}
% That is, $\prob{P}_\square^{\RV{Y}_{[n]}\|\RV{D}_{[n]}}\cong \prob{P}_\square^{\RV{Y}_{[n]}|\RV{D}_{[n]}}$
% \end{theorem}

% \begin{proof}
% For any $n>1\in \mathbb{N}$, $\alpha\in R$

% \begin{align}
%     \prob{P}_\alpha^{\RV{Y}_{[n]}\RV{D}_{[n]}} &= \tikzfig{do_model_1}\\
%     &= \tikzfig{do_model_2}\\
%     &= \tikzfig{do_model_3}\\
%     &= \tikzfig{do_model_4}\\
%     \implies \prob{P}_\alpha^{\RV{Y}_{[n]}|\RV{D}_{[n]}} &= \tikzfig{do_model_5}\\
%     &= \prob{P}_\alpha^{\RV{Y}_{[n-1]}|\RV{D}_{[n-1]}}\combprod \prob{P}_\square^{\RV{Y}_n|\RV{Y}_{[n-1]}\RV{D}_n}
% \end{align}

% Applying this recursively with $\prob{P}_\alpha^{\RV{Y}_{[1]}|\RV{D}_{[1]}}=\prob{P}_\square^{\RV{Y}_{[1]}|\RV{D}_{[1]}}$ yields

% \begin{align}
%     \prob{P}_\alpha^{\RV{Y}_{[n]}|\RV{D}_{[n]}} = \prob{P}_\square^{\RV{Y}_{[n]}\|\RV{D}_{[n]}}
% \end{align}
% as desired.
% \end{proof}
\subsection{Causal contractibility}\label{sec:ccontracibility}

Here we set out formal definitions of exchange commutativity and locality of consequences, as well as ``consequence contractibility'', which is the conjunction of both conditions.

\begin{definition}[Locality of consequences]\label{def:caus_cont}
Suppose we have a sample space $(\Omega,\sigalg{F})$ and a probability set $\prob{P}_C$  where $\RV{Y}:=\RV{Y}:=(\RV{Y}_i)_{M}$, $\RV{D}:=\RV{D}_M:=(\RV{D}_i)_M$, $M\subseteq \mathbb{N}$. If for any $A\subset M$, $\RV{Y}_A\CI^e_{\prob{P}_C} \RV{D}_{A^C} C |\RV{D}_A$ then $\prob{P}_C$ exhibits $(\RV{D};\RV{Y})$-\emph{local consequences}.
\end{definition}

If $\prob{P}_C$ exhibits $(\RV{D};\RV{Y})$-local consequences then, given two different choices $\alpha$ and $\alpha'$ such that $\prob{P}_\alpha^{\RV{D}_A}=\prob{P}_{\alpha'}^{\RV{D}_A}$ then $\prob{P}_\alpha^{\RV{Y}_A}=\prob{P}_{\alpha'}^{\RV{Y}_A}$. However, $\prob{P}_C$ may exhibit consequence locality even if no such pair of choices exists.

Note that consequence locality implies $\RV{Y}_M \CI^e_{\prob{P}_C} C |\RV{D}_M$, and hence we have the uniform conditional $\prob{P}_C^{\RV{Y}_M|\RV{D}_M}$. We assume the existence of such a conditional for the next definition.

\begin{definition}[Swap map]
Given $M\subset \mathbb{N}$ a finite permutation $\rho:M\to M$ and a variable $\RV{X}:\Omega\to X^M$ such that $\RV{X}=(\RV{X}_i)_{i\in M}$, define the Markov kernel $\text{swap}_{\rho(\RV{X})}:X^M\kto X^M$ by $(d_i)_{i\in\mathbb{N}}\mapsto \delta_{(d_{\rho(i)})_{i\in\mathbb{N}}}$.
\end{definition}

\begin{definition}[Exchange commutativity]\label{def:caus_exch}
Suppose we have a sample space $(\Omega,\sigalg{F})$ and a probability set $\prob{P}_C$ with uniform conditional probability $\prob{P}_C^{\RV{Y}|\RV{D}}$ where $\RV{Y}:=\RV{Y}:=(\RV{Y}_i)_{M}$, $\RV{D}:=\RV{D}_M:=(\RV{D}_i)_M$, $M\subseteq \mathbb{N}$. If for any finite permutation $\rho:M\to M$
\begin{align}
    \text{swap}_{\rho(\RV{D})} \prob{P}_{C}^{\RV{Y}|\RV{D}} &\overset{\prob{P}_C}{\cong} \prob{P}_{C}^{\RV{Y}|\RV{D}}\text{swap}_{\rho(\RV{Y})}
\end{align}
Then $\prob{P}_C^{\RV{Y}|\RV{D}}$ is $(\RV{D};\RV{Y})$-\emph{exchange commutative}.
\end{definition}

If $\prob{P}_C$ is $(\RV{D};\RV{Y})$-exchange commutative and we have $\alpha,\alpha'\in C$ such that $\prob{P}_\alpha^{\RV{C}} = \prob{P}_{\alpha'}^{\RV{C}}\text{swap}_{\rho(\RV{D})}$, then $\prob{P}_\alpha^{\RV{Y}} = \prob{P}_{\alpha'}^{\RV{Y}}\text{swap}_{\rho(\RV{Y})}$. However, $\prob{P}_C$ may commute with exchange even if there are no such $\alpha$ and $\alpha'\in C$.

Theorem \ref{th:no_implication} shows that neither condition implies the other. 

\begin{theorem}\label{th:no_implication}
Exchange commutativity does not imply locality of consequences or vise versa.
\end{theorem}

\begin{proof}
Appendix \ref{sec:ccontract_appendix}.
\end{proof}

If we are modelling the treatment of several patients whom who have already been examined, we might assume consequence locality -- patient B's treatment does not affect patient A -- but not exchange commutativity -- we don't expect the same results from giving patient A's treatment to patient B as we would from giving patient A's treatment to patient A. 

A model of stimulus payments might exhibit exchange commutativity but not consequence locality. If exactly $n$ payments of \$10 000 are made, we might suppose that it doesn't matter much exactly who receives the payments, but the amount of inflation induced depends on the number of payments made; making 100 such payments will have a negligible effect on inflation, while making payments to everyone in the country will have a substantial effect. \citet{dawid_causal_2000} offers the example of herd immunity in vaccination campaigns as a situation where post-treatment exchangeability holds but locality of consequences does not.

Although locality of consequences seems to intuitively encompass an assumption of non-interference, it still allows for some models in which exhibit certain kinds of interference between actions and outcomes of different indices. For example: I have an experiment where I first flip a coin and record the results of this flip as the outcome of the first step of the experiment, but I can choose either to record this same outcome as the provisional result of the second step (this is the choice $\RV{D}_1=0$), or choose to flip a second coin and record the result of that as the provisional result of the second step of the experiment (this is the choice $\RV{D}_1=1$). At the second step, I may further choose to copy the provisional results ($\RV{D}_2=0$) or invert them ($\RV{D}_2=1$). Then

\begin{align}
    \prob{P}_S^{\RV{Y}_1|\RV{D}}(y_1|d_1,d_2) &= 0.5\\
    \prob{P}_S^{\RV{Y}_2|\RV{D}}(y_2|d_1,d_2) &= 0.5
\end{align}
\begin{itemize}
    \item The marginal distribution of both experiments in isolation is $\text{Bernoulli}(0.5)$ no matter what choices I make, so a model of this experiment would satisfies Definition \ref{def:caus_cont}
    \item Nevertheless, the choice for the first experiment affects the result of the second experiment
\end{itemize}

We call the conjunction of exchange commutativity and consequence locality \emph{causal contractibility}.

\begin{definition}[Causal contractibility]
A probability set $\prob{P}_C$ is $(\RV{D};\RV{Y})$-\emph{causally contractible} if it is both exchange commutative and exhibits consequence locality.
\end{definition}

\begin{theorem}[Equality of reduced conditionals]\label{th:equal_of_condits}
A probability set $\prob{P}_C$ that is $(\RV{D};\RV{Y})$-causally contractible has, for any $A,B\subset M$ with $|A|=|B|$
\begin{align}
    \prob{P}_C^{\RV{Y}_A|\RV{D}_A} \overset{\prob{P}_C}{\cong} \prob{P}_C^{\RV{Y}_B|\RV{D}_B}
\end{align}
\end{theorem}

\begin{proof}
Only if:
For any $A,B\subset M$, let $\text{s}_{BA}:D^M\kto D^M$ be the swap map that sends the $B$ indices to $A$ indices and $\text{s}_{AB}:Y^M\kto Y^M$ be the swap map that sends $A$ indices to $B$ indices.
\begin{align}
    \tikzfig{consequence_locality} &= \tikzfig{contractibility_from_exchange_1}\\
    &= \tikzfig{contractibility_from_exchange_2}\\
    &= \tikzfig{contractibility_from_exchange_3}
\end{align}
Thus
\begin{align}
    \prob{P}_C^{\RV{Y}_A|\RV{D}_A\RV{D}_{M\setminus A}} &\overset{\prob{P}_C}{\cong} \prob{P}_C^{\RV{Y}_B|\RV{D}_B\RV{D}_{M\setminus B}}\\
    &\overset{\prob{P}_C}{\cong} \tikzfig{consequence_locality}\label{eq:cons_local}\\
    \implies \prob{P}_C^{\RV{Y}_A|\RV{D}_A} \overset{\prob{P}_C}{\cong} \prob{P}_C^{\RV{Y}_B|\RV{D}_B}
\end{align}
\end{proof}



% \begin{proposition}[Representation of do-models that commute with exchange]
% Suppose we have a fundamental probability set $\Omega$ and a do model $(\prob{P},\RV{D},\RV{Y},R)$ such that $\RV{D}:=(\RV{D}_i)_{i\in \mathbb{N}}$ and $\RV{Y}:=(\RV{Y}_i)_{i\in\mathbb{N}}$ where $\prob{P}$ commutes with exchange and there is some $\alpha^*\in R$ such that $\prob{P}^{\alpha^*}\gg\prob{P}_\beta$ for all $\beta in R$. Then there exists a symmetric function $\RV{H}:(Y\times D)^\mathbb{N}\to H$ such that  $\prob{P}^{\RV{Y}|\RV{DH}}$ exists and $\RV{Y}_i\CI_{\prob{P}}(\RV{D}_j,\RV{Y}_j)_{j\in \mathbb{N}}\setminus \{i\}|\RV{H}\RV{D}_i$, or equivalently 
% \begin{align}
%     \prob{P}^{\RV{Y}} &= \tikzfig{do_model_representation}
% \end{align}
% \end{proposition}

% % \begin{lemma}[Contraction and independence]
% % Let $\RV{J}$, $\RV{K}$ and $\RV{L}$ be variables on $\Omega$ and $\prob{Q}\in \Delta(\Omega)$ a base measure such that $\prob{Q}^{\RV{JK}}=\prob{Q}^{\RV{JL}}$ and $\sigma{K}\subset \sigma{L}$. Then $\RV{J}\CI\RV{L}|\RV{K}$. 
% % \end{lemma}

% % \begin{proof}
% % From Lemma 1.3 in \citet{kallenberg_basic_2005}.
% % \end{proof}

% \begin{proof}
% If $\prob{P}$ commutes with exchange, then for any $\alpha\in R$ such that $\prob{P}_\alpha^{\RV{D}}$ is exchangeable then $\prob{P}_\alpha$ is also exchangeable. Then there exists $\RV{H}$ a symmetric function of $(\RV{Y}_i,\RV{D}_i)_{i\in\mathbb{N}}$ such that $\RV{Y}_i\CI_{\prob{P}}(\RV{D}_j,\RV{Y}_j)_{j\in \mathbb{N}}\setminus \{i\}|\RV{H}\RV{D}_i$. This is De Finetti's representation theorem, and many proofs exists, see for example \citep{kallenberg_basic_2005}.

% In particular, let 

% \begin{align}
%     \RV{H}:=A\times B\mapsto \lim_{n\to\infty} \frac{1}{n}\sum_{i\in n} \mathds{1}_{A\times B}((\RV{Y}_i, \RV{D}_i))
% \end{align}

% Then for all $\alpha\in R$,
% \begin{align}
%     \prob{P}_\alpha^{(\RV{Y}_i,\RV{D}_i)_{i\in\mathbb{N}}|\RV{H}}(A\times B|h) \overset{a.s.}{=} h(A\times B)\label{eq:given_h}
% \end{align}

% The proof that the limit exists and the above equality holds can again be found int \citep{kallenberg_basic_2005}.
% \end{proof}

\subsection{Existence of response conditionals}

The main result in this section is Theorem \ref{th:iid_rep} which shows that a probability set $\prob{P}_C$ is causally contractible if and only if it can be represented as the product of a distribution over hypotheses $\prob{P}_\square^{\RV{H}}$ and a collection of identical uniform conditionals $\prob{P}_C^{\RV{Y}_1|\RV{D}_1\RV{H}}$. Note the hypothesis $\RV{H}$ that appears in this conditional; it can be given the interpretation of a random variable that expresses the ``true but initially unknown'' $\RV{Y}_1|\RV{D}_1$ conditional probability.

\begin{theorem}\label{th:table_rep}
Given a probability set $\prob{P}_C$ and variables $\RV{D}:=(\RV{D}_i)_{i\in \mathbb{N}}$ and $\RV{Y}:=(\RV{Y}_i)_{i\in \mathbb{N}}$, $\prob{P}_C$ is  $(\RV{D};\RV{Y})$-causally contractible if and only if there exists a column exchangeable probability distribution $\mu^{\RV{Y}^D}\in \Delta(Y^{|D|\times \mathbb{N}})$ such that
\begin{align}
    \prob{P}_C^{\RV{Y}|\RV{D}} &= \tikzfig{lookup_representation}\label{eq:lup_rep}\\
    &\iff\\
    \prob{P}_C^{\RV{Y}|\RV{D}}(y|(d_i)_{i\in \mathbb{N}}) &= \mu^{\RV{Y}^D} \Pi_{(d_i i)_{i\in\mathbb{N}}}(y)
\end{align}
Where $\Pi_{(d_i i)_{i\in\mathbb{N}}}:Y^{|D|\times \mathbb{N}}\to Y^{\mathbb{N}}$ is the function that projects the $(d_i,i)$ indices for all $i\in \mathbb{N}$ and $\prob{F}_{\text{ev}}$ is the Markov kernel associated with the evaluation map
\begin{align}
    \text{ev}:D^\mathbb{N}\times Y^{D\times \mathbb{N}}&\to Y\\
    ((d_i)_\mathbb{N},(y_{ij})_{i\in D,j\in \mathbb{N}})&\mapsto (y_{d_i i})_{i\in \mathbb{N}}
\end{align}
\end{theorem}

\begin{proof}
Appendix \ref{sec:ccontract_appendix}.
\end{proof}

We would prefer to talk about $\RV{Y}^D$ as a latent variable, rather than needing to refer to the the factorisation of a model in terms of $\mu^{\RV{Y}^D}$ in Equation \ref{eq:lup_rep}. This motivates the definition of an \emph{augmented} causally contractible model.

\begin{lemma}[Augmented causally contractible model]\label{lem:aug_cc}
Given a $(\RV{D};\RV{Y})$-causally contractible model $\prob{P}_C'$ on $(\Omega',\sigalg{F}')$, there exists an \emph{augmented} model $\prob{P}_C$ on $(\Omega,\sigalg{F}):=((\Omega'\times Y^D,\sigalg{F}'\otimes\sigalg{Y}^D)$ such that $\prob{P}_C\Pi_{\Omega'}=\prob{P}_C'$ and, defining $\RV{Y}^D:\Omega\times Y^D\to Y^D$ as the projection onto $Y^D$
\begin{align}
    \prob{P}_C^{\RV{Y}|\RV{D}} &= \tikzfig{lookup_representation_variablised}\label{eq:lup_rep_varb}
\end{align}
\end{lemma}

\begin{proof}
Appendix \ref{sec:ccontract_appendix}.
\end{proof}

An augmented causally contractible model looks in some respects similar to a potential outcomes model - both have a distribution over an unobserved ``tabular'' variable $\RV{Y}^D$, and the value of $\RV{Y}_i$ given $\RV{D}$ is deterministically equal to the $\RV{Y}_i^\RV{D}$ (abusing notation). However, the $\RV{Y}^D$ in an augmented causally contractible model usually can't be interpreted as potential outcomes. For example, consider a series of bets on fair coin flips. Model the consequence $\RV{Y}_i$ as uniform on $\{0,1\}$ for any decision $\RV{D}_i$, for all $i$. Specifically, $D=Y=\{0,1\}$ and $\prob{P}_\alpha^{\RV{Y}_n}(y)=\prod_{i\in [n]} 0.5$ for all $n$, $y\in Y^n$, $\alpha\in R$. Then the construction of $\prob{P}^{\RV{Y}^D}$ following the method in Lemma \ref{th:table_rep} yields $\prob{P}^{Y^D_i}(y^D_i)=\prod_{j\in D} 0.5$ for all $y^D_i\in Y^D$. In this model $\RV{Y}^0_i$ and $\RV{Y}^1_i$ are independent and uniformly distributed. However, if we wanted $\RV{Y}^0_i$ to be interpretable as ``what would happen if I bet on outcome 0 on turn $i$'' and $\RV{Y}^1$ to represent ``what would happen if I bet on outcome 1 on turn $i$'', then we ought to have $\RV{Y}^0_i = 1-\RV{Y}^1_i$.

The following is the main theorem of this section, that establishes the equivalence between causal contractibility and the existence of response conditionals. The argument in outline is: because $\prob{P}_C^{\RV{Y}^D}$ is a column exchangeable probability distribution we can apply De Finetti's theorem to show $\prob{P}_C^{\RV{Y}^D}$ is representable as a product of identical parallel copies of $\prob{P}_C^{\RV{Y}_1^D|\RV{H}}$ and a common prior $\prob{P}_C^{\RV{H}}$. This in turn can be used to show that $\prob{P}_C^{\RV{Y}|\RV{D}}$ can be represented as a product of identical parallel copies of $\prob{P}_C^{\RV{Y}_1|\RV{D}_1\RV{H}}$ and the same common prior $\prob{P}_C^{\RV{H}}$.

\begin{theorem}\label{th:iid_rep}
Suppose we have a sample space $(\Omega,\sigalg{F})$ and a probability set $\prob{P}_C$ and variables $\RV{D}:=(\RV{D}_i)_{i\in \mathbb{N}}$ and $\RV{Y}:=(\RV{Y}_i)_{i\in \mathbb{N}}$. Suppose also that  $\prob{P}_C$ is $(\RV{D};\RV{Y})$-causally contractible if and only if there exists some $\RV{H}:\Omega\to H$ such that $\prob{P}^{\RV{H}}_C$ and $\prob{P}_C^{\RV{Y}_i|\RV{H}\RV{D}_i}$ exist for all $i\in \mathbb{N}$ and
\begin{align}
    \prob{P}_C^{\RV{Y}|\RV{D}} &= \tikzfig{do_model_representation}\\
    &\iff\\
    \RV{Y}_i&\CI^e_{\prob{P}_C} \RV{Y}_{\mathbb{N}\setminus i},\RV{D}_{\mathbb{N}\setminus i}C|\RV{H}\RV{D}_i&\forall i\in \mathbb{N}\\
    \land \RV{H} &\CI^e_{\prob{P}_C} \RV{D} C\\
    \land \RV{D}_i&\CI_{\prob{P}_C}^e \RV{Y}_{<i>} C|\RV{D}_{<i}\\
    \land \prob{P}_C^{\RV{Y}_i|\RV{H}\RV{D}_i} &= \prob{P}^{\RV{Y}_0|\RV{H}\RV{D}_0} & \forall i\in \mathbb{N}
\end{align}
Where $\Pi_{D,i}:D^\mathbb{N}\kto D$ is the $i$th projection map.
\end{theorem}

\begin{proof}
Appendix \ref{sec:ccontract_appendix}.
\end{proof}

\subsection{Elaborations and examples}

Theorem \ref{th:iid_rep} requires an infinite sequence of causally contractible pairs. In practice we only want to model finite sequences of variables, but this theorem applies as long as it is possible to extend the finite model to an infinite model maintaining causal contractibility.


Theorem \ref{th:iid_rep} applies whatever procedure we use to obtain the $(\RV{D}_i,\RV{Y}_i)$ pairs -- the $\RV{D}_i$s may be randomised, passive observations or active choices. Purely passive observations can be modeled with a probability set of size 1, and in this case an exchangeable sequence of $(\RV{D}_i,\RV{Y}_i)$ will also be causally contractible.

If we are modelling $M$ passive observations followed by $N$ active choices, then we will have a model $\prob{P}_C$ with $\RV{D}_{[M]}\CI_{\prob{P}_C}^e C$ (because these are passive observations). If this model is $(\RV{D};\RV{Y})$-causally contractible, then one consequence of this is an ``observational imitation'' condition: any choice $\alpha$ that makes $\prob{P}_\alpha^{\RV{D}_{[M+N]}}$ exchangeable also makes $\prob{P}_\alpha^{\RV{Y}_{[M+N]}}$ exchangeable. That is, if for some permutation $\mathrm{swap}_\rho$
\begin{align}
    \prob{P}_\alpha^{\RV{D}_{[M+N]}}\mathrm{swap}_\rho &= \prob{P}_\alpha^{\RV{D}_{[M+N]}}
\end{align}
then by commutativity of exchange
\begin{align}
    \prob{P}_\alpha^{\RV{Y}_{[M+N]}} &= \prob{P}_\alpha^{\RV{D}_{[M+N]}} \prob{P}_C^{\RV{Y}_{[M+N]}|\RV{D}_{[M+N]}}\\
    &=  \prob{P}_\alpha^{\RV{D}_{[M+N]}}\mathrm{swap}_\rho \prob{P}_C^{\RV{Y}_{[M+N]}|\RV{D}_{[M+N]}}\\
    &= \prob{P}_\alpha^{\RV{D}_{[M+N]}} \prob{P}_C^{\RV{Y}_{[M+N]}|\RV{D}_{[M+N]}}\mathrm{swap}_\rho\\
    &= \prob{P}_\alpha^{\RV{Y}_{[M+N]}}\mathrm{swap}_\rho
\end{align}

If we assume a probability set $\prob{P}_C$ is $(\RV{D},\RV{X};\RV{Y})$-causally contractible and $\RV{X}_{i}\CI^e_{\prob{P}_C}\RV{D}_{i}C|\RV{H}$ -- that is, $\RV{D}_i$ is must be independent of $\RV{X}_i$ conditional on $\RV{H}$ -- then we get a version of the ``backdoor adjustment'' formula. Specifically
\begin{align}
    \prob{P}_\alpha^{\RV{Y}_{i}|\RV{D}_{i}\RV{H}}(A|d,h) &= \int_X \prob{P}_\alpha^{\RV{Y}_{i}|\RV{X}_{i}\RV{D}_{i}\RV{H}}(A|d,x,h)\prob{P}_\alpha^{\RV{X}_{i}|\RV{D}_{i}\RV{H}}(\mathrm{d}x|d,h)\\
    &= \int_X \prob{P}_C^{\RV{Y}_{1}|\RV{X}_{1}\RV{D}_{1}\RV{H}}(A|d,x,h)\prob{P}_C^{\RV{X}_{i}|\RV{H}}(\mathrm{d}x|h)
\end{align}

If we additionally assume $\prob{P}_C^{\RV{X}_{i}|\RV{H}}\cong \prob{P}_C^{\RV{X}_{1}|\RV{H}}$ then 
\begin{align}
    \prob{P}_\alpha^{\RV{Y}_{i}|\RV{D}_{i}\RV{H}}(A|d,h) &= \int_X \prob{P}_C^{\RV{Y}_{1}|\RV{X}_{1}\RV{D}_{1}\RV{H}}(A|d,x,h)\prob{P}_C^{\RV{X}_{1}|\RV{H}}(\mathrm{d}x|h)\label{eq:backdoor}
\end{align}

Equation \ref{eq:backdoor} is identical to the backdoor adjustment formula for an intervention on $\RV{D}_1$ targeting $\RV{Y}_1$ where $\RV{X}_1$ is a common cause of both.

While it is formally possible to use a causally contractible model for a decision procedure that involves both passive observations and active choices, causal contractibility is a very strong assumption. Suppose we have a decision procedure in which $M$ passive observations are made $(\RV{D}_M,\RV{Y}_M)$, followed by $M$ active choices $(\RV{D}_{(M,2M]},\RV{Y}_{(M,2M]})$. If a model $\prob{P}_C$ of this procedure is $(\RV{D}_{2M},\RV{Y}_{2M})$-causally contractible model then the following holds (see corollary \ref{th:equal_of_condits}):
\begin{align}
    \prob{P}^{\RV{Y}_{[2,M+1]}|\RV{D}_{[2,M+1]}}_C &= \prob{P}^{\RV{Y}_{(M,2M]}|\RV{D}_{(M,2M]}}\\
    \implies \prob{P}^{\RV{Y}_{M+1}|\RV{D}_{[2,M+1]}\RV{Y}_{[2,M]}}_C &= \prob{P}^{\RV{Y}_{M+1}|\RV{D}_{(M,2M]}\RV{Y}_{(M+1,2M]}}
\end{align}
That is, causal contractibility implies that there is no difference between conditioning on observational results or on the results of active choices; active choices are as good for predicting observations as vise-versa. Normally one might consider randomised experimental results to be ``better'' than passive observations, but this is not compatible with the assumption of causal contractibility.

\subsection{Assessing causal contractibility}\label{ssec:assessing}

Assessing when a particular sequence of experiments should be modeled with a causally contractible model can be difficult. One way to justify the assumption is in two steps: first, all the repetitions of the experiment that yield the values of each of the $(\RV{D}_i,\RV{Y}_i)$ pairs are indistinguishable ``at the time of model construction'', and and they are still indistinguishable after learning the value of $\RV{D}$ -- because, for example, $\RV{D}$ is deterministic for each choice $\alpha\in C$. 

Two step justifications of this form are common in literature on causal identifiability. For example, \citet{greenland_identifiability_1986} explain

\begin{quote}
    Equivalence of response type may be thought of in terms of exchangeability of individuals: if the exposure states of the two individuals had been exchanged, the same data distribution would have resulted.
\end{quote}

Note that exchanging individuals involved in an experiment and exchanging the individuals' exposure states are two different things, and the former doesn't imply the latter. We may consider a model that is symmetric to permutations of individual identifiers but is not symmetric to permuting individual identifiers and leaving exposure states fixed.

\citet{dawid_decision-theoretic_2020} suggests (with many qualifications) that ``post-treatment exchangeability'' for a decision problem regarding taking aspirin to treat a headache may be acceptable if the data are from

\begin{quote}
    A group of individuals whom I can regard, in an intuitive sense, as similar to myself, with headaches similar to my own.
\end{quote}

Dawid points to the ``first step'' in our two step justification for causal contractibility: that the people involved are ``similar'' in an appropriate sense. However, under Dawid's approach there is a background assumption here that whether or not I take the aspirin is deterministic given the choice I end up making, which is the second step in our two step justification.

Finally, \citet{rubin_causal_2005} explicitly discusses two separate assumptions to justify causal identifiability:

\begin{quote}
    indexing of the units is, by definition, a random permutation of $1,..., N$, and thus any distribution on the science must be row-exchangeable [...] The second critical fact is that if the treatment assignment mechanism is ignorable (e.g., randomized), then when the expression for the assignment mechanism (2) is evaluated at the observed data, it is free of dependence on $Y_{mis}$
\end{quote}

Here we have a more abstract statement about the row-exchangeability of ``the science'', rather than individual people involved in an experiment, but we regard it as similar in spirit to assumptions that people involved in the experiment are ``similar''. Rubin explicitly mentions a second condition: that the treatment assignment is randomized.

Theorem \ref{th:cc_ind_treat} formalises these ideas. As an example of its application, consider an experiment where $N$ patients, each with an individual identifier $\RV{I}_i$, receive treatment $\RV{D}_i$ and experience outcome $\RV{Y}_i$. We assume a $((\RV{D},\RV{I});\RV{Y})$-causally contractible model $\prob{P}_C$ is appropriate. This reflects two judgments; firstly, that treatment $\RV{D}_i$ and identifiers $\RV{I}_i$ screen off all other variables from $\RV{Y}_i$ (Definition \ref{def:caus_cont}), and secondly that the order in which the individuals appear and the treatments are received does not alter the consequences we expect to see (Definition \ref{def:caus_exch}). The fact that we need a preliminary assumption of causal contractibility is similar to how, in the potential outcomes framework, a preliminary assumption of SUTVA is required in order to justify the use of potential outcomes.

Next, we assume that, no matter which choice $\alpha\in C$ is decided on, all identifiers can be swapped without altering the distribution over consequences, and finally that for each choice $\alpha\in C$ the treatment vector $\RV{D}$ is deterministic. Then, according to Theorem \ref{th:cc_ind_treat}, $\prob{P}_C$ is also $(\RV{D};\RV{Y})$-causally contractible. This can be extended to the case where $\RV{D}$ is a function of a ``random signal'' $\RV{R}$.

\begin{lemma}\label{lem:ind_to_cc}
If $\prob{P}_C$ is $((\RV{D},\RV{I});\RV{Y})$-causally contractible and $\RV{Y}\CI_{\prob{P}_C}^e \RV{I}C|\RV{D}$, then $\prob{P}_C$ is also $(\RV{D};\RV{Y})$-causally contractible.
\end{lemma}

\begin{proof}
For arbitrary $\nu\in \Delta(I^{\mathbb{N}})$, by assumption of $((\RV{D},\RV{I});\RV{Y})$-causal contractibility and Theorem \ref{th:iid_rep}
\begin{align}
    \prob{P}_C^{\RV{Y}|\RV{DI}} &= \tikzfig{index_independence_1}\\
    &= \tikzfig{index_independence_2}\\
    &= \tikzfig{index_independence_3}\\
    \implies \prob{P}_C^{\RV{Y}|\RV{D}} &= \tikzfig{index_independence_4}
\end{align}
Applying Theorem \ref{th:iid_rep} in reverse, we get $\prob{P}_C$ is $(\RV{D};\RV{Y})$-causally contractible.
\end{proof}

\begin{definition}[Index variable]
Suppose we have a probability set $\prob{P}_C$ and a variable $\RV{I}:\Omega\to \mathbb{N}^{\mathbb{N}}$, such that, defining $A\subset\mathscr{P}(\mathbb{N})$ to be the set of all permutations of $\mathbb{N}$, $\prob{P}_\alpha^{\RV{I}}(A)=1$. Then $\RV{I}$ is an \emph{index variable}.
\end{definition}

\begin{lemma}\label{lem:ind}
Suppose we have a probability set $\prob{P}_C$ where $\RV{Y}\CI_{\prob{P}_C}^e C|(\RV{D},\RV{I})$ and $\RV{I}$ is an index variable. If for each permutation $\rho:\mathbb{N}\to \mathbb{N}$
\begin{align}
    \prob{P}_\alpha^{\RV{Y}|\RV{ID}} &= (\text{swap}_{\rho(I)}\otimes \text{Id}_X )\prob{P}_\alpha^{\RV{Y}|\RV{ID}}
\end{align}
then $\RV{Y}\CI_{\prob{P}_C}^e \RV{I}C|\RV{D}$.
\end{lemma}

\begin{proof}
Taking $A\subset \mathbb{N}^{\mathbb{N}}$ to be the set of permutations of $\mathbb{N}$, note that for every $i\in A$, $B\in\sigalg{Y}^{\mathbb{N}}$, $d\in D^{\mathbb{N}}$ we can take $\rho_i:\mathbb{N}\to \mathbb{N}$ such that the image of $i$ under $\rho$ is $\mathbb{N}$; that is, $\rho_i(i)=\text{id}_{\mathbb{N}}$. Then
\begin{align}
    \prob{P}_C^{\RV{Y}|\RV{ID}}(B|i,d) &= (\text{swap}_{\rho_i(I)}\otimes \text{Id}_X )\prob{P}_C^{\RV{Y}|\RV{ID}}(B|i,d)\\
    &= \prob{P}_C^{\RV{Y}|\RV{ID}}(B|\text{id}_{\mathbb{N}},d)
\end{align}
Therefore
\begin{align}
    \prob{P}_C^{\RV{Y}|\RV{ID}} &\overset{\prob{P}_C}{\cong} \text{erase}_{\mathbb{N}^{\mathbb{N}}}\otimes \kernel{K} 
\end{align}
where $\kernel{K}:D^{\mathbb{N}}\kto Y^{\mathbb{N}}$ is the kernel
\begin{align}
    (B|d)\mapsto \prob{P}_C^{\RV{Y}|\RV{ID}}(B|\text{id}_{\mathbb{N}},d)
\end{align}
\end{proof}


\begin{theorem}\label{th:cc_ind_treat}
Suppose we have a probability set $\prob{P}_C$, $C$ countable, that $((\RV{D},\RV{I});\RV{Y})$-causally contractible for variables $\RV{Y}:\Omega\to Y^{\mathbb{N}}$, $D:\Omega\to D^{\mathbb{N}}$ and index variable $\RV{I}:\Omega\to \mathbb{N}^{\mathbb{N}}$. If for each $\alpha\in C$, $\rho:\mathbb{N}\to \mathbb{N}$
\begin{align}
    \prob{P}_\alpha^{\RV{Y}|\RV{I}} &= \text{swap}_{\rho(I)}\prob{P}_\alpha^{\RV{Y}|\RV{I}}
\end{align}
and there is an invertible function $f:C\to D$ such that
\begin{align}
    \prob{P}_\alpha^{\RV{D}} = \kernel{F}_f
\end{align}
then $\prob{P}_C$ is $(\RV{D};\RV{Y})$-causally contractible.
\end{theorem}

\begin{proof}
The map $\kernel{Q}:(B|i,\alpha)\mapsto \prob{P}_\alpha^{\RV{Y}|\RV{I}}(B|i)$ is itself a Markov kernel. By assumption, for any $\alpha$,
\begin{align}
    \kernel{Q} \overset{\prob{P}_\alpha}{\cong} (\text{id}_{\mathbb{N}^\mathbb{N}}\otimes\kernel{F}_f) \prob{P}_\alpha^{\RV{Y}|\RV{ID}}
\end{align}
Furthermore, by assumption
\begin{align}
    (\text{swap}_{\rho(I)}\otimes \text{Id}_{C} )\kernel{Q} = \kernel{Q}
\end{align}
Therefore
\begin{align}
    (\text{swap}_{\rho(I)}\otimes \text{Id}_{C} ) \prob{P}_\alpha^{\RV{Y}|\RV{ID}}&= (\text{id}_{\mathbb{N}^\mathbb{N}}\otimes\kernel{F}_{f})(\text{id}_{\mathbb{N}^\mathbb{N}}\otimes\kernel{F}_{f^-1})(\text{swap}_{\rho(I)}\otimes \text{Id}_{C} ) \prob{Q}\\
     &= (\text{id}_{\mathbb{N}^\mathbb{N}}\otimes\kernel{F}_{f^{-1}}) \prob{Q}\\
     &= \prob{P}_\alpha^{\RV{Y}|\RV{ID}}
\end{align}
Then by Lemma \ref{lem:ind} we have $\RV{Y}\CI_{\prob{P}_C}^e \RV{I}C|\RV{D}$ and by Lemma \ref{lem:ind_to_cc} we have $(\RV{D};\RV{Y})$-causal contractibility.
\end{proof}

If we suppose Theorem \ref{th:cc_ind_treat} applies to $C'\subset C$ such that $\RV{D}$ is deterministic for all $\alpha\in C'$, while $C$ consists of $C'$ and all ``random choices between elements of $C'$''; that is for all $\beta\in C$
\begin{align}
    \prob{P}_\beta &= \sum_{c\in C} k_c \prob{P}_c 
\end{align} 

Then it follows that
\begin{align}
    \prob{P}_\beta^{\RV{Y}|\RV{D}} &= \sum_{c\in C} k_c \prob{P}_c^{\RV{Y}|\RV{D}}
\end{align}
and hence $\prob{P}_C$ is still $(\RV{D};\RV{Y})$-causally contractible. Note that in order to actually implemented a random choice, we would typically consult a known random source $\RV{R}$ and set $\RV{D}$ deterministically on the basis of the value of $\RV{R}$.

\subsection{Body mass index revisited}

If we have a probability set $\prob{P}_C$ with $\RV{B}:=(\RV{B}_i)_{i\in M}$ representing body mass index and $\RV{Y}:=(\RV{Y}_i)_{i\in M}$ representing health outcomes of interest, the previous considerations don't support a judgement of causal contractibility for $(\RV{B};\RV{Y})$, because the choices we imagine we might have available do not allow $\RV{B}$ to be a deterministic invertible function of the choice. Note that we haven't established that causal contractibility cannot be appropriate, merely that we have no reason to accept it on the basis of arguments so far.

Causal contractibility is the a priori assumption that there is a response function relating each pair from a sequence of pairs of variables. However, we could also consider the possibility that we conclude that there is such a response function after reviewing the data.

Suppose we are in possession of a $(\RV{D};(\RV{B},\RV{Y}))$-causally contractible probability set $\prob{P}_C$, such that each $(\RV{D}_i,\RV{B}_i,\RV{Y}_i)$ is related by the response conditional $\prob{P}_C^{\RV{Y}_1\RV{B}_1|\RV{D}_1\RV{H}}$. Suppose that we also have an ``oracle'' available that performs an infinite number of samples under appropriate conditions and reveals the value $h\in H$ yielded by the variable $\RV{H}$. Then we can consider the new probability set $\prob{P}_{C,h}$ where for arbitrary $\RV{Z}:\Omega\to Z$, $A\in \sigalg{Z}$
\begin{align}
    \prob{P}_{C,h}^{\RV{Z}}(A) &= \prob{P}_C^{\RV{Z}|\RV{H}}(A|h)
\end{align}

Note that $\prob{P}_{C,h}$ remains $(\RV{D};(\RV{B},\RV{Y}))$-causally contractible with response conditionals $\prob{P}_{C,h}^{\RV{Y}_1\RV{B}_1|\RV{D}_1}$. Furthermore that by Theorem \ref{th:higher_order_conditionals}, we have $((\RV{D},\RV{B});\RV{Y})$-causal contractibility with response conditionals $\prob{P}_{C,h}^{\RV{Y}_1|\RV{D}_1\RV{B}_1}$. In this case, we could find that $\RV{Y}_i\CI_{\prob{P}_{C,h}}^e \RV{D}_i|\RV{B}_i$, and so by Lemma \ref{lem:ind_to_cc} $\prob{P}_{C,h}$ is also $(\RV{B};\RV{Y})$-causally contractible.

In this case, it seems much more reasonable to describe the fact that $\RV{B}$ has a causal effect on $\RV{Y}$ as a \emph{finding}, rather than an \emph{assumption}. 

% \subsection{Weakening causal contractibility}

% We have pointed out that causal contractibility is a very strong assumption, and will usually be unacceptable. We proposed three assumptions that could justify causal contractibility for some decision procedures:

% \begin{enumerate}
%     \item Two procedures $\proc{S}_\alpha$ and $\proc{S}_{\alpha'}$ are indistinguishable if the description of one can be obtained by permuting patients in the description of the other (\emph{patient indistinguishability})
%     \item Two procedures $\proc{S}_\alpha$ and $\proc{S}_{\alpha'}$ are indistinguishable if the description of one can be obtained by permuting the order of treatment administration in the description of the other (\emph{order indistinguishability})
%     \item $c:A\to D^2$ is an invertible function
% \end{enumerate}

% We can imagine that many decision procedures involving patient treatment might satisfy the first two properties, but not the third. A question to explore is: is there a representation theorem relevant to a decision procedure in which the third assumption is removed or weakened? A common assumption in other causal frameworks for procedures like this is to assume that there is some variable $(\RV{X},\RV{Z})$ that is ``causally sufficent'' for $\RV{Y}$, but $\RV{Z}$ is not observed. In our framework, this would amount to $\prob{P}_C$ being $((\RV{X},\RV{Z});\RV{Y})$-causally contractible, with $\RV{Z}$ unobserved. However, at this point we do not know of a relevant representation theorem for unobservable causal contractibility like this, nor of an argument that connects the representation with a particular family of decision procedures.