\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\citation{pearl_causality:_2009}
\citation{rubin_causal_2005}
\citation{korzybski_science_1933}
\citation{hernan_does_2008}
\citation{pearl_does_2018}
\citation{shahar_association_2009}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Variables and Probability Models}{3}{section.2}\protected@file@percent }
\newlabel{sec:vague_variables}{{2}{3}{Variables and Probability Models}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Section outline}{3}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Brief outline of probability gap models}{4}{subsubsection.2.1.1}\protected@file@percent }
\citation{feynman_feynman_1979}
\citation{menger_random_2003}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Semantics of observed and unobserved variables}{5}{subsection.2.2}\protected@file@percent }
\newlabel{sec:variables}{{2.2}{5}{Semantics of observed and unobserved variables}{subsection.2.2}{}}
\citation{pearl_causality:_2009}
\newlabel{def:observable}{{2.4}{7}{Consistency with observation}{theorem.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Events}{8}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Standard probability theory}{8}{subsection.2.4}\protected@file@percent }
\newlabel{def:pushforward}{{2.10}{9}{Marginal distribution with respect to a probability space}{theorem.2.10}{}}
\newlabel{eq:disint_def}{{5}{9}{Disintegration}{equation.2.5}{}}
\newlabel{def:disint}{{2.12}{9}{Conditional probability with respect to a probability space}{theorem.2.12}{}}
\citation{cho_disintegration_2019}
\citation{hajek_what_2003}
\newlabel{lem:disint_exist}{{2.14}{10}{Disintegration existence in standard measurable Markov kernels}{theorem.2.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Probabilistic models for causal inference}{10}{subsection.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Probability sets}{11}{subsection.2.6}\protected@file@percent }
\newlabel{def:cprob_pset}{{2.17}{12}{Conditional probability with respect to a probability set}{theorem.2.17}{}}
\newlabel{th:recurs_pushf}{{2.18}{12}{Recursive pushforward}{theorem.2.18}{}}
\newlabel{def:copyproduct}{{2.19}{12}{Semidirect product}{theorem.2.19}{}}
\newlabel{def:asequal}{{2.21}{13}{Almost sure equality}{theorem.2.21}{}}
\newlabel{lem:joint_conditional}{{2.24}{13}{Semidirect product of conditionals is a joint conditional}{theorem.2.24}{}}
\citation{richardson2013single,pearl_causality:_2009}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Probability sets defined by marginal and conditional probabilities}{14}{subsection.2.7}\protected@file@percent }
\newlabel{def:valid_dist}{{2.25}{14}{Valid distribution}{theorem.2.25}{}}
\newlabel{def:valid_conditional_prob}{{2.26}{14}{Valid conditional}{theorem.2.26}{}}
\citation{chiribella_quantum_2008,jacobs_causal_2019}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}Probability gap models}{15}{subsection.2.8}\protected@file@percent }
\newlabel{eq:semidirect_intersection}{{40}{15}{Probability gap models}{equation.2.40}{}}
\citation{shahar_association_2009}
\citation{constantinou_extended_2017}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9}Example: invalidity}{16}{subsection.2.9}\protected@file@percent }
\newlabel{eq:bmi_example}{{41}{16}{Example: invalidity}{equation.2.41}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.1}Conditional independence}{16}{subsubsection.2.9.1}\protected@file@percent }
\newlabel{ssec:cond_indep}{{2.9.1}{16}{Conditional independence}{subsubsection.2.9.1}{}}
\citation{cho_disintegration_2019}
\citation{cho_disintegration_2019}
\newlabel{th:cho_ci_equiv}{{2.30}{17}{}{theorem.2.30}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.10}Curried Markov kernels}{17}{subsection.2.10}\protected@file@percent }
\newlabel{sec:curry}{{2.10}{17}{Curried Markov kernels}{subsection.2.10}{}}
\citation{dawid_causal_2000}
\citation{richardson2013single}
\citation{pearl_causality:_2009}
\citation{rubin_causal_2005}
\newlabel{eq:curry_identity}{{48}{18}{Curried Markov kernels}{equation.2.48}{}}
\citation{ramsey_truth_2016}
\citation{savage_foundations_1954}
\citation{bolker_functions_1966,jeffrey_logic_1990}
\citation{joyce_foundations_1999}
\@writefile{tdo}{\contentsline {todo}{start again here}{19}{section*.2}\protected@file@percent }
\pgfsyspdfmark {pgfid19}{20088093}{39363844}
\@writefile{toc}{\contentsline {section}{\numberline {3}Decision theoretic causal inference}{19}{section.3}\protected@file@percent }
\newlabel{sec:seedo_models}{{3}{19}{Decision theoretic causal inference}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Decision problems}{19}{subsection.3.1}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{I think adding hypotheses at this point might make things unnecessarily confusing; on the other hand, they are useful for the connection to classical statistical decision theory. The "repeatable experiments" section shows how see-do models with certain assumptions induce an easier to understand class of hypotheses, and I could just save the idea of a hypothesis until I get there}{20}{section*.3}\protected@file@percent }
\pgfsyspdfmark {pgfid20}{20088093}{28979192}
\citation{lattimore_causal_2019}
\citation{lattimore_replacing_2019}
\@writefile{tdo}{\contentsline {todo}{I need to update the proof for this claim}{21}{section*.4}\protected@file@percent }
\pgfsyspdfmark {pgfid21}{13754458}{36565011}
\pgfsyspdfmark {pgfid24}{34243869}{36579118}
\pgfsyspdfmark {pgfid25}{36357404}{36353388}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Decisions as measurement procedures}{21}{subsection.3.2}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{I don't know how important this observation is, but the fact that $\ensuremath  {\EuScript  {D}}$ is an output of a formal decision making system makes it different from other things we might call decisions, and I wonder if I should call it something else in order to avoid ambiguity. The vague reason I think this matters is: whatever you might want to measure, you won't learn more about $\ensuremath  {\EuScript  {D}}$ from it than you already know once you have the model, the utility and the decision rule, this is not a property that other things we call ``decisons'' share and this distinction might be important regarding judgements of causal contractibilty.}{21}{section*.5}\protected@file@percent }
\pgfsyspdfmark {pgfid26}{20088093}{15317868}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Causal models similar to see-do models}{21}{subsection.3.3}\protected@file@percent }
\citation{dawid_decision-theoretic_2020}
\citation{heckerman_decision-theoretic_1995}
\citation{jacobs_causal_2019}
\citation{tian2002general}
\citation{von_neumann_theory_1944}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}See-do models and classical statistics}{22}{subsection.3.4}\protected@file@percent }
\citation{wald_statistical_1950}
\citation{dawid_decision-theoretic_2020}
\citation{greenland_identifiability_1986}
\citation{banerjee_chapter_2017}
\citation{de_finetti_foresight_1992}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conditional probabilities in sequential experiments}{24}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Repeatable experiments}{24}{subsection.4.1}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{I think the useful part is not that these ideas are conceptually new, but they have sharp definitions instead of }{24}{section*.6}\protected@file@percent }
\pgfsyspdfmark {pgfid27}{20088093}{12833746}
\@writefile{tdo}{\contentsline {todo}{Not sure if or where I want to put this, I just think it helps to illustrate the difference}{24}{section*.7}\protected@file@percent }
\pgfsyspdfmark {pgfid28}{20088093}{10982371}
\@writefile{tdo}{\contentsline {todo}{----end not sure where to put------}{25}{section*.8}\protected@file@percent }
\pgfsyspdfmark {pgfid33}{20088093}{26215360}
\newlabel{def:caus_exch}{{4.2}{25}{Commutativity of exchange}{theorem.4.2}{}}
\newlabel{def:caus_cont}{{4.3}{26}{Commutativity of marginalisation}{theorem.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}When does a canonical ``effect of a decision'' exist?}{27}{subsection.4.2}\protected@file@percent }
\newlabel{th:table_rep}{{4.2}{27}{When does a canonical ``effect of a decision'' exist?}{subsection.4.2}{}}
\citation{rubin_causal_2005}
\newlabel{th:iid_rep}{{4.6}{30}{}{theorem.4.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}In decison problems, policies are extreme}{30}{subsection.4.3}\protected@file@percent }
\citation{constantinou_extended_2017}
\citation{constantinou_extended_2017}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Extended conditional independence}{33}{subsubsection.4.3.1}\protected@file@percent }
\newlabel{ap:eci}{{4.3.1}{33}{Extended conditional independence}{subsubsection.4.3.1}{}}
\@writefile{tdo}{\contentsline {todo}{Needs a support condition}{33}{section*.9}\protected@file@percent }
\pgfsyspdfmark {pgfid42}{20088093}{32534003}
\newlabel{th:dawid_constantionou}{{4.8}{33}{}{theorem.4.8}{}}
\newlabel{eq:higherorder_ci_erase}{{105}{35}{Unresponsiveness}{equation.4.105}{}}
\newlabel{th:cons_ci}{{4.12}{35}{Conditional independence from kernel unresponsiveness}{theorem.4.12}{}}
\citation{fong_causal_2013}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Graphical properties of conditional independence}{36}{subsubsection.4.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Results I use that don't really fit into the flow of the text}{36}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}Repeated variables}{36}{subsubsection.4.4.1}\protected@file@percent }
\newlabel{lem:nocopy1}{{4.13}{36}{Output copies of the same variable are identical}{theorem.4.13}{}}
\newlabel{lem:nocopy2}{{4.14}{37}{Copies shared between input and output are identical}{theorem.4.14}{}}
\@writefile{tdo}{\contentsline {todo}{This got mixed up at some point and needs ot be unmixed-up}{37}{section*.10}\protected@file@percent }
\pgfsyspdfmark {pgfid59}{20088093}{28412949}
\newlabel{th:valid_disint}{{4.15}{38}{Existence of valid conditional probabilities}{theorem.4.15}{}}
\newlabel{eq:k_disint}{{130}{38}{Repeated variables}{equation.4.130}{}}
\citation{ershov_extension_1975}
\citation{ershov_extension_1975}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Validity}{39}{subsection.4.5}\protected@file@percent }
\newlabel{th:completion}{{4.16}{39}{Validity}{theorem.4.16}{}}
\newlabel{th:intersection}{{4.17}{39}{Copy-product is an intersection of probability sets}{theorem.4.17}{}}
\newlabel{th:valid_agree}{{4.18}{40}{Equivalence of validity definitions}{theorem.4.18}{}}
\newlabel{lem:valid_extendability}{{4.19}{40}{Copy-product of valid candidate conditionals is valid}{theorem.4.19}{}}
\newlabel{corr:valid_extend_order1}{{4.20}{41}{Valid conditionals are validly extendable to valid distributions}{theorem.4.20}{}}
\newlabel{th:valid_conditional_probability}{{4.21}{41}{Validity of conditional probabilities}{theorem.4.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Combs}{41}{subsection.4.6}\protected@file@percent }
\newlabel{ap:combs}{{4.6}{41}{Combs}{subsection.4.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}Comb conditional correspondence}{43}{subsection.4.7}\protected@file@percent }
\newlabel{ap:ccc}{{4.7}{43}{Comb conditional correspondence}{subsection.4.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8}Representation of conditional probability models}{44}{subsection.4.8}\protected@file@percent }
\bibstyle{plainnat}
\bibdata{references}
\bibcite{banerjee_chapter_2017}{{1}{2017}{{Banerjee et~al.}}{{Banerjee, Chassang, and Snowberg}}}
\bibcite{bolker_functions_1966}{{2}{1966}{{Bolker}}{{}}}
\bibcite{chiribella_quantum_2008}{{3}{2008}{{Chiribella et~al.}}{{Chiribella, D'Ariano, and Perinotti}}}
\newlabel{eq:pci_1}{{186}{46}{Representation of conditional probability models}{equation.4.186}{}}
\newlabel{eq:pci_2}{{187}{46}{Representation of conditional probability models}{equation.4.187}{}}
\newlabel{eq:pci_4}{{189}{46}{Representation of conditional probability models}{equation.4.189}{}}
\newlabel{eq:pci_5}{{190}{46}{Representation of conditional probability models}{equation.4.190}{}}
\newlabel{eq:pci_6}{{191}{46}{Representation of conditional probability models}{equation.4.191}{}}
\newlabel{eq:pci_7}{{192}{46}{Representation of conditional probability models}{equation.4.192}{}}
\bibcite{cho_disintegration_2019}{{4}{2019}{{Cho and Jacobs}}{{}}}
\bibcite{constantinou_extended_2017}{{5}{2017}{{Constantinou and Dawid}}{{}}}
\bibcite{dawid_causal_2000}{{6}{2000}{{Dawid}}{{}}}
\bibcite{dawid_decision-theoretic_2020}{{7}{2020}{{Dawid}}{{}}}
\bibcite{de_finetti_foresight_1992}{{8}{[1937] 1992}{{de~Finetti}}{{}}}
\bibcite{ershov_extension_1975}{{9}{1975}{{Ershov}}{{}}}
\bibcite{feynman_feynman_1979}{{10}{1979}{{Feynman}}{{}}}
\bibcite{fong_causal_2013}{{11}{2013}{{Fong}}{{}}}
\bibcite{greenland_identifiability_1986}{{12}{1986}{{GREENLAND and ROBINS}}{{}}}
\bibcite{heckerman_decision-theoretic_1995}{{13}{1995}{{Heckerman and Shachter}}{{}}}
\bibcite{hernan_does_2008}{{14}{2008}{{Hernán and Taubman}}{{}}}
\bibcite{hajek_what_2003}{{15}{2003}{{Hájek}}{{}}}
\bibcite{jacobs_causal_2019}{{16}{2019}{{Jacobs et~al.}}{{Jacobs, Kissinger, and Zanasi}}}
\bibcite{jeffrey_logic_1990}{{17}{1965}{{Jeffrey}}{{}}}
\bibcite{joyce_foundations_1999}{{18}{1999}{{Joyce}}{{}}}
\bibcite{korzybski_science_1933}{{19}{1933}{{Korzybski}}{{}}}
\bibcite{lattimore_causal_2019}{{20}{2019{a}}{{Lattimore and Rohde}}{{}}}
\bibcite{lattimore_replacing_2019}{{21}{2019{b}}{{Lattimore and Rohde}}{{}}}
\bibcite{menger_random_2003}{{22}{2003}{{Menger}}{{}}}
\bibcite{pearl_causality:_2009}{{23}{2009}{{Pearl}}{{}}}
\bibcite{pearl_does_2018}{{24}{2018}{{Pearl}}{{}}}
\bibcite{ramsey_truth_2016}{{25}{2016}{{Ramsey}}{{}}}
\bibcite{richardson2013single}{{26}{2013}{{Richardson and Robins}}{{}}}
\bibcite{rubin_causal_2005}{{27}{2005}{{Rubin}}{{}}}
\bibcite{savage_foundations_1954}{{28}{1954}{{Savage}}{{}}}
\bibcite{shahar_association_2009}{{29}{2009}{{Shahar}}{{}}}
\bibcite{tian2002general}{{30}{2002}{{Tian and Pearl}}{{}}}
\bibcite{von_neumann_theory_1944}{{31}{1944}{{Von~Neumann and Morgenstern}}{{}}}
\bibcite{wald_statistical_1950}{{32}{1950}{{Wald}}{{}}}
