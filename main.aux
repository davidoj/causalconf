\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\citation{pearl_causality:_2009}
\citation{rubin_causal_2005}
\HyPL@Entry{0<</S/D>>}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{korzybski_science_1933}
\citation{hernan_does_2008}
\citation{pearl_does_2018}
\citation{shahar_association_2009}
\@writefile{tdo}{\contentsline {todo}{I'm probably going to have to cut some of the above}{3}{section*.2}\protected@file@percent }
\pgfsyspdfmark {pgfid1}{20088093}{15770884}
\@writefile{toc}{\contentsline {section}{\numberline {2}Probability with connectable submodels}{3}{section.2}\protected@file@percent }
\citation{pearl_causality:_2009}
\citation{pearl_causality:_2009}
\citation{dawid_causal_2000}
\newlabel{eq:truncated_fac}{{1}{4}{Probability with connectable submodels}{equation.2.1}{}}
\citation{fritz_synthetic_2020,cho_disintegration_2019}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Markov categories}{5}{subsection.2.1}\protected@file@percent }
\citation{fritz_synthetic_2020,cho_disintegration_2019,fong_causal_2013}
\citation{selinger_survey_2010}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Truncated factorisation with Markov kernels}{7}{subsection.2.2}\protected@file@percent }
\newlabel{eq:tfac_setted}{{10}{7}{Truncated factorisation with Markov kernels}{equation.2.10}{}}
\newlabel{eq:double_label}{{11}{7}{Truncated factorisation with Markov kernels}{equation.2.11}{}}
\@writefile{tdo}{\contentsline {todo}{A more general version of non-contradiction is desirable}{8}{section*.3}\protected@file@percent }
\pgfsyspdfmark {pgfid26}{20088093}{17765172}
\@writefile{tdo}{\contentsline {todo}{The following proofs are not done with string diagrams because we'd need a more general version of non-contradiction to do it}{9}{section*.4}\protected@file@percent }
\pgfsyspdfmark {pgfid27}{20088093}{20896894}
\newlabel{lem:nocopy1}{{2.5}{9}{Output copies of the same variable are identical}{theorem.2.5}{}}
\newlabel{lem:nocopy2}{{2.6}{10}{Copies shared between input and output are identical}{theorem.2.6}{}}
\newlabel{lem:nocopy3}{{2.7}{10}{No duplicated inputs}{theorem.2.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Truncated factorisation a third time}{10}{subsection.2.3}\protected@file@percent }
\newlabel{eq:tfac_labeled}{{35}{10}{Truncated factorisation a third time}{equation.2.35}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Submodels}{11}{subsection.2.4}\protected@file@percent }
\citation{cho_disintegration_2019}
\newlabel{eq:submodel}{{36}{12}{Conditional submodel}{equation.2.36}{}}
\newlabel{lem:subm_exist}{{2.11}{12}{Submodel existence}{theorem.2.11}{}}
\citation{fritz_synthetic_2020}
\citation{constantinou_extended_2017}
\citation{cho_disintegration_2019}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Conditional independence}{13}{subsection.2.5}\protected@file@percent }
\newlabel{ssec:cond_indep}{{2.5}{13}{Conditional independence}{subsection.2.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Variables or vague variables?}{13}{subsection.2.6}\protected@file@percent }
\newlabel{sec:vague_variables}{{2.6}{13}{Variables or vague variables?}{subsection.2.6}{}}
\citation{pearl_causality:_2009}
\citation{menger_random_2003}
\citation{lattimore_causal_2019}
\citation{lattimore_replacing_2019}
\@writefile{toc}{\contentsline {section}{\numberline {3}Decision theoretic causal inference}{15}{section.3}\protected@file@percent }
\newlabel{sec:seedo_models}{{3}{15}{Decision theoretic causal inference}{section.3}{}}
\newlabel{eq:see_do_query}{{45}{15}{Decision theoretic causal inference}{equation.3.45}{}}
\citation{wald_statistical_1950}
\citation{chiribella_quantum_2008}
\citation{jacobs_causal_2019}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}See-do models and classical statistics}{16}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Combs}{16}{subsection.3.2}\protected@file@percent }
\citation{dawid_decision-theoretic_2020}
\citation{pearl_causality:_2009}
\newlabel{eq:kernel_with_hole}{{51}{17}{Combs}{equation.3.51}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Causal Bayesian Networks}{17}{section.4}\protected@file@percent }
\newlabel{sec:CBN}{{4}{17}{Causal Bayesian Networks}{section.4}{}}
\@writefile{tdo}{\contentsline {todo}{We need to rename the consequence variables because otherwise we would have $\ensuremath  {\mathbf  {T}}[\ensuremath  {\mathsf  {XYXY}}|\ensuremath  {\mathsf  {HD}}]$ and the two $\ensuremath  {\mathsf  {X}}$'s and the two $\ensuremath  {\mathsf  {Y}}$'s would be deterministically equal by the ``identical labels'' rule}{17}{section*.5}\protected@file@percent }
\pgfsyspdfmark {pgfid40}{20088093}{14685793}
\citation{jacobs_causal_2019}
\citation{tian2002general}
\@writefile{toc}{\contentsline {section}{\numberline {5}Potential outcomes with and without counterfactuals}{18}{section.5}\protected@file@percent }
\newlabel{sec:potential_outcomes}{{5}{18}{Potential outcomes with and without counterfactuals}{section.5}{}}
\citation{rubin_causal_2005}
\citation{dawid_causal_2000}
\citation{robins_causal_2000}
\@writefile{tdo}{\contentsline {todo}{I have a vague intuition here that you always need some kind of assumption like ``my model is faithful to the real thing'', but if you are stating fairly specific conditions in English you should also be able to state them mathematically. Among other reasons, this is useful because it's easier for other people to know what you mean when you state them.}{19}{section*.6}\protected@file@percent }
\pgfsyspdfmark {pgfid43}{20088093}{23897348}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Potential outcomes in see-do models}{20}{subsection.5.1}\protected@file@percent }
\newlabel{def:potential_outcomes}{{5.1}{20}{Potential outcomes}{theorem.5.1}{}}
\@writefile{tdo}{\contentsline {todo}{How this will change: a potential outcomes model is a comb $\ensuremath  {\mathbf  {K}}[\ensuremath  {\mathsf  {Y}}(W)|\ensuremath  {\mathsf  {H}}]\rightrightarrows \ensuremath  {\mathbf  {K}}[\ensuremath  {\mathsf  {Y}}|\ensuremath  {\mathsf  {W}}\ensuremath  {\mathsf  {Y}}(W)]$.}{20}{section*.7}\protected@file@percent }
\pgfsyspdfmark {pgfid44}{20088093}{34514961}
\newlabel{def:pa_pot_outcomes}{{5.2}{20}{Parallel potential outcomes}{theorem.5.2}{}}
\@writefile{tdo}{\contentsline {todo}{How this will change: a parallel potential outcomes model is a comb $\ensuremath  {\mathbf  {K}}[\ensuremath  {\mathsf  {Y}}(W)|\ensuremath  {\mathsf  {H}}]\rightrightarrows \ensuremath  {\mathbf  {K}}[\ensuremath  {\mathsf  {Y}}_i|\ensuremath  {\mathsf  {W}}_i\ensuremath  {\mathsf  {Y}}(W)]$.}{20}{section*.8}\protected@file@percent }
\pgfsyspdfmark {pgfid45}{20088093}{10360505}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Parallel potential outcomes representation theorem}{21}{subsection.5.2}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{An interesting question is whether there is a similar representation theorem for potential outcomes without the assumption of deterministic reproducibility. I'm reasonably confident that this is a straightforward corollary of the representation theorem proved in my thesis. However, this requires maths not introduced in this draft of the paper.}{21}{section*.9}\protected@file@percent }
\pgfsyspdfmark {pgfid46}{20088093}{41785034}
\newlabel{def:exchangeable}{{5.3}{22}{Exchangeability}{theorem.5.3}{}}
\@writefile{tdo}{\contentsline {todo}{I think this is a very standard thing to do -- propose some $\ensuremath  {\mathsf  {X}}$ and $\ensuremath  {\mathbb  {P}}(\ensuremath  {\mathsf  {X}})$ then introduce some random variable $\ensuremath  {\mathsf  {Y}}$ and $\ensuremath  {\mathbb  {P}}(\ensuremath  {\mathsf  {X}}\ensuremath  {\mathsf  {Y}})$ as if the sample space contained both $\ensuremath  {\mathsf  {X}}$ and $\ensuremath  {\mathsf  {Y}}$ all along.}{22}{section*.10}\protected@file@percent }
\pgfsyspdfmark {pgfid49}{20088093}{22466491}
\newlabel{def:ext_exchangeable}{{5.5}{22}{Extendably exchangeable}{theorem.5.5}{}}
\newlabel{th:cfac_rep}{{5.7}{23}{Potential outcomes representation}{theorem.5.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Appendix:see-do model representation}{24}{section.6}\protected@file@percent }
\newlabel{sec:see-do-rep}{{6}{24}{Appendix:see-do model representation}{section.6}{}}
\@writefile{tdo}{\contentsline {todo}{Modularise the treatment of probability}{24}{section*.11}\protected@file@percent }
\pgfsyspdfmark {pgfid50}{20088093}{25870500}
\newlabel{th:see_do_rep}{{6.1}{24}{See-do model representation}{theorem.6.1}{}}
\newlabel{eq:disint}{{60}{25}{Appendix:see-do model representation}{equation.6.60}{}}
\newlabel{eq:comb_disint}{{61}{25}{Appendix:see-do model representation}{equation.6.61}{}}
\newlabel{eq:t_is_comb_disint_start}{{66}{25}{Appendix:see-do model representation}{equation.6.66}{}}
\newlabel{eq:t_is_comb_disint_end}{{71}{25}{Appendix:see-do model representation}{equation.6.71}{}}
\newlabel{eq:comb_disint_nonuniq}{{74}{26}{Appendix:see-do model representation}{equation.6.74}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Appendix: Connection is associative}{26}{section.7}\protected@file@percent }
\newlabel{sec:connect_associative}{{7}{26}{Appendix: Connection is associative}{section.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Appendix: String Diagram Examples}{27}{section.8}\protected@file@percent }
\newlabel{eq:extn_definition1}{{97}{27}{Connection}{equation.8.97}{}}
\newlabel{eq:extn_definition2}{{99}{27}{Connection}{equation.8.99}{}}
\citation{fritz_synthetic_2020}
\@writefile{toc}{\contentsline {section}{\numberline {9}Markov variable maps and variables form a Markov category}{28}{section.9}\protected@file@percent }
\newlabel{sec:app_mcat}{{9}{28}{Markov variable maps and variables form a Markov category}{section.9}{}}
\newlabel{eq:ccom_1}{{104}{28}{}{equation.9.104}{}}
\newlabel{eq:nat}{{109}{29}{}{equation.9.109}{}}
\citation{fong_causal_2013,cho_disintegration_2019,fritz_synthetic_2020}
\bibstyle{plainnat}
\bibdata{references}
\bibcite{chiribella_quantum_2008}{{1}{2008}{{Chiribella et~al.}}{{Chiribella, D'Ariano, and Perinotti}}}
\bibcite{cho_disintegration_2019}{{2}{2019}{{Cho and Jacobs}}{{}}}
\bibcite{constantinou_extended_2017}{{3}{2017}{{Constantinou and Dawid}}{{}}}
\@writefile{tdo}{\contentsline {todo}{I'm not sure how to formally argue that it is monoidal and symmetric as the relevant texts I've checked all gloss over the functors with respect to which the relevant isomorphisms should be natural, but labels with products were intentionally made to act just like sets with cartesian products which are symmetric monoidal}{30}{section*.12}\protected@file@percent }
\pgfsyspdfmark {pgfid99}{20088093}{18575466}
\bibcite{dawid_causal_2000}{{4}{2000}{{Dawid}}{{}}}
\bibcite{dawid_decision-theoretic_2020}{{5}{2020}{{Dawid}}{{}}}
\bibcite{fong_causal_2013}{{6}{2013}{{Fong}}{{}}}
\bibcite{fritz_synthetic_2020}{{7}{2020}{{Fritz}}{{}}}
\bibcite{hernan_does_2008}{{8}{2008}{{Hern√°n and Taubman}}{{}}}
\bibcite{jacobs_causal_2019}{{9}{2019}{{Jacobs et~al.}}{{Jacobs, Kissinger, and Zanasi}}}
\bibcite{korzybski_science_1933}{{10}{1933}{{Korzybski}}{{}}}
\bibcite{lattimore_causal_2019}{{11}{2019{a}}{{Lattimore and Rohde}}{{}}}
\bibcite{lattimore_replacing_2019}{{12}{2019{b}}{{Lattimore and Rohde}}{{}}}
\bibcite{menger_random_2003}{{13}{2003}{{Menger}}{{}}}
\bibcite{pearl_causality:_2009}{{14}{2009}{{Pearl}}{{}}}
\bibcite{pearl_does_2018}{{15}{2018}{{Pearl}}{{}}}
\bibcite{robins_causal_2000}{{16}{2000}{{Robins and Greenland}}{{}}}
\bibcite{rubin_causal_2005}{{17}{2005}{{Rubin}}{{}}}
\bibcite{selinger_survey_2010}{{18}{2010}{{Selinger}}{{}}}
\bibcite{shahar_association_2009}{{19}{2009}{{Shahar}}{{}}}
\bibcite{tian2002general}{{20}{2002}{{Tian and Pearl}}{{}}}
\bibcite{wald_statistical_1950}{{21}{1950}{{Wald}}{{}}}
