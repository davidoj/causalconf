\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\citation{pearl_causality:_2009}
\citation{rubin_causal_2005}
\citation{korzybski_science_1933}
\citation{hernan_does_2008}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\citation{pearl_does_2018}
\citation{shahar_association_2009}
\@writefile{toc}{\contentsline {section}{\numberline {2}Variables and Probability Models}{3}{section.2}\protected@file@percent }
\newlabel{sec:vague_variables}{{2}{3}{Variables and Probability Models}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Section outline}{3}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Brief outline of probability gap models}{4}{subsubsection.2.1.1}\protected@file@percent }
\citation{selinger_survey_2010}
\citation{fritz_synthetic_2020,cho_disintegration_2019}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Probability distributions, Markov kernels and string diagrams}{5}{subsection.2.2}\protected@file@percent }
\citation{fritz_synthetic_2020,cho_disintegration_2019,fong_causal_2013}
\citation{selinger_survey_2010}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Examples}{7}{subsubsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Example: comb insertion}{8}{subsubsection.2.2.2}\protected@file@percent }
\newlabel{eq:2comb_M}{{20}{9}{Example: comb insertion}{equation.2.20}{}}
\newlabel{eq:2comb_winsert}{{28}{9}{Example: comb insertion}{equation.2.28}{}}
\citation{feynman_feynman_1979}
\citation{menger_random_2003}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Semantics of observed and unobserved variables}{10}{subsection.2.3}\protected@file@percent }
\newlabel{sec:variables}{{2.3}{10}{Semantics of observed and unobserved variables}{subsection.2.3}{}}
\citation{pearl_causality:_2009}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Events}{12}{subsection.2.4}\protected@file@percent }
\citation{hajek_what_2003}
\citation{pearl_causality:_2009}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Probabilistic models for causal inference}{13}{subsection.2.5}\protected@file@percent }
\newlabel{eq:truncated_fac}{{41}{13}{Probabilistic models for causal inference}{equation.2.41}{}}
\citation{shahar_association_2009}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Probability gaps}{15}{subsection.2.6}\protected@file@percent }
\newlabel{def:pushforward}{{2.9}{15}{Marginal distribution with respect to a probability space}{theorem.2.9}{}}
\newlabel{def:disint}{{2.10}{15}{Conditional probability with respect to a probability space}{theorem.2.10}{}}
\newlabel{lem:prod_pushf}{{2.13}{16}{Equivalence of pushforward definitions}{theorem.2.13}{}}
\newlabel{th:recurs_pushf}{{2.14}{17}{Recursive pushforward}{theorem.2.14}{}}
\@writefile{tdo}{\contentsline {todo}{Copy-paste the relevant theorems}{17}{section*.2}\protected@file@percent }
\pgfsyspdfmark {pgfid23}{20088093}{29021668}
\newlabel{th:recursive-disint}{{2.15}{17}{Recursive disintegration}{theorem.2.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Probability gap models defined by marginal and conditional probabilities}{17}{subsection.2.7}\protected@file@percent }
\citation{hajek_what_2003}
\newlabel{def:copyproduct}{{2.16}{18}{Copy-product}{theorem.2.16}{}}
\@writefile{tdo}{\contentsline {todo}{Mention Kolmogorov consistency}{18}{section*.3}\protected@file@percent }
\pgfsyspdfmark {pgfid26}{20088093}{16438856}
\newlabel{def:valid_dist}{{2.17}{18}{Valid canditate distribution}{theorem.2.17}{}}
\newlabel{def:valid_conditional_prob}{{2.18}{18}{Valid candidate conditional}{theorem.2.18}{}}
\newlabel{def:order_0_marg}{{2.20}{19}{Order 0 model associated with a given marginal}{theorem.2.20}{}}
\newlabel{th:completion}{{2.21}{19}{Completion}{theorem.2.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}Higher order gap models}{20}{subsection.2.8}\protected@file@percent }
\newlabel{sec:validity_of_gapprob}{{2.8}{20}{Higher order gap models}{subsection.2.8}{}}
\newlabel{def:order1_bycond}{{2.23}{20}{Order 1 model defined by a conditional}{theorem.2.23}{}}
\citation{ershov_extension_1975}
\newlabel{th:valid_agree}{{2.24}{21}{Equivalence of validity definitions}{theorem.2.24}{}}
\newlabel{eq:nec_and_suff}{{80}{21}{Higher order gap models}{equation.2.80}{}}
\newlabel{lem:valid_extendability}{{2.25}{21}{Product of valid candidate conditionals is valid}{theorem.2.25}{}}
\citation{chiribella_quantum_2008,jacobs_causal_2019}
\newlabel{corr:valid_extend_order1}{{2.26}{22}{Valid candidate conditional is validly extendable to a valid candidate distribution}{theorem.2.26}{}}
\newlabel{th:valid_conditional_probability}{{2.27}{22}{Validity of conditional probabilities}{theorem.2.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9}Order 2 gaps: probability combs}{22}{subsection.2.9}\protected@file@percent }
\newlabel{eq:insert}{{91}{23}{Order 2 gaps: probability combs}{equation.2.91}{}}
\newlabel{eq:insert_op}{{93}{23}{Order 2 gaps: probability combs}{equation.2.93}{}}
\newlabel{th:extension_2comb_valid}{{2.32}{24}{Extension of valid probability 2-combs}{theorem.2.32}{}}
\newlabel{lem:valid_conditionals}{{2.33}{25}{Valid conditional probabilities combine to a valid 2-comb}{theorem.2.33}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.10}Revisiting truncated factorisation}{25}{subsection.2.10}\protected@file@percent }
\newlabel{sec:truncated_fac_again}{{2.10}{25}{Revisiting truncated factorisation}{subsection.2.10}{}}
\newlabel{eq:int_to_obs}{{105}{25}{Revisiting truncated factorisation}{equation.2.105}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.10.1}Disintegrations}{26}{subsubsection.2.10.1}\protected@file@percent }
\newlabel{lem:disint_exist}{{2.34}{26}{Disintegration existence in discrete Markov kernels}{theorem.2.34}{}}
\newlabel{th:valid_disint}{{2.35}{26}{Existence of conditional probabilities}{theorem.2.35}{}}
\newlabel{eq:k_disint}{{113}{26}{Disintegrations}{equation.2.113}{}}
\citation{constantinou_extended_2017}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.10.2}Conditional independence}{27}{subsubsection.2.10.2}\protected@file@percent }
\newlabel{ssec:cond_indep}{{2.10.2}{27}{Conditional independence}{subsubsection.2.10.2}{}}
\citation{cho_disintegration_2019}
\citation{cho_disintegration_2019}
\newlabel{th:cho_ci_equiv}{{2.37}{28}{}{theorem.2.37}{}}
\newlabel{eq:higherorder_ci_erase}{{125}{29}{Conditional independence from kernel unresponsiveness}{equation.2.125}{}}
\newlabel{th:cons_ci}{{2.42}{29}{}{theorem.2.42}{}}
\citation{constantinou_extended_2017}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.10.3}Extended conditional independence}{30}{subsubsection.2.10.3}\protected@file@percent }
\newlabel{th:dawid_constantionou}{{2.43}{30}{}{theorem.2.43}{}}
\citation{fong_causal_2013}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.11}Recursive disintegration}{32}{subsection.2.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.11.1}Graphical properties of conditional independence}{32}{subsubsection.2.11.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.12}Results I use that don't really fit into the flow of the text}{33}{subsection.2.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.12.1}Repeated variables}{33}{subsubsection.2.12.1}\protected@file@percent }
\newlabel{lem:nocopy1}{{2.46}{33}{Output copies of the same variable are identical}{theorem.2.46}{}}
\citation{ramsey_truth_2016}
\citation{savage_foundations_1954}
\citation{bolker_functions_1966,jeffrey_logic_1990}
\citation{joyce_foundations_1999}
\newlabel{lem:nocopy2}{{2.47}{34}{Copies shared between input and output are identical}{theorem.2.47}{}}
\@writefile{tdo}{\contentsline {todo}{This got mixed up at some point and needs ot be unmixed-up}{34}{section*.4}\protected@file@percent }
\pgfsyspdfmark {pgfid63}{20088093}{42473162}
\@writefile{toc}{\contentsline {section}{\numberline {3}Decision theoretic causal inference}{35}{section.3}\protected@file@percent }
\newlabel{sec:seedo_models}{{3}{35}{Decision theoretic causal inference}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Decision problems}{35}{subsection.3.1}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{$\ensuremath  {\mathsf  {H}}$ parametrises observations and consequences together; not just a function of observations so req. slight generalisation of De Finetti}{36}{section*.5}\protected@file@percent }
\pgfsyspdfmark {pgfid70}{20088093}{28219091}
\citation{nozick_newcombs_1969}
\citation{weirich_causal_2016,lewis_causation_1986}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}What should a probability model represent? Controversies about decision theories}{37}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Decisions as measurement procedures}{37}{subsection.3.3}\protected@file@percent }
\citation{lattimore_causal_2019}
\citation{lattimore_replacing_2019}
\citation{dawid_decision-theoretic_2020}
\citation{heckerman_decision-theoretic_1995}
\citation{jacobs_causal_2019}
\citation{tian2002general}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Causal models similar to see-do models}{38}{subsection.3.4}\protected@file@percent }
\citation{von_neumann_theory_1944}
\citation{wald_statistical_1950}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}See-do models and classical statistics}{39}{subsection.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Repeatable experiments}{40}{section.4}\protected@file@percent }
\citation{greenland_identifiability_1986}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Assumptions of repeatability and their consequences}{42}{subsection.4.1}\protected@file@percent }
\newlabel{def:domodel}{{4.1}{42}{Do model}{theorem.4.1}{}}
\newlabel{def:caus_exch}{{4.2}{42}{Commutativity of exchange}{theorem.4.2}{}}
\newlabel{def:caus_cont}{{4.3}{42}{Causal contractibility}{theorem.4.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Causal Bayesian Networks}{46}{section.5}\protected@file@percent }
\newlabel{sec:CBN}{{5}{46}{Causal Bayesian Networks}{section.5}{}}
\citation{peters_structural_2015}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Probability 2-combs represented by causal Bayesian networks}{47}{subsection.5.1}\protected@file@percent }
\newlabel{def:cbn_o2}{{5.1}{48}{Order 2 model associated with the CBN in question}{theorem.5.1}{}}
\newlabel{eq:cbn_ci1}{{213}{48}{Order 2 model associated with the CBN in question}{equation.5.213}{}}
\newlabel{eq:cbn_ci2}{{214}{48}{Order 2 model associated with the CBN in question}{equation.5.214}{}}
\newlabel{eq:cbn_ci3}{{215}{48}{Order 2 model associated with the CBN in question}{equation.5.215}{}}
\newlabel{eq:identically_distributed}{{217}{48}{Order 2 model associated with the CBN in question}{equation.5.217}{}}
\newlabel{eq:cbn_insert}{{218}{48}{Order 2 model associated with the CBN in question}{equation.5.218}{}}
\newlabel{th:cbn_2comb_exist}{{5.2}{48}{Existence of CBN 2-comb}{theorem.5.2}{}}
\newlabel{eq:obs_cbn_existence}{{219}{48}{Probability 2-combs represented by causal Bayesian networks}{equation.5.219}{}}
\newlabel{eq:int_cbn_existence}{{220}{48}{Probability 2-combs represented by causal Bayesian networks}{equation.5.220}{}}
\newlabel{eq:identical_1}{{224}{49}{Probability 2-combs represented by causal Bayesian networks}{equation.5.224}{}}
\newlabel{eq:identical_2}{{225}{49}{Probability 2-combs represented by causal Bayesian networks}{equation.5.225}{}}
\newlabel{eq:identical_3}{{226}{49}{CBN observations are identically distributed}{equation.5.226}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}See-do models corresponding to causal Bayesian networks}{49}{subsection.5.2}\protected@file@percent }
\newlabel{eq:consistent}{{230}{50}{See-do models corresponding to causal Bayesian networks}{equation.5.230}{}}
\newlabel{th:seedo_rep}{{5.4}{50}{}{theorem.5.4}{}}
\citation{heckerman_decision-theoretic_1995}
\newlabel{eq:not_indep}{{246}{52}{See-do models corresponding to causal Bayesian networks}{equation.5.246}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Proxy control}{52}{subsection.5.3}\protected@file@percent }
\citation{pearl_does_2018}
\@writefile{toc}{\contentsline {section}{\numberline {6}Potential outcomes}{53}{section.6}\protected@file@percent }
\newlabel{sec:potential_outcomes}{{6}{53}{Potential outcomes}{section.6}{}}
\newlabel{def:potential_outcomes}{{6.2}{54}{Potential outcomes: formal requirement}{theorem.6.2}{}}
\newlabel{lem:po_triviality}{{6.3}{54}{Trivial formal potential outcomes}{theorem.6.3}{}}
\newlabel{def:po_whatmodel}{{6.4}{54}{What potential outcomes model: counterfactual extension}{theorem.6.4}{}}
\newlabel{eq:po_probmodel}{{260}{55}{Potential outcomes}{equation.6.260}{}}
\newlabel{lem:selector}{{6.5}{55}{Selector kernel}{theorem.6.5}{}}
\newlabel{eq:multiplex2}{{261}{55}{Selector kernel}{equation.6.261}{}}
\newlabel{eq:multiplex1}{{263}{55}{Selector kernel}{equation.6.263}{}}
\citation{rubin_causal_2005}
\citation{hernan_does_2008}
\newlabel{def:po_dte}{{6.6}{56}{}{theorem.6.6}{}}
\newlabel{eq:different_ys}{{264}{56}{}{equation.6.264}{}}
\newlabel{eq:po_exist_con1}{{267}{56}{}{equation.6.267}{}}
\newlabel{eq:po_exist_con2}{{271}{57}{}{equation.6.271}{}}
\@writefile{tdo}{\contentsline {todo}{I think I asked the wrong question here -- should've asked when I can extend a see-do model with additonal pre-choice variables. I think it's possible to always choose some deterministic potential outcomes.}{57}{section*.6}\protected@file@percent }
\pgfsyspdfmark {pgfid99}{20088093}{28242219}
\newlabel{eq:po_proxycontrol}{{272}{57}{}{equation.6.272}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Appendix:see-do model representation}{58}{section.7}\protected@file@percent }
\newlabel{sec:see-do-rep}{{7}{58}{Appendix:see-do model representation}{section.7}{}}
\@writefile{tdo}{\contentsline {todo}{Update notation}{58}{section*.7}\protected@file@percent }
\pgfsyspdfmark {pgfid100}{20088093}{41804522}
\newlabel{th:see_do_rep}{{7.1}{58}{See-do model representation}{theorem.7.1}{}}
\newlabel{eq:disint}{{273}{58}{Appendix:see-do model representation}{equation.7.273}{}}
\newlabel{eq:comb_disint}{{274}{58}{Appendix:see-do model representation}{equation.7.274}{}}
\newlabel{eq:t_is_comb_disint_start}{{279}{59}{Appendix:see-do model representation}{equation.7.279}{}}
\newlabel{eq:t_is_comb_disint_end}{{284}{59}{Appendix:see-do model representation}{equation.7.284}{}}
\newlabel{eq:comb_disint_nonuniq}{{287}{59}{Appendix:see-do model representation}{equation.7.287}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Appendix: Counterfactual representation}{59}{section.8}\protected@file@percent }
\newlabel{sec:pot_rep}{{8}{59}{Appendix: Counterfactual representation}{section.8}{}}
\newlabel{def:pa_pot_outcomes}{{8.1}{59}{Parallel potential outcomes}{theorem.8.1}{}}
\@writefile{tdo}{\contentsline {todo}{How this will change: a parallel potential outcomes model is a comb $\ensuremath  {\mathbb  {K}}[\ensuremath  {\mathsf  {Y}}(W)|\ensuremath  {\mathsf  {H}}]\rightrightarrows \ensuremath  {\mathbb  {K}}[\ensuremath  {\mathsf  {Y}}_i|\ensuremath  {\mathsf  {W}}_i\ensuremath  {\mathsf  {Y}}(W)]$.}{60}{section*.8}\protected@file@percent }
\pgfsyspdfmark {pgfid101}{20088093}{42946477}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Parallel potential outcomes representation theorem}{60}{subsection.8.1}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{An interesting question is whether there is a similar representation theorem for potential outcomes without the assumption of deterministic reproducibility. I'm reasonably confident that this is a straightforward corollary of the representation theorem proved in my thesis. However, this requires maths not introduced in this draft of the paper.}{61}{section*.9}\protected@file@percent }
\pgfsyspdfmark {pgfid102}{20088093}{37790980}
\newlabel{def:exchangeable}{{8.2}{61}{Exchangeability}{theorem.8.2}{}}
\@writefile{tdo}{\contentsline {todo}{I think this is a very standard thing to do -- propose some $\ensuremath  {\mathsf  {X}}$ and $\ensuremath  {\mathbb  {P}}(\ensuremath  {\mathsf  {X}})$ then introduce some random variable $\ensuremath  {\mathsf  {Y}}$ and $\ensuremath  {\mathbb  {P}}(\ensuremath  {\mathsf  {X}}\ensuremath  {\mathsf  {Y}})$ as if the sample space contained both $\ensuremath  {\mathsf  {X}}$ and $\ensuremath  {\mathsf  {Y}}$ all along.}{61}{section*.10}\protected@file@percent }
\pgfsyspdfmark {pgfid105}{20088093}{18472437}
\newlabel{def:ext_exchangeable}{{8.4}{61}{Extendably exchangeable}{theorem.8.4}{}}
\newlabel{th:cfac_rep}{{8.6}{62}{Potential outcomes representation}{theorem.8.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9}Appendix: Connection is associative}{63}{section.9}\protected@file@percent }
\newlabel{sec:connect_associative}{{9}{63}{Appendix: Connection is associative}{section.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10}Appendix: String Diagram Examples}{64}{section.10}\protected@file@percent }
\citation{fritz_synthetic_2020}
\newlabel{eq:extn_definition1}{{316}{65}{Connection}{equation.10.316}{}}
\newlabel{eq:extn_definition2}{{318}{65}{Connection}{equation.10.318}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11}Markov variable maps and variables form a Markov category}{65}{section.11}\protected@file@percent }
\newlabel{sec:app_mcat}{{11}{65}{Markov variable maps and variables form a Markov category}{section.11}{}}
\newlabel{eq:ccom_1}{{323}{66}{}{equation.11.323}{}}
\newlabel{eq:nat}{{328}{66}{}{equation.11.328}{}}
\citation{fong_causal_2013,cho_disintegration_2019,fritz_synthetic_2020}
\bibstyle{plainnat}
\bibdata{references}
\bibcite{bolker_functions_1966}{{1}{1966}{{Bolker}}{{}}}
\@writefile{tdo}{\contentsline {todo}{I'm not sure how to formally argue that it is monoidal and symmetric as the relevant texts I've checked all gloss over the functors with respect to which the relevant isomorphisms should be natural, but labels with products were intentionally made to act just like sets with cartesian products which are symmetric monoidal}{67}{section*.11}\protected@file@percent }
\pgfsyspdfmark {pgfid154}{20088093}{13881244}
\bibcite{chiribella_quantum_2008}{{2}{2008}{{Chiribella et~al.}}{{Chiribella, D'Ariano, and Perinotti}}}
\bibcite{cho_disintegration_2019}{{3}{2019}{{Cho and Jacobs}}{{}}}
\bibcite{constantinou_extended_2017}{{4}{2017}{{Constantinou and Dawid}}{{}}}
\bibcite{dawid_decision-theoretic_2020}{{5}{2020}{{Dawid}}{{}}}
\bibcite{ershov_extension_1975}{{6}{1975}{{Ershov}}{{}}}
\bibcite{feynman_feynman_1979}{{7}{1979}{{Feynman}}{{}}}
\bibcite{fong_causal_2013}{{8}{2013}{{Fong}}{{}}}
\bibcite{fritz_synthetic_2020}{{9}{2020}{{Fritz}}{{}}}
\bibcite{greenland_identifiability_1986}{{10}{1986}{{GREENLAND and ROBINS}}{{}}}
\bibcite{heckerman_decision-theoretic_1995}{{11}{1995}{{Heckerman and Shachter}}{{}}}
\bibcite{hernan_does_2008}{{12}{2008}{{Hernán and Taubman}}{{}}}
\bibcite{hajek_what_2003}{{13}{2003}{{Hájek}}{{}}}
\bibcite{jacobs_causal_2019}{{14}{2019}{{Jacobs et~al.}}{{Jacobs, Kissinger, and Zanasi}}}
\bibcite{jeffrey_logic_1990}{{15}{1965}{{Jeffrey}}{{}}}
\bibcite{joyce_foundations_1999}{{16}{1999}{{Joyce}}{{}}}
\bibcite{korzybski_science_1933}{{17}{1933}{{Korzybski}}{{}}}
\bibcite{lattimore_causal_2019}{{18}{2019{a}}{{Lattimore and Rohde}}{{}}}
\bibcite{lattimore_replacing_2019}{{19}{2019{b}}{{Lattimore and Rohde}}{{}}}
\bibcite{lewis_causation_1986}{{20}{1986}{{Lewis}}{{}}}
\bibcite{menger_random_2003}{{21}{2003}{{Menger}}{{}}}
\bibcite{nozick_newcombs_1969}{{22}{1969}{{Nozick}}{{}}}
\bibcite{pearl_causality:_2009}{{23}{2009}{{Pearl}}{{}}}
\bibcite{pearl_does_2018}{{24}{2018}{{Pearl}}{{}}}
\bibcite{peters_structural_2015}{{25}{2015}{{Peters and Bühlmann}}{{}}}
\bibcite{ramsey_truth_2016}{{26}{2016}{{Ramsey}}{{}}}
\bibcite{rubin_causal_2005}{{27}{2005}{{Rubin}}{{}}}
\bibcite{savage_foundations_1954}{{28}{1954}{{Savage}}{{}}}
\bibcite{selinger_survey_2010}{{29}{2010}{{Selinger}}{{}}}
\bibcite{shahar_association_2009}{{30}{2009}{{Shahar}}{{}}}
\bibcite{tian2002general}{{31}{2002}{{Tian and Pearl}}{{}}}
\bibcite{von_neumann_theory_1944}{{32}{1944}{{Von~Neumann and Morgenstern}}{{}}}
\bibcite{wald_statistical_1950}{{33}{1950}{{Wald}}{{}}}
\bibcite{weirich_causal_2016}{{34}{2016}{{Weirich}}{{}}}
