\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\citation{pearl_causality:_2009}
\citation{rubin_causal_2005}
\citation{korzybski_science_1933}
\citation{hernan_does_2008}
\citation{pearl_does_2018}
\citation{shahar_association_2009}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Variables and Probability Models}{3}{section.2}\protected@file@percent }
\newlabel{sec:vague_variables}{{2}{3}{Variables and Probability Models}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Section outline}{3}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Brief outline of probability gap models}{4}{subsubsection.2.1.1}\protected@file@percent }
\citation{feynman_feynman_1979}
\citation{menger_random_2003}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Semantics of observed and unobserved variables}{5}{subsection.2.2}\protected@file@percent }
\newlabel{sec:variables}{{2.2}{5}{Semantics of observed and unobserved variables}{subsection.2.2}{}}
\citation{pearl_causality:_2009}
\newlabel{def:observable}{{2.4}{7}{Consistency with observation}{theorem.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Events}{8}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Standard probability theory}{8}{subsection.2.4}\protected@file@percent }
\newlabel{def:pushforward}{{2.10}{9}{Marginal distribution with respect to a probability space}{theorem.2.10}{}}
\newlabel{eq:disint_def}{{5}{9}{Disintegration}{equation.2.5}{}}
\newlabel{def:disint}{{2.12}{9}{Conditional probability with respect to a probability space}{theorem.2.12}{}}
\citation{cho_disintegration_2019}
\citation{hajek_what_2003}
\newlabel{lem:disint_exist}{{2.14}{10}{Disintegration existence in standard measurable Markov kernels}{theorem.2.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Probabilistic models for causal inference}{10}{subsection.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Probability sets}{11}{subsection.2.6}\protected@file@percent }
\newlabel{th:recurs_pushf}{{2.18}{12}{Recursive pushforward}{theorem.2.18}{}}
\newlabel{def:copyproduct}{{2.19}{12}{Copy product}{theorem.2.19}{}}
\newlabel{def:asequal}{{2.21}{13}{Almost sure equality}{theorem.2.21}{}}
\citation{richardson2013single,pearl_causality:_2009}
\newlabel{lem:joint_conditional}{{2.24}{14}{Copy product of conditionals is a joint conditional}{theorem.2.24}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Probability sets defined by marginal and conditional probabilities}{14}{subsection.2.7}\protected@file@percent }
\newlabel{def:valid_dist}{{2.25}{14}{Valid distribution}{theorem.2.25}{}}
\newlabel{def:valid_conditional_prob}{{2.26}{14}{Valid conditional}{theorem.2.26}{}}
\@writefile{tdo}{\contentsline {todo}{We're making complicated models where we can choose many different combinations of conditional probabilities, validity is useful because we can check just the individual conditionals, don't need to check all the combinations. Also, there are examples in the wild of invalid collections -- see BMI example}{15}{section*.2}\protected@file@percent }
\pgfsyspdfmark {pgfid13}{20088093}{29964809}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}Probability combs}{15}{subsection.2.8}\protected@file@percent }
\newlabel{def:assmbl_pcomb}{{2.31}{16}{Assembled probability comb}{theorem.2.31}{}}
\newlabel{th:comb_equiv}{{2.32}{17}{Equivalence of comb representations}{theorem.2.32}{}}
\citation{hutter_universal_2004}
\citation{chiribella_quantum_2008,jacobs_causal_2019}
\citation{constantinou_extended_2017}
\newlabel{th:comb_conditional_correspondence}{{2.36}{18}{Comb-conditional correspondence}{theorem.2.36}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.1}Examples of probability combs}{18}{subsubsection.2.8.1}\protected@file@percent }
\newlabel{eq:insert_op}{{53}{18}{Examples of probability combs}{equation.2.53}{}}
\citation{cho_disintegration_2019}
\citation{cho_disintegration_2019}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.2}Conditional independence}{19}{subsubsection.2.8.2}\protected@file@percent }
\newlabel{ssec:cond_indep}{{2.8.2}{19}{Conditional independence}{subsubsection.2.8.2}{}}
\newlabel{th:cho_ci_equiv}{{2.38}{19}{}{theorem.2.38}{}}
\citation{richardson2013single,dawid_causal_2000}
\citation{ramsey_truth_2016}
\citation{savage_foundations_1954}
\citation{bolker_functions_1966,jeffrey_logic_1990}
\citation{joyce_foundations_1999}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9}Curried Markov kernels}{20}{subsection.2.9}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{start again here}{20}{section*.3}\protected@file@percent }
\pgfsyspdfmark {pgfid26}{20088093}{16689120}
\@writefile{toc}{\contentsline {section}{\numberline {3}Decision theoretic causal inference}{20}{section.3}\protected@file@percent }
\newlabel{sec:seedo_models}{{3}{20}{Decision theoretic causal inference}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Decision problems}{21}{subsection.3.1}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{I think adding hypotheses at this point might make things unnecessarily confusing; on the other hand, they are useful for the connection to classical statistical decision theory. The "repeatable experiments" section shows how see-do models with certain assumptions induce an easier to understand class of hypotheses, and I could just save the idea of a hypothesis until I get there}{21}{section*.4}\protected@file@percent }
\pgfsyspdfmark {pgfid27}{20088093}{41455533}
\@writefile{tdo}{\contentsline {todo}{I need to update the proof for this claim}{22}{section*.5}\protected@file@percent }
\pgfsyspdfmark {pgfid28}{13754458}{11864571}
\pgfsyspdfmark {pgfid31}{34243869}{11878678}
\pgfsyspdfmark {pgfid32}{36357404}{11652948}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Decisions as measurement procedures}{22}{subsection.3.2}\protected@file@percent }
\citation{lattimore_causal_2019}
\citation{lattimore_replacing_2019}
\citation{dawid_decision-theoretic_2020}
\@writefile{tdo}{\contentsline {todo}{I don't know how important this observation is, but the fact that $\ensuremath  {\EuScript  {D}}$ is an output of a formal decision making system makes it different from other things we might call decisions, and I wonder if I should call it something else in order to avoid ambiguity. The vague reason I think this matters is: whatever you might want to measure, you won't learn more about $\ensuremath  {\EuScript  {D}}$ from it than you already know once you have the model, the utility and the decision rule, this is not a property that other things we call ``decisons'' share and this distinction might be important regarding judgements of causal contractibilty.}{23}{section*.6}\protected@file@percent }
\pgfsyspdfmark {pgfid33}{20088093}{26776562}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Causal models similar to see-do models}{23}{subsection.3.3}\protected@file@percent }
\citation{heckerman_decision-theoretic_1995}
\citation{jacobs_causal_2019}
\citation{tian2002general}
\citation{von_neumann_theory_1944}
\citation{wald_statistical_1950}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}See-do models and classical statistics}{24}{subsection.3.4}\protected@file@percent }
\citation{dawid_decision-theoretic_2020}
\citation{greenland_identifiability_1986}
\@writefile{toc}{\contentsline {section}{\numberline {4}Repeatable experiments}{25}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Assumptions of repeatability applicable to models of decisions and consequences}{27}{subsection.4.1}\protected@file@percent }
\newlabel{def:caus_exch}{{4.1}{27}{Commutativity of exchange}{theorem.4.1}{}}
\newlabel{def:caus_cont}{{4.2}{28}{Causal contractibility}{theorem.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Representations of contractible probability models}{28}{subsection.4.2}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{matrix of variables?}{28}{section*.7}\protected@file@percent }
\pgfsyspdfmark {pgfid34}{31409438}{8056282}
\pgfsyspdfmark {pgfid37}{34243869}{8070389}
\pgfsyspdfmark {pgfid38}{36357404}{7844659}
\@writefile{tdo}{\contentsline {todo}{The following can be deduced from the theorems after it, but I thought it might be helpful to have the explanation.}{29}{section*.8}\protected@file@percent }
\pgfsyspdfmark {pgfid39}{20088093}{27613563}
\newlabel{eq:table_lookup_example}{{73}{29}{Representations of contractible probability models}{equation.4.73}{}}
\newlabel{eq:table_lookup_cons}{{74}{29}{Representations of contractible probability models}{equation.4.74}{}}
\newlabel{th:table_rep}{{4.4}{30}{Table representation of causally contractible do models}{theorem.4.4}{}}
\citation{rubin_causal_2005}
\newlabel{th:contractibility_commutativity}{{4.5}{32}{}{theorem.4.5}{}}
\citation{kallenberg_basic_2005}
\newlabel{th:iid_rep}{{4.6}{33}{}{theorem.4.6}{}}
\newlabel{eq:pci_1}{{114}{34}{Representations of contractible probability models}{equation.4.114}{}}
\newlabel{eq:pci_2}{{115}{34}{Representations of contractible probability models}{equation.4.115}{}}
\newlabel{eq:pci_4}{{117}{34}{Representations of contractible probability models}{equation.4.117}{}}
\newlabel{eq:pci_5}{{118}{34}{Representations of contractible probability models}{equation.4.118}{}}
\newlabel{eq:pci_6}{{119}{34}{Representations of contractible probability models}{equation.4.119}{}}
\newlabel{eq:pci_7}{{120}{34}{Representations of contractible probability models}{equation.4.120}{}}
\citation{constantinou_extended_2017}
\citation{constantinou_extended_2017}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Potential outcomes}{35}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Extended conditional independence}{35}{subsubsection.4.3.1}\protected@file@percent }
\newlabel{ap:eci}{{4.3.1}{35}{Extended conditional independence}{subsubsection.4.3.1}{}}
\@writefile{tdo}{\contentsline {todo}{Needs a support condition}{35}{section*.9}\protected@file@percent }
\pgfsyspdfmark {pgfid58}{20088093}{40876646}
\newlabel{th:dawid_constantionou}{{4.7}{35}{}{theorem.4.7}{}}
\citation{fong_causal_2013}
\newlabel{eq:higherorder_ci_erase}{{136}{37}{Unresponsiveness}{equation.4.136}{}}
\newlabel{th:cons_ci}{{4.11}{37}{Conditional independence from kernel unresponsiveness}{theorem.4.11}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Graphical properties of conditional independence}{37}{subsubsection.4.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Results I use that don't really fit into the flow of the text}{38}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}Repeated variables}{38}{subsubsection.4.4.1}\protected@file@percent }
\newlabel{lem:nocopy1}{{4.12}{38}{Output copies of the same variable are identical}{theorem.4.12}{}}
\newlabel{lem:nocopy2}{{4.13}{39}{Copies shared between input and output are identical}{theorem.4.13}{}}
\@writefile{tdo}{\contentsline {todo}{This got mixed up at some point and needs ot be unmixed-up}{39}{section*.10}\protected@file@percent }
\pgfsyspdfmark {pgfid75}{20088093}{42473162}
\newlabel{th:valid_disint}{{4.14}{40}{Existence of valid conditional probabilities}{theorem.4.14}{}}
\newlabel{eq:k_disint}{{161}{40}{Repeated variables}{equation.4.161}{}}
\citation{ershov_extension_1975}
\citation{ershov_extension_1975}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Validity}{41}{subsection.4.5}\protected@file@percent }
\newlabel{th:completion}{{4.15}{41}{Validity}{theorem.4.15}{}}
\newlabel{th:intersection}{{4.16}{41}{Copy-product is an intersection of probability sets}{theorem.4.16}{}}
\newlabel{th:valid_agree}{{4.17}{42}{Equivalence of validity definitions}{theorem.4.17}{}}
\newlabel{lem:valid_extendability}{{4.18}{42}{Copy-product of valid candidate conditionals is valid}{theorem.4.18}{}}
\newlabel{corr:valid_extend_order1}{{4.19}{42}{Valid conditionals are validly extendable to valid distributions}{theorem.4.19}{}}
\newlabel{th:valid_conditional_probability}{{4.20}{43}{Validity of conditional probabilities}{theorem.4.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Combs}{43}{subsection.4.6}\protected@file@percent }
\newlabel{ap:combs}{{4.6}{43}{Combs}{subsection.4.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}Comb conditional correspondence}{44}{subsection.4.7}\protected@file@percent }
\newlabel{ap:ccc}{{4.7}{44}{Comb conditional correspondence}{subsection.4.7}{}}
\bibstyle{plainnat}
\bibdata{references}
\bibcite{kallenberg_basic_2005}{{1}{2005}{{kal}}{{}}}
\bibcite{bolker_functions_1966}{{2}{1966}{{Bolker}}{{}}}
\bibcite{chiribella_quantum_2008}{{3}{2008}{{Chiribella et~al.}}{{Chiribella, D'Ariano, and Perinotti}}}
\bibcite{cho_disintegration_2019}{{4}{2019}{{Cho and Jacobs}}{{}}}
\bibcite{constantinou_extended_2017}{{5}{2017}{{Constantinou and Dawid}}{{}}}
\bibcite{dawid_causal_2000}{{6}{2000}{{Dawid}}{{}}}
\bibcite{dawid_decision-theoretic_2020}{{7}{2020}{{Dawid}}{{}}}
\bibcite{ershov_extension_1975}{{8}{1975}{{Ershov}}{{}}}
\bibcite{feynman_feynman_1979}{{9}{1979}{{Feynman}}{{}}}
\bibcite{fong_causal_2013}{{10}{2013}{{Fong}}{{}}}
\bibcite{greenland_identifiability_1986}{{11}{1986}{{GREENLAND and ROBINS}}{{}}}
\bibcite{heckerman_decision-theoretic_1995}{{12}{1995}{{Heckerman and Shachter}}{{}}}
\bibcite{hernan_does_2008}{{13}{2008}{{Hernán and Taubman}}{{}}}
\bibcite{hutter_universal_2004}{{14}{2004}{{Hutter}}{{}}}
\bibcite{hajek_what_2003}{{15}{2003}{{Hájek}}{{}}}
\bibcite{jacobs_causal_2019}{{16}{2019}{{Jacobs et~al.}}{{Jacobs, Kissinger, and Zanasi}}}
\bibcite{jeffrey_logic_1990}{{17}{1965}{{Jeffrey}}{{}}}
\bibcite{joyce_foundations_1999}{{18}{1999}{{Joyce}}{{}}}
\bibcite{korzybski_science_1933}{{19}{1933}{{Korzybski}}{{}}}
\bibcite{lattimore_causal_2019}{{20}{2019{a}}{{Lattimore and Rohde}}{{}}}
\bibcite{lattimore_replacing_2019}{{21}{2019{b}}{{Lattimore and Rohde}}{{}}}
\bibcite{menger_random_2003}{{22}{2003}{{Menger}}{{}}}
\bibcite{pearl_causality:_2009}{{23}{2009}{{Pearl}}{{}}}
\bibcite{pearl_does_2018}{{24}{2018}{{Pearl}}{{}}}
\bibcite{ramsey_truth_2016}{{25}{2016}{{Ramsey}}{{}}}
\bibcite{richardson2013single}{{26}{2013}{{Richardson and Robins}}{{}}}
\bibcite{rubin_causal_2005}{{27}{2005}{{Rubin}}{{}}}
\bibcite{savage_foundations_1954}{{28}{1954}{{Savage}}{{}}}
\bibcite{shahar_association_2009}{{29}{2009}{{Shahar}}{{}}}
\bibcite{tian2002general}{{30}{2002}{{Tian and Pearl}}{{}}}
\bibcite{von_neumann_theory_1944}{{31}{1944}{{Von~Neumann and Morgenstern}}{{}}}
\bibcite{wald_statistical_1950}{{32}{1950}{{Wald}}{{}}}
