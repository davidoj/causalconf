%!TEX root = main.tex


\section{Decision problems}\label{sec:dec_probs}

We want to construct models to help make decisions. For our purposes, ``making a decision'' means choosing some element of a mathematically well-defined set $\alpha\in C$, and following a measurement procedure $\proc{S}_\alpha$ associated with the choice $\alpha\in C$ (see Section \ref{sec:actions}). We suppose that each $\proc{S}_\alpha$ is modeled by a probability model $\prob{P}_\alpha$ on a shared sample space $(\Omega,\sigalg{F})$. Decision making also involves comparing the outcomes of different choices (that is, comparing the probability models $\prob{P}_\alpha$ associated with each choice) and selecting one of the ``best'' decisions, but we leave questions of comparison in the background.

The way we treat consequences of decisions is, in a sense, the opposite of the way we treat conducting measurements. A measurement involves some unclear measurement procedure that interacts with the world and leaves us with a collection of well-defined mathematical objects. Our view of the consequences of making a decision, in contrast, is that we assume that we start with some element of a well-defined set $C$ which is then mapped to some unclear measurement procedure. If a measurement is a ``function'' whose domain is actions in the world, the consequences of a decision is a ``function'' whose codomain is actions in the world.

We make the assumption that each choice is associated with a measurement procedure $\proc{S}_\alpha$ modeled by probability distribution $\prob{P}_\alpha$. This is a Bayesian approach -- uncertainty over the outcomes of a measurement procedure is represented with a single probability measure. It is not our intention to suggest that this is the only way of representing uncertain knowledge, and it may be interesting to extend our theory to other methods for representing uncertain outcomes of a measurement procedure. A particularly simple extension would be to model each $\proc{S}_\alpha$ with a probability set rather than a single probability distribution. 

The model of a decision problem of this form is naturally captured by a probability set $\prob{P}_{C}:=\{\prob{P}_\alpha|\alpha\in C\}$. 

\subsection{Other decision theoretic causal models}

There have been a number of formalisations of decision theoretic foundations of causal inference. All share the feature that there is a basic set of choices/interventions/regimes that may be chosen from, and a probability distribution is associated with each element of this set, so they all induce probability sets. 

\citet{lattimore_causal_2019} and \citet{lattimore_replacing_2019} describe a method for reformulating causal Bayesian networks as a set of probability distributions indexed by an intervention set $T$. Their algorithm \emph{CausalBayesConstruct} is a method for translating directly from causal Bayesian networks with a specification of interventions to probability sets.

A key feature of the \emph{CausalBayesConstruct} algorithm is that every probability distribution in the set can be represented as a product of the same set of conditional probabilities - clearly, these must be uniform conditional probabilities. We posit, therefore, that d-separation in probabilistic graphical models corresponds to \emph{extended conditional independence} of the form given in Definition \ref{def:eci}.

An alternative decision theoretic foundation has been developed in \citet{dawid_decision-theoretic_2020,dawid_beware_2010,dawid_causal_2000}. A key contribution of this literature is the notion of extended conditional independence (formally described in \citet{constantinou_extended_2017}, see Section \ref{sec:eci}), and its application to probability sets. Many common causal models have been described as probability sets in which certain extended conditional independence statements hold. A second contribution of \citet{dawid_decision-theoretic_2020} is to develop a lower level justification for the use of probability sets modelling ``generic variables'' that appears in earlier work. Our work is an extension of this latter investigation.

\citet{heckerman_decision-theoretic_1995} also explore a decision theoretic approach to causal inference. Their approach differs from the previous two in two ways: first, they posit a set of choices and a set of unobserved states, and consider models that map $\mathrm{States}\times\mathrm{Choices}\to \mathrm{Outcomes}$, instead of mapping choices only to outcomes. Secondly, they consider only deterministic maps rather than general probability distribution valued maps. This approach is based on the decision theory of \citet{savage_foundations_1954}. They consider an alternative ``conditional independence-like'' property of these models that they call \emph{limited unresponsiveness}.