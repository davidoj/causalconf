%!TEX root = main.tex

\section{Decision theoretic causal inference}\label{sec:seedo_models}

\citet{lattimore_causal_2019} and \citet{lattimore_replacing_2019} describe a novel approach to causal inference: rather than consider ``one'' causal model, they consider a pair of models; an observational and interventional model that share parameters.

We will use the theory of probability set out previously to see how such a model can arise if we are given a decision problem with some data. Our aim is ultimately to represent ``causal effects'' and ``the consequences of my actions'' in the same model, so that we can discuss issues like possible non-correspondence between causal effects and consequences in formal mathematical language rather than in English. Understanding how we can model decision problems is a first step, because while decision models don't feature any notion of ``causal effect'', consequences of actions are primitives. We will go on to consider how to combine decision models with models that define causal effects.

We suppose we have a decision problem of the following type: we will be given an observation that takes values in $X$ and in response to this we can select any decision or stochastic mixture of decisions from $D$. $\RV{X}$ is the variable representing the quesion ``what will we observe?'' and $\RV{D}$ the question ``what decision will we choose?''. We can consider a number of different strategies for selecting a decision, each of which corresponds to a Markov variable map $\kernel{S}_\alpha:\RV{X}\to \Delta(\RV{D})$.  The variable $\RV{Y}$ represents ``what will we see when all is said and done?'', and it takes values in $Y$. After considering the available strategies, we want to select the strategy for which we expect to see the best ultimate outcome.

We will represent our uncertain answers to the questions $\RV{X}$, $\RV{D}$ and $\RV{Y}$ with probability distributions. We will allow for multiple probability distributions to be entertained as an answer; let hypotheses $\RV{H}$ represent the question ``which model best captures this problem?'', taking values in $H$. Then for each strategy $\kernel{S}_\alpha$, our forecast will be represented by a joint probability $\kernel{P}_{\alpha}\equiv\model{P}_\alpha^{\RV{XDY}|\RV{H};\kernel{P}_\alpha}:\RV{H}\to\Delta(\RV{X},\RV{D},\RV{Y})$. Because observations come before we execute our strategy, we might assume that they will be unchanged by any choice of strategy: $\model{P}_{\alpha}^{\RV{X}|\RV{H}}=P_{\beta}^{\RV{X}|\RV{H}}$ for all $\alpha,\beta$. We expect to choose a decision precisely in line with the strategy under consideration: $\model{P}_{\alpha}^{\RV{D}|\RV{X}}=\kernel{S}_\alpha$. Finally, our answer to $\RV{Y}$ will be the same under any strategy supposing we have the same observation, decision and hypothesis: $\model{P}_{\alpha}^{\RV{Y}|\RV{HD}}=P_{\beta}^{\RV{Y}|\RV{HD}}$ for all $\alpha,\beta$.

Under these assumptions, there exists $\model{T}[\RV{X}\RV{Y}|\RV{HD}]\in \mathscr{M}$ with $\RV{X}\CI_{\model{T}}\RV{D}|\RV{H}$ such that for all $\alpha$, 

\begin{align}
    \model{P}_{\alpha}[\RV{X}\RV{D}\RV{Y}|\RV{H}]\overset{krn}{=}\model{T}[\RV{X}|\RV{H}]\rightrightarrows \model{S}_\alpha [\RV{D}|\RV{X}] \rightrightarrows \model{T}[\RV{Y}|\RV{XHD}] \label{eq:see_do_query}
\end{align}

The proof is given in Appendix \ref{sec:see-do-rep}. Note that $\model{T}[\RV{X}|\RV{H}]$ exists by virtue of the fact $\RV{X}\CI_{\model{T}}\RV{D}|\RV{H}$. While this independence is what enables Equation \ref{eq:see_do_query}, in general $\RV{X}\not\CI_{\model{P}_\alpha} \RV{D}|\RV{H}$, so $\model{T}$ cannot be a disintegration of $\model{P}_\alpha$. Modular probability allows us to specify $\model{T}$, which we call a \emph{see-do model}, as a partial forecast to be completed with a strategy $\model{S}_\alpha$ while also being able to use consistent names for variables that represent the same things (observations, decisions, consequences, hypotheses) whether their distributions are given by $\model{P}_\alpha$, $\model{T}$, which are mutually incompatible conditional probabilities.

\subsection{See-do models and classical statistics}

A \emph{statistical model} (or \emph{statistical experiment}) is a collection of probability distributions indexed by some set $\Theta$. We can observe that $\{\model{T}[\RV{X}|\RV{H}]_h\}_{h\in H}$ is a collection of probability distributions indexed by $H$.

In statistical decision theory, as introduced by \citet{wald_statistical_1950}, we are given a statistical experiment $\{\prob{P}_\theta\in \Delta(X)\}_\Theta$, a decision set $D$ and a loss $l:\Theta\times D\to \mathbb{R}$. A strategy $\model{S}_\alpha:X\to \Delta(D)$ is evaluated according to the risk functional $R(\theta,\model{S}_\alpha)=\sum_{x\in X}\sum_{d\in D} \prob{P}_\theta^x (S_\alpha)_x^d l(h,d)$.

Suppose we have a see-do model $\model{T}[\RV{X}\RV{Y}|\RV{HD}]$ with $\RV{Y}\CI_{\kernel{T}} \RV{X}|\RV{HD}$, and suppose that the random variable $\RV{Y}$ is a ``reverse utility'' function taking values in $\mathbb{R}$ for which low values are considered desirable. Then, defining a loss $l:H\times D\to \mathbb{R}$ by $l(h,d) = \sum_{y\in \mathbb{R}} y\model{T}[\RV{Y}|\RV{H}\RV{D}]_{h,d}^y$, we have 

\begin{align}
    \mathbb{E}_{\model{P}_{\alpha}[\RV{X}\RV{D}\RV{Y}|\RV{H}]}[\RV{Y}] &= \sum_{x\in X} \sum_{d\in D} \sum_{y\in Y} y \left(\model{T}[\RV{X}|\RV{H}]\rightrightarrows \model{S}_\alpha [\RV{D}|\RV{X}] \rightrightarrows \model{T}[\RV{Y}|\RV{XHD}]\right)_h^{xdy}\\
     &= \sum_{x\in X} \sum_{d\in D} \sum_{y\in Y} \model{T}[\RV{X}|\RV{H}]^x_h \model{S}_\alpha [\RV{D}|\RV{X}]_x^d \model{T}[\RV{Y}|\RV{H}\RV{D}]_{h,d}^y\\
    &= \sum_{x\in X}\sum_{d\in D} \model{T}[\RV{X}|\RV{H}]_h^x (S_\alpha)_x^d l(h,d)\\
    &= R(h,\model{S}_\alpha)
\end{align}

That is, if we are given a see-do model where we interpret $\model{T}[\RV{X}|\RV{H}]$ as a statistical experiment and $\RV{Y}$ as a reversed utility, the expectation of the utility under the strategy forecast given in equation \ref{eq:see_do_query} is the risk of that strategy under hypothesis $h$.

\subsection{Combs}

The see-do model $\model{T}[\RV{X}\RV{Y}|\RV{HD}]$ is known as a \emph{comb}. This structure was introduced by \citet{chiribella_quantum_2008} in the context of quantum circuit architecture, and \citet{jacobs_causal_2019} adapted the concept to causal modelling.

A comb is a Markov kernel with a ``hole'' in it. We combine the see-do model with a strategy by putting the strategy ``in the middle'' of the see-do model (Equation \ref{eq:see_do_query}), rather than attaching it to one end. While it is not a well-formed diagram in the language described in this paper, we can visualise combs as Markov kernels with holes:

\begin{align}
\model{T}[\RV{XY}|\RV{HD}] &= \begin{tikzpicture}
    \path (0,0) node (H) {$\RV{H}$}
     ++ (0.5,0) node[copymap] (copy0) {}
     ++ (0.5,0) node[kernel] (XH) {$\model{T}$}
     ++ (0.5,0) node[copymap] (copy1) {}
     ++ (0.5,0) node (X) {$\RV{X}$}
     ++ (0.5,0.) node (D) {$\RV{D}$}
     ++ (0.7,-0.15) node[kernel,inner sep=5pt] (YDXH) {$\model{T}$}
     ++ (0.7,0.15) node (Y) {$\RV{Y}$};
     \draw (H) -- (XH) -- (X) (D) to [out=0,in=180] ($(YDXH.west) + (0,0.15)$) ($(YDXH.east) + (0,0.15)$) -- (Y);
     \draw (copy0) to [out=-90,in=180] ($(copy0.east) + (0.8,-0.5)$) to [out=0,in=180] ($(YDXH.west) + (0,-0.2)$) (copy1) to [out=-90,in=180] ($(YDXH.west) + (0,-0.05)$);
\end{tikzpicture}\\
&= \begin{tikzpicture}
    \path (0,0) node (H) {$\RV{H}$}
     ++ (0.7,0) node (XH) {$\model{T}$}
     ++ (0.7,0) node (X) {$\RV{X}$}
     ++ (0.5,0) node (D) {$\RV{D}$}
     ++ (0.5,0) node[inner sep=4pt] (YDXH) {}
     ++ (0.5,0) node (Y) {$\RV{Y}$};
     \draw (H) -- (XH) -- (X) (D) -- (YDXH) -- (Y);
     \draw ($(XH.west) + (0,0.2)$) -- ($(XH.west) + (0,-0.6)$) -- ($(YDXH.east) + (0,-0.6)$)
     -- ($(YDXH.east) + (0,0.2)$) -- ($(YDXH.west) + (0,0.2)$) -- ($(YDXH.west) + (0,-0.4)$)
     -- ($(XH.east) + (0,-0.4)$) -- ($(XH.east) + (0,0.2)$) -- ($(XH.west) + (0,0.2)$);
\end{tikzpicture}\label{eq:kernel_with_hole}
\end{align}

We can take any strategy $\model{S}_\alpha[\RV{D}|\RV{X}]$ and drop it into the ``hole'' in \ref{eq:kernel_with_hole} (as described in Equation \ref{eq:see_do_query}) to get a forecast of the outcome of that strategy. 

\citet{dawid_decision-theoretic_2020} has described his decision theoretic approach to causal inference:

\begin{quote}
A fundamental feature of the DT approach is its consideration of the relationships between the various probability distributions that govern different regimes of interest. As a very simple example, suppose that we have a binary treatment variable T, and a response variable Y. We consider three different regimes [...] the first two regimes may be described as interventional, and the last as observational.
\end{quote}
