%!TEX root = main.tex

\section{Decision problems}

We want to construct models to help make decisions. For our purposes, ``making a decision'' means we have some mathematically well-defined set $A$ of choices under consideration, and some means of comparing one choice to another that induces a partial order on choices. If we are trying to be precise with language, we might call this \emph{formal} decision making; people may often make decisions where it is difficult to identify a set $A$ of choices under consideration or a rule for inducing a partial order on it.

Formal decision making can be considered as a rough opposite of measurment. With measurement, we have some unclear process that interacts with the world and leaves us with a collection of mathematical objects. Formal decision making starts with a collection of mathematical objects -- a set of choices, a partial order and a tie-breaking rule which together imply a \emph{choice}, and then on the basis of this choice some unclear procedure takes place that has consequences in the world. If a measurement is a ``function'' whose domain is the world, a choice can be thought of as a ``function'' whose codomain is the world.

We make the following assumptions about how choices are compared:
\begin{itemize}
    \item Each choice is associated with a probability set over some sample space $(\Omega,\sigalg{F})$; that is, we have which induces a function $C:A\to \mathscr{P}(\Delta(\Omega))$
    \item There is a utility function $u:\Omega\to \mathbb{R}$
    \item A choice $a_1$ is preferred to $a_2$ if $\mathbb{E}_{f}[u]\geq \mathbb{E}_{g}[u]$ for all $f\in C(a_1)$ and all $g\in C(a_2)$
\end{itemize}

This setup induces a probability gap model in the following way:

\begin{itemize}
    \item Define $\prob{P}_{\{\}}:=\cup_{a\in A} C(a)$
    \item For each $a\in A$, define $\prob{P}_a$ such that $\prob{P}_a\cap \prob{P}_{\{\}}= C(a)$
\end{itemize}

$\prob{P}_{\{\}}$ is a probability set representing everything that is common to all possible choices, while for each $a$ there is a $\prob{P}_a$ such that $\prob{P}_{\{\}} \cap \prob{P}_a=C(a)$. Note that $\prob{P}_a$ must be a subset of $C(a)\cup \prob{P}_{\{\}}^C$ containing $C(a)$.

A particularly simple model of this variety is a \emph{conditional probability model}. Recalling Definition \ref{def:cprob_model}, this is a model where $\prob{P}_{\{\}}$ is defined by $\prob{P}_{\{\}}^{\RV{Y}|\RV{X}}$ for some $\RV{X}:\Omega\to X$ and $\RV{Y}:\Omega\to Y$ and each $\alpha$ is defined by $\prob{P}_\alpha^{\RV{X}}$. We could further consider $\RV{X}$ to be associated with a measurement procedure $\proc{A}$ that reports the choice we end up making, and $\RV{Y}$ to be the identity function on $\Omega$. Then we have a conditional probability model where $\prob{P}_{\{\}}^{\RV{Y}|\RV{X}}=C$.

In conditional models, we can think of the choice $\alpha$ sets the distribution of $\RV{X}$ in a known way, and expectations of $\RV{Y}$ are set in response to this according to $\prob{P}_{\{\}}^{\RV{Y}|\RV{X}}$.

\subsection{Is this the right way to represent decision problems?}

Probabilistic models combined with the principle of expected utility have a long history of being used to represent and reason about decision problems. We might ask: while this choice is conventional, how confident are we that it is the right choice for any given problem? One difficulty with the formalism above is that many practical causal investigations seem to involve decision problems where the set of choices $A$ is somewhat vague, which we explain in the following section.

There is a large literature in decision theory that aims to address the question of the ``right way'' to represent decision problems by posing abstract conditions that we feel decision models ought to respect, and then proving representation theorems showing that all decision problems can be represented as, for example, probability distributions over functions from choices to outcomes. Notable examples are the theorems of \citet{ramsey_truth_2016} and \citet{savage_foundations_1954} (held to be equivalent), and the theorem of \citet{bolker_functions_1966,jeffrey_logic_1990}. Whether probability gap models can be identified with a Savage or Jeffrey style models of a decision problem is a question that we leave open.

There is also a literature that considers the use of probability sets rather than probability distributions as a tool for representing uncertainty under the name of ``imprecise probability'' \citet{bradley_imprecise_2019,walley_statistical_1991}. Probability sets, it is argued, can be used to represent an epistemic state of witholding judgement on certain propositions and it is useful to be able to represent this in addition to the epistemic state of being indifferent to the truth or falsehood of a proposition. We build our theory on probability sets, so we think it is likely (but we do not show) that imprecise probability can naturally be incorporated as a representation of uncertainty. Speculatively, a decision maker may have some reason to withold judgement regarding which choice they are likely to make while deliberating about which choice is the most desirable, and this might be why we find probability sets to be useful tools for modelling decision problems.

\subsubsection{Causal investigations involve decision problems with ill-defined choices}

While causal investigations are often concerned with helping someone to make better decisions, the kind of ``decision making process'' associated with them is not necessarily well modeled by the setup above. Often the identity of the decision maker and the exact choices at hand are vague. Consider \citet{banerjee_mainstreaming_2016}: a large scale experiment was conducted trialling a number of different strategies all aiming to increase the amount of learning level appropriate instruction available to students in four Indian states. It is not clear who, exactly, is going to make a decision on the basis of this information, but one can guess:

\begin{itemize}
    \item They're someone with interest in and authority to make large scale changes to a school system
    \item They consider the evidence of effectiveness of teaching at the right level relevant to their situation
    \item They consider the evidence regarding which strategies work to implement this approach relevant to their situation
\end{itemize}

This could describe a writer who is considering what kind of advice they can provide in a document, a grantmaker looking to direct funds, a policy maker trying to design policies with appropriate incentives a program manager trying to implement reforms or someone in a position we haven't thought of yet. All of these people have very different choices facing them, and to some extent it is desirable that this research is relevant to all of them.

These situations are common in the field of causal inference and the question of how to formalise them may be worthy of study. However, we feel that it is appropriate at to begin with theory appropriate for the simpler situations where the available choices are known.

\subsection{Other decision theoretic causal models}

\citet{lattimore_causal_2019} and \citet{lattimore_replacing_2019} consider an observational probability model coupled to a collection of indexed interventional probability models, with the observational probability model coupled to the interventional models by shared (unobserved) parameters. In these papers, they show how such a model can reproduce inferences made using Causal Bayesian Networks. We can reproduce this general setup with a conditional probability model $(\prob{P}_{\{\}},A)$ defined by $\prob{P}_{\{\}}^{\RV{OCP}|\RV{X}}$ where $\RV{O}$ represents observations, $\RV{I}$ interventional consequences and $\prob{P}$ shared parameters, with the properties $\RV{P}\CI_{\prob{P}_{\{\}}} \RV{X}$, $\RV{O}\CI_{\prob{P}_{\{\}}} \RV{X}|\RV{P}$ and $\RV{C}\CI_{\prob{P}_{\{\}}} \RV{O}|\RV{X},\RV{P}$.

Note that we may well prefer to use a model in which the intervention $\RV{X}$ is chosen to depend on the observations $\RV{O}$ somehow. It's possible to represent this using probability gap models, but doing so is beyond the scope of this paper.

The approach to decision theoretic causal inference described by \citet{dawid_decision-theoretic_2020} is somewhat different to Rohde and Lattimore's:

\begin{quote}
A fundamental feature of the DT approach is its consideration of the relationships between the various probability distributions that govern different regimes of interest. As a very simple example, suppose that we have a binary treatment variable $\RV{T}$, and a response variable $\RV{Y}$. We consider three different regimes [...] the first two regimes may be described as interventional, and the last as observational.
\end{quote}

The key difference is that Rohde and Lattimore's model employs different variables $\RV{O}$ and $\RV{C}$ to represent observations and interventional consequences, which allows us to write conditional independence statements like $\RV{C}\CI_{\prob{P}_{\{\}}} \RV{O}|\RV{X},\RV{P}$, while Dawid's approach uses the same variable $\RV{Y}$ to represent observations and interventional consequences, depending on the choice of regime. In this scheme there is no way we can see to express something like ``the observations are independent of the interventional consequences given the choice of intervention and the parameters''. If we require that the map from regimes to probability distributions is measurable (which can be trivially satisfied if the set of regimes is countable), then we can also model this approach using conditional probability models where the conditioning variable $\RV{X}$ corresponds to the regime indicator.

\citet{heckerman_decision-theoretic_1995} also explore a decision theoretic approach to causal inference. Their approach represents a decision problem in terms of choices $\RV{D}$, outcome variables $\RV{U}$ and unobserved states of the world $\RV{S}$. Conditional on $\RV{S}$ and $\RV{D}$, they assume outcomes are deterministic. This is similar to the approach of Lattimore and Rohde, with the added requirement of deterministic outcomes (though see the next section) and no distinction between observations and outcomes of interventions (though one could always postulate that $\RV{U}$ is a pair of variables $(\RV{O},\RV{I})$ satisfying the independences in the Lattimore and Rohde model). Heckerman and Shachter's approach is based on Savage's decision theory.

\subsection{Randomness pushback}\label{sec:curry}

Given a function $f:X\times Y\to Z$, we can obtain a curried version $\lambda f:Y\to Z^X$. In particular, if $Y=\{*\}$ then $\lambda f:\{*\}\to Y^X$. At least for countable $X$, we can apply this construction to Markov kernels: given a kernel $\kernel{K}:X\kto Y$, define $\kernel{L}: \{*\}\kto Y^X$ by 
\begin{align}
    \lambda \kernel{K} ((y_i)_{i\in X}) &= \prod_{i\in X} \kernel{K}(y_i|i)
\end{align}

We can then define an evaluation map $\text{ev}:Y^X\times X\to Y$ by $\text{ev}((y_i)_{i\in X},x)=y_x$. Then

\begin{align}
    \kernel{K} &= \tikzfig{curry_kernel_definition} \label{eq:curry_identity}\\
    &\iff\\
    \kernel{K}(A|x) &= \int_{Y^X} \delta_{\text{ev}(y^X,x)}(A) \kernel{L}(\mathrm{d}y^X|x)
\end{align}

Unlike the case of function currying, $\lambda \kernel{K}$ is not the unique Markov kernel for which \ref{eq:curry_identity} holds. In fact, we can substitute any $\kernel{M}$ such that, for any $i\in X$

\begin{align}
    \sum_{y_{\{i\}^C\in Y^{|X|-1}}} \kernel{M}((y_i)_{i\in X}) = \kernel{K}(y_i|i)
\end{align}

This representation of a Markov kernel is called a \emph{randomness pushback} by \citet{fritz_synthetic_2020}.

\subsection{Connections to potential outcomes}

Randomness pushbacks have a few features in common with potential outcomes causal models. For our purposes, we will say a potential outcomes model is a probability set $(\Omega,\sigalg{F},\prob{P}_{\{\}})$ along with variables $\RV{X}$, $\RV{Y}$, $\RV{Y}^X$ such that 

\begin{align}
    \prob{P}_{\{\}}^{\RV{Y}|\RV{XY}^X} &= \kernel{F}_{\text{ev}}
\end{align}

More commonly, this property is expressed as

\begin{align}
    \RV{Y}\overset{a.s.}{=}\text{ev}(\RV{X},\RV{Y}^X)
\end{align}

We consider a potential outcomes model to be a probability set here, but we can formally recover a ``traditional'' potential outcomes model by considering probability sets of size $1$.

If we additionally have the existence of $\prob{P}_{\{\}}^{\RV{Y}^X|\RV{X}}$ and $\RV{Y}^\RV{X}\CI_{\prob{P}_{\{\}}} \RV{X}$ then 

\begin{align}
    \prob{P}_{\{\}}^{\RV{Y}|\RV{X}} &= \tikzfig{curry_kernel_copied}\label{eq:curry_identity_po}
\end{align}

Equation \ref{eq:curry_identity_po} is clearly a version of \ref{eq:curry_identity}. As we have established, provided $\prob{P}_{\{\}}^{\RV{Y}|\RV{X}}$ exists, we can always introduce some variable $\RV{Y}^X$ and corresponding $\prob{P}_{\{\}}^{\RV{Y}^X}$ such that Equation \ref{eq:curry_identity_po} holds.

The point that we want to make is that representing some conditional probability with a randomness pushback is not itself at all special - in fact, it's possible to do it with any conditional probability. We suspect that more important than questions about the choice of representation is the question: what is the conditional probability that is being represented? That is, what is the measurement procedure that gives us $\proc{X}$ and $\proc{Y}$ which we model with the random variables $\RV{X}$ and $\RV{Y}$?

A similar view is expressed by \citet{dawid_causal_2000} and \citet{richardson2013single}, who both indicate that avoiding assumptions that cannot be tested by an ideal experiment is a desirable feature of a causal model. \citet{richardson2013single} consider models that make use of the potential outcomes approach that go beyond Equation \ref{eq:curry_identity_po}, but a Single World Intervention Graph (SWIG) fundamentally represents a collection of probability measures indexed by different values of a possible intervention. If we suppose that deterministically choosing an intervention $x$ yields the probability model corresponding to the $x$-indexed SWIG, and allow that we can have measurement procedures that give us intervention values (Section \label{sec:actions}), then such an indexed collection of probability models is a conditional probability -- namely, the probability of outcomes conditional on interventions.

The question we want to ask is: in a setting where we can make choices that ``probabilistically determine $\RV{X}$'', when does a conditional probability $\prob{P}_{\{\}}^{\RV{Y}|\RV{X}}$ exist?
