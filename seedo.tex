%!TEX root = main.tex


\section{Decision problems}

We want to construct models to help make decisions. For our purposes, ``making a decision'' means choosing some element of a mathematically well-defined set $\alpha\in C$, and following a measurement procedure $\proc{S}_\alpha$ associated with the choice $\alpha\in C$ (see Section \ref{sec:actions}). We suppose that each $\proc{S}_\alpha$ is modeled by a probability model $\prob{P}_\alpha$ on a shared sample space $(\Omega,\sigalg{F})$. Decision making also involves comparing the outcomes of different choices (that is, comparing the probability models $\prob{P}_\alpha$ associated with each choice) and selecting one of the ``best'' decisions, but we leave questions of comparison in the background.

The way we treat consequences of decisions is, in a sense, the opposite of the way we treat conducting measurements. A measurement involves some unclear measurement procedure that interacts with the world and leaves us with a collection of well-defined mathematical objects. Our view of the consequences of making a decision, in contrast, is that we assume that we start with some element of a well-defined set $C$ which is then mapped to some unclear measurement procedure. If a measurement is a ``function'' whose domain is actions in the world, the consequences of a decision is a ``function'' whose codomain is actions in the world.

We make the assumption that each choice is associated with a measurement procedure $\proc{S}_\alpha$ modeled by probability distribution $\prob{P}_\alpha$. This is a Bayesian approach -- uncertainty over the outcomes of a measurement procedure is represented with a single probability measure. It is not our intention to suggest that this is the only way of representing uncertain knowledge, and it may be interesting to extend our theory to other methods for representing uncertain outcomes of a measurement procedure. A particularly simple extension would be to model each $\proc{S}_\alpha$ with a probability set rather than a single probability distribution. 

The model of a decision problem of this form is naturally captured by a probability set $\prob{P}_{\{\}}:=\{\prob{P}_\alpha|\alpha\in C\}$. 

\begin{example}[Choice variable]
Suppose we have a decision procedure $\proc{S}_C:=\{\proc{S}_\alpha|\alpha\in C\}$ that consists of a measurement procedure for each element of a denumerable set of choices $C$. Each measurement procedure $\proc{S}_\alpha$ is modeled by a probability distribution $\prob{P}_\alpha$ on a shared sample space $(\Omega,\sigalg{F})$ such that we have an observable ``choice'' variable $(\RV{C},\RV{C}\circ\proc{S}_\alpha)$ where $\RV{C}\circ\proc{S}_\alpha$ always yields $\alpha$.

Furthermore, Define $\RV{Y}:\Omega\to \Omega$ as the identity function. Then, by supposition, for each $\alpha\in A$, $\prob{P}_\alpha^{\RV{Y}\RV{C}}$ exists and for $A\in \sigalg{Y}$, $B\in \sigalg{C}$:

\begin{align}
    \prob{P}_\alpha^{\RV{YC}}(A\times B) &= \prob{P}_\alpha(A)\delta_\alpha(B)
\end{align}

This implies, for all $\alpha\in C$

\begin{align}
    \prob{P}_\alpha^{\RV{Y}|\RV{C}} &= \prob{P}_\alpha^{\RV{Y}}
\end{align}

Thus $\prob{P}_\square^{\RV{Y}|\RV{C}}$ exists and

\begin{align}
    \prob{P}_\square^{\RV{Y}|\RV{C}}(A|c) &= \prob{P}_\alpha^{\RV{Y}} (A)&\forall A\in \sigalg{Y},c\in C 
\end{align}

In this way, we can take a generic decision problem and represent it with a probability set $\prob{P}_\square$ with the uniform conditional probability $\prob{P}_\square^{\RV{Y}|\RV{C}}$.
\end{example}

If a decision problem model $\prob{P}_\square$ has a uniform conditional probability $\prob{P}_\square^{\RV{Y}|\RV{X}}$ but no uniform marginal $\prob{P}_\square^{\RV{X}}$, we could think of it a situation where $\RV{X}$ is directly controllable and $\RV{Y}$ is controllable via choosing the distribution of $\RV{X}$. 

We might, alternatively, want to construct a probability set $\prob{P}_\square$ by declaring that it has a uniform $\RV{Y}|\RV{X}$ conditional probability $\kernel{K}\overset{\prob{P}_\square}{\cong}\prob{P}_\square^{\RV{Y}|\RV{X}}$ and each element has a known marginal $\mu^{\RV{X}}$. We could then attempt to define $\prob{P}_\alpha$

\begin{align}
    \prob{P}_\alpha &= \prob{P}_\alpha^{\RV{X}}\odot \prob{P}_\square^{\RV{Y}|\RV{X}}\label{eq:set_intersection}
\end{align}

And $\prob{P}_\square = \{\prob{P}_\alpha|\alpha\in C\}$. If we are successful, the end result is the same: we have a collection $\prob{P}_\alpha$ of probability distributions, one associated with each choice, and a probability set $\prob{P}_\square$ with the uniform conditional probability $\kernel{K}\overset{\prob{P}_\square}{\cong}\prob{P}_\square^{\RV{Y}|\RV{X}}$.

However, success is not guaranteed. If the conditional probability $\prob{P}_{\square}^{\RV{Y}|\RV{X}}$ and all the marginal probabilities $\prob{P}_\alpha^{\RV{X}}$ are valid, then by Lemma \ref{lem:valid_extendability} we have at least defined a nonempty \emph{probability set} $\prob{P}_\alpha$ by Eq. \ref{eq:set_intersection} (we would need additional restrictions to ensure that $\prob{P}_\alpha$ was actually a unique probability measure). On the other hand, if we do not ensure that all the ``building blocks'' are valid we can encounter difficulty. This can be analogised to specifying a set of simultaneous equations -- if we are not careful, they may have an empty solution set.

\subsection{Example: invalidity}

Body mass index is defined as a person's weight divided by the square of their height. Suppose we have a measurement process $\proc{S}=(\proc{W},\proc{H})$ and $\proc{B}=\frac{\proc{W}}{\proc{H}^2}$ - i.e. we figure out someone's body mass index first by measuring both their height and weight, and then passing the result through a function that divides the second by the square of the first. Thus, given the random variables $\RV{W},\RV{H}$ modelling $\proc{W},\proc{H}$, $\proc{B}$ is the function given by $\RV{B}=\frac{\RV{W}}{\RV{H}^2}$. Given $x\in \mathbb{R}$, consider the conditional probability
\begin{align}
    \nu^{\RV{B}|\RV{WH}} &= \tikzfig{invalid_BMI_model} \label{eq:bmi_example}
\end{align}
Then pick some $w,h\in\mathbb{R}$ such that $\frac{w}{h^2}\neq x$ and $(\RV{W},\RV{H})\yields (w,h)\neq \emptyset$ (our measurement procedure could possibly yield $(w,h)$ for a person's height and weight). We have $\nu^{\RV{B}|\RV{WH}}(x|w,h)=1$, but 
\begin{align}
    (\RV{B},\RV{W},\RV{H})\yields \{(x,w,h)\} &= \{\omega|(\RV{W},\RV{H})(\omega) = (w,h),\RV{B}(\omega) = \frac{w}{h^2}\}\\
    &=\emptyset
\end{align}
so $\nu^{\RV{B}|\RV{WH}}$ is invalid, and there is some valid $\mu^{\RV{X}}$ such that the probability set $\prob{P}_{\{\}}$ with $\prob{P}_{\{\}}^{\RV{XY}} = \mu^{\RV{X}}\odot \nu^{\RV{Y}|\RV{X}}$ is empty.

Validity rules out conditional probabilities like \ref{eq:bmi_example}. We conjecture that in many cases this condition may either be trivial or implicitly taken into account when constructing conditional probabilities. However, we think it is useful to make this condition explicit nonetheless. We note that the invalid conditional probability \ref{eq:bmi_example} would be used to evaluate the causal effect of body mass index in the causal diagram found in \citet{shahar_association_2009}, presuming the author used the term ``causal effect'' to depend somehow on the function $x\mapsto P(\cdot|do(\RV{B}=x))$ as is the usual convention when discussing causal Bayesian networks.

\subsection{Response conditionals}

Given any probability gap model $(\prob{P}_\square,\{\prob{P}_{\tilde{\alpha}}\}_A,f)$ and variables $\RV{X}:\Omega\to X$, $\RV{Y}:\Omega\to Y$, if we have a conditional probability $\prob{P}_\square^{\RV{Y}|\RV{X}}$, then this must be the conditional probability of $\RV{Y}$ given $\RV{X}$ for any $\alpha\in A$. It must therefore be the case that
\begin{align}
    \prob{P}_\alpha^{\RV{Y}} &= \prob{P}_\alpha^{\RV{X}}\prob{P}_\square^{\RV{Y}}&\forall \alpha\in A
\end{align}

If it is possible to control $\RV{X}$ to some extent (i.e. $\prob{P}_\alpha^{\RV{X}}\neq\prob{P}_{\alpha'}^{\RV{X}}$ for some $\alpha,\alpha'$), then $\prob{P}_\square^{\RV{Y}}$ tells us how $\prob{P}_\alpha^{\RV{X}}$ determines its effect on $\prob{P}_\alpha^{\RV{Y}}$. This feature motivates the name \emph{response conditional} for conditional probabilities of this type.

The motivating question we introduced at the beginning of this paper was ``when are potential outcomes well-defined?''. This is not written using the potential outcomes framework, so we cannot directly address this question. However, we can ask ``when do probability gap models feature response conditionals?''.

\subsection{Response conditionals and potential outcomes}\label{sec:curry}

There is a connection between the question of when a particular conditional probability exists and when potential outcomes are wel-defined. Given any Markov kernel there is an operation akin to function currying termed ``randomness pushback'' that represents the kernel as the product of a probability measure and a deterministic Markov kernel. We observe that potential outcomes models share a number of features in common with a Markov kernel represented using a randomness pushback.

Unlike function currying, there are many different randomness pushbacks that represent the same Markov kernel. The interpretation of potential outcomes models seems to require that exactly one of these possible pushbacks is a genuine potential outcomes model. Several works including \citet{dawid_causal_2000} and \citet{richardson2013single} have expressed the view that some of the degrees of freedom in potential outcomes models are superfluous; both propose that the degrees of freedom that can be tested using some idealised experiment are the degrees that should be kept.

Notably, the single world intervention graphs of \citet{richardson2013single} feature an operation that splits an ``intervenable'' variable $\RV{X}$ into two versions, $\RV{X}$ and $\RV{X}'$, representing ``the actual $\RV{X}$'' and ``the unobseved value $\RV{X}$ would have taken absent intervention'' respectively (this interpretation is ours, not theirs). Thus Richardson and Robins might argue that they are interested in the existence of response conditionals of the form $\prob{P}_\square^{\RV{Y}|\RV{X}\RV{X}'}$ rather than $\prob{P}_{\square}^{\RV{Y}|\RV{X}}$. 

We do not take a position on which degrees of freedom are good or bad in a typical potential outcomes model, nor do we explore conditionals of the form $\prob{P}^{\RV{Y}|\RV{X}\RV{X}'}$. We can, however, distinguish two different questions:

\begin{itemize}
    \item How are response conditionals represented?
    \item Which response conditionals are of interest?
\end{itemize}

The first question seems to be an inconsequential stylistic matter, while the second question may determine the direction of one's analysis.

\subsection{Randomness pushbacks}

Given a function $f:X\times Y\to Z$, we can obtain a curried version $\lambda f:Y\to Z^X$. In particular, if $Y=\{*\}$ then $\lambda f:\{*\}\to Z^X$. At least for countable $X$, we can apply this construction to Markov kernels: given a kernel $\kernel{K}:X\kto Y$, define $\kernel{L}: \{*\}\kto Y^X$ by 
\begin{align}
    \kernel{L} ((y_i)_{i\in X}) &= \prod_{i\in X} \kernel{K}(y_i|i)
\end{align}

We can then define an evaluation map $\text{ev}:Y^X\times X\to Y$ by $\text{ev}((y_i)_{i\in X},x)=y_x$. Then

\begin{align}
    \kernel{K} &= \tikzfig{curry_kernel_definition} \label{eq:curry_identity}\\
    &\iff\\
    \kernel{K}(A|x) &= \int_{Y^X} \delta_{\text{ev}(y^X,x)}(A) \kernel{L}(\mathrm{d}y^X|x)
\end{align}

Unlike the case of function currying, $\kernel{L}$ is not the unique Markov kernel for which \ref{eq:curry_identity} holds. In fact, we can substitute any $\kernel{M}$ such that, for any $i\in X$

\begin{align}
    \sum_{y_{\{i\}^C}\in Y^{|X|-1}} \kernel{M}((y_i)_{i\in X}) = \kernel{K}(y_i|i)
\end{align}

This representation of a Markov kernel is called a \emph{randomness pushback} by \citet{fritz_synthetic_2020}. The idea is that the randomness in the orignal Markov kernel $\kernel{L}$ has been ``pushed back'' to $\kernel{L}$, which now passes through the deterministic Markov kernel $\kernel{F}_{\mathrm{ev}}$.

Randomness pushbacks have a few features in common with potential outcomes causal models. For our purposes, we will say a potential outcomes model is a probability set $(\Omega,\sigalg{F},\prob{P}_{\{\}})$ along with variables $\RV{X}$, $\RV{Y}$, $\RV{Y}^X$ such that 

\begin{align}
    \prob{P}_{\{\}}^{\RV{Y}|\RV{XY}^X} &= \kernel{F}_{\text{ev}}
\end{align}

More commonly, this property is expressed as

\begin{align}
    \RV{Y}\overset{a.s.}{=}\text{ev}(\RV{X},\RV{Y}^X)
\end{align}

We consider a potential outcomes model to be a probability set here, but we can formally recover a ``traditional'' potential outcomes model by considering probability sets of size $1$.

If we additionally have the existence of $\prob{P}_{\{\}}^{\RV{Y}^X|\RV{X}}$ and $\RV{Y}^\RV{X}\CI_{\prob{P}_{\{\}}} \RV{X}$ then 

\begin{align}
    \prob{P}_{\{\}}^{\RV{Y}|\RV{X}} &= \tikzfig{curry_kernel_copied}\label{eq:curry_identity_po}
\end{align}

Equation \ref{eq:curry_identity_po} is clearly a version of \ref{eq:curry_identity}. As we have established, provided $\prob{P}_{\{\}}^{\RV{Y}|\RV{X}}$ exists, we can always introduce some variable $\RV{Y}^X$ and corresponding $\prob{P}_{\{\}}^{\RV{Y}^X}$ such that Equation \ref{eq:curry_identity_po} holds.

\subsubsection{Choices aren't always known}

One area of potentail difficulty with our approach to formalising causal inference from the starting point of modelling decision problems is related to the issue of unknown choice sets. While causal investigations are often concerned with helping someone to make better decisions, the kind of ``decision making process'' associated with them is not necessarily well modeled by the setup above. Often the identity of the decision maker and the exact choices at hand are vague. Consider \citet{banerjee_mainstreaming_2016}: a large scale experiment was conducted trialling a number of different strategies all aiming to increase the amount of learning level appropriate instruction available to students in four Indian states. It is not clear who, exactly, is going to make a decision on the basis of this information, but one can guess:

\begin{itemize}
    \item They're someone with interest in and authority to make large scale changes to a school system
    \item They consider the evidence of effectiveness of teaching at the right level relevant to their situation
    \item They consider the evidence regarding which strategies work to implement this approach relevant to their situation
\end{itemize}

This could describe a writer who is considering what kind of advice they can provide in a document, a grantmaker looking to direct funds, a policy maker trying to design policies with appropriate incentives a program manager trying to implement reforms or someone in a position we haven't thought of yet. All of these people have very different choices facing them, and to some extent it is desirable that this research is relevant to all of them.

These situations are common in the field of causal inference and the question of how to formalise them may be worthy of study. The situation of known choices that we focus on here is easier to study, and it may serve as an idealisation or a limiting case of situations where choices are unknown.

\subsection{Other decision theoretic causal models}

\citet{lattimore_causal_2019} and \citet{lattimore_replacing_2019} consider an observational probability model coupled to a collection of indexed interventional probability models, with the observational probability model coupled to the interventional models by shared (unobserved) parameters. In these papers, they show how such a model can reproduce inferences made using Causal Bayesian Networks. In our terms, Lattimore and Rohde's model family can be thought of as conditional probability models $(\prob{P}_\square^{\RV{OCH}|\RV{D}[M]},\{\prob{P}_{\tilde{\alpha}}^{\RV{D}}\}_A,f)$ where $\RV{D}$ represents the choice of intervention, $\RV{O}$ observations, $\RV{I}$ interventional consequences and $\prob{H}$ model parameters or hypotheses, with the properties $\RV{H}\CI_{\prob{P}_{\square}} \RV{D}$, $\RV{O}\CI_{\prob{P}_{\square}} \RV{D}|\RV{H}$ and $\RV{C}\CI_{\prob{P}_{\square}} \RV{O}|\RV{D},\RV{H}$.

Note that we may well prefer to use a model in which the intervention $\RV{X}$ is chosen to depend on the observations $\RV{O}$ somehow. It's possible to represent this using probability gap models, but doing so is beyond the scope of this paper.

The approach to decision theoretic causal inference described by \citet{dawid_decision-theoretic_2020} is somewhat different to Rohde and Lattimore's:

\begin{quote}
A fundamental feature of the DT approach is its consideration of the relationships between the various probability distributions that govern different regimes of interest. As a very simple example, suppose that we have a binary treatment variable $\RV{T}$, and a response variable $\RV{Y}$. We consider three different regimes [...] the first two regimes may be described as interventional, and the last as observational.
\end{quote}

The key difference is that Rohde and Lattimore's model employs different variables $\RV{O}$ and $\RV{C}$ to represent observations and interventional consequences, which allows us to write conditional independence statements like $\RV{C}\CI_{\prob{P}_{\{\}}} \RV{O}|\RV{D},\RV{H}$, while Dawid's approach uses the same variable $\RV{Y}$ to represent observations and interventional consequences, depending on the choice of regime. In this scheme there is no way we can see to express something like ``the observations are independent of the interventional consequences given the choice of intervention and the parameters''. 

If we require that the map from regimes to probability distributions is measurable (which can be trivially satisfied if the set of regimes is countable), then we can also characterise Dawid's approach using a probability set $\prob{P}_{\{\}}^{\RV{TY}|\RV{F}_T[M]}$ where $\RV{F}_T$ represents the prevailing regime, and $\RV{T}$ and $\RV{Y}$ are as in the quote above. Note that we do not consider conditional probability models here, because it is not obvious how we should say $\RV{F}_T$ is distributed given any choice of intervention; for any choice of intervention, $\RV{F}_T$ will sometimes take th evalue ``observational'' and sometimes take a value corresponding to the chosen intervention. Moreover, it seems inappropriate to posit a sequence of independent and identically distributed copies of $\RV{F}_T$ because we are likely to know it advance exactly when it will and won't take on the observational value, and so we can't associate it with a unique marginal distribution.

\citet{heckerman_decision-theoretic_1995} also explore a decision theoretic approach to causal inference. Their approach is based on the decision theory of \citet{savage_foundations_1954}, and represents a decision problem in terms of choices $\RV{D}$, outcome variables $\RV{U}$ and unobserved states of the world $\RV{S}$; each state of the world defines a deterministic map $\RV{D}\kto \RV{U}$ In comparison with the theory Lattimore and Rohde Heckerman and Schachter's comes with the added requirement of deterministic outcomes. It also features no built in distinction between observations and outcomes of interventions, though one could always consider models where $\RV{U}$ is in fact a pair of variables $(\RV{O},\RV{I})$ such that $\RV{O}$ satisfies the independences required of observations in the Lattimore and Rohde model.
