%!TEX root = main.tex

\section{Decision theoretic causal inference}\label{sec:seedo_models}

People very often have to make decisions with some information they may consult to help them make the decision. We are going to examine how gappy probability models can formally represent problems of this type, which in turn allows us to make use of the theory of probability to help guide us to a good decision. Probabilistic models have a long history of being used to represent decision problems, and there exist a number of coherence theorems that show that preferences that satisfy certain kinds of constraints must admit representation by a probability model and a utility function of the appropriate type. Particularly noteworthy are the theorems of \citet{ramsey_truth_2016} and \citet{savage_foundations_1954}, which together yield a method for representing decision problems known as ``Savage decision theory'', and the theorem of \citet{bolker_functions_1966,jeffrey_logic_1990} which yields a rather different method for representing decision problems known as ``evidential decision theory''. \citet{joyce_foundations_1999} extends Jeffrey and Bolker's result to a representation theorem that subsumes both ``causal decision theory'' and ``evidential decision theory''.

It is an open question whether the models induced by any of these theories are equivalent to probability gap models.

We do not have a comparable axiomatisation of preferences that yield a representation of decision problems in terms of utility and gappy probability. Such an undertaking could potentially clarify some choices that can be made in setting up a gappy probability model of decision making, but it is the subject of future work. Instead, we suppose that we are satisfied with a particular probabilistic model of a decision problem, based on convention rather than axiomatisation.

\subsection{Decision problems}

Suppose we have an observation process $\proc{X}$, modelled by $\RV{X}$ taking values in $X$ (we are \emph{informed}). Given an observation $x\in X$, we suppose that we can choose a decision from a known set $D$ (the set of decisions is \emph{transparent}), and we suppose that choosing a decision results in some action being taken in the real world. As with processes of observation, we will mostly ignore the details of what ``taking an action'' involves. The process of choosing a decision that yields an element of $D$ is a decision making process $\proc{D}$ modelled by $\RV{D}$. We might be able to introduce randomness to the choice, in which case the relation between $\RV{X}$ and $\RV{D}$ may be stochastic.  We will assume that there is some $\proc{Y}$ modelled by $\RV{Y}$ such that $(\RV{X},\RV{D},\RV{Y})$ tell us everything we want to know for the purposes of deciding which outcomes are better than others.

We want a model that allows us to compare different stochastic \emph{decision functions} $\kernel{Q}^{\RV{D}|\RV{X}}_\alpha:X\kto D$, letting $A$ be the set of all such functions available to be chosen. That is, we need a higher order function $f$ that takes a decision function $\kernel{Q}^{\RV{X}|\RV{D}}_\alpha$ and returns a probabilistic model of the consequences of selecting that decision function $\kernel{P}_\alpha^{\RV{DXY}}$. An order 2 model $(\kernel{P}_\square^{\RV{X},\prob{P}_\square^\RV{Y}|\RV{XD}},A)$ defines such a function, though there are many such functions that are not order 2 models. The key feature of probability gap models is that the map is by intersection of probability sets, so for example the conditional probability of $\RV{X}|\RV{D}$ given a decision function $\kernel{Q}^{\RV{X}|\RV{D}}_\alpha$ must actually be equal to $\kernel{Q}^{\RV{X}|\RV{D}}_\alpha$, and we can say the same for $\kernel{P}_\square^{\RV{X}}$ and $\prob{P}_\square^{\RV{Y}|\RV{XD}}$. If we don't think all of these conditional probabilities are fixed, then we want something other than an order 2 model of the type discussed. We will define \emph{ordinary decision problems} to be those for which the desired model $\prob{P}_\square$ is this type of order 2 probability gap model.

\todo[inline]{I think adding hypotheses at this point might make things unnecessarily confusing; on the other hand, they are useful for the connection to classical statistical decision theory. The "repeatable experiments" section shows how see-do models with certain assumptions induce an easier to understand class of hypotheses, and I could just save the idea of a hypothesis until I get there}

We consider an additional kind of gap in our probability model. The nature of this gap is: we don't know exactly which order 2 model $\kernel{P}^{\RV{X}\square \RV{Y}|\RV{D}}$ we ``ought'' to use. To represent this gap we include an unobserved variable $\RV{H}$, the \emph{hypothesis}. We can interpret $\RV{H}$ as expressing the fac that, if we knew the value of $\RV{H}$ then we would know that our decision problem was represented by a unique order 2 model $\kernel{P}_h^{\RV{X}\square \RV{Y}|\RV{D}}$. However, $\RV{H}$ is not known and in fact we do not know how to determine $\RV{H}$ (this is the nature of an \emph{unoserved} variable -- there is no process available to find the value it yields). Our model is thus given by $\kernel{P}^{\RV{X}|\RV{H}\square \RV{Y}|\RV{D}}$.

\begin{definition}[Ordinary decision problem]
An ordinary decision problem $(\prob{P},\Omega,\RV{H},(\RV{X},\proc{X}),(\RV{D},\proc{D}),(\RV{Y},\proc{Y}))$ consists of a fundamental probability set $\Omega$, hypotheses $\RV{H}:\Omega\to H$, observations $\RV{X}\Omega\to X$, decisions $\RV{D}:\Omega\to D$ and consequences $\RV{Y}:\Omega\to Y$, and the latter three random variables are associated with measurement processes. It is equipped with a probability gap model $\prob{P}:\Delta(D)^X\to \Delta(\Omega)^H$ where $\Delta(D)^X$ is the set of valid $\RV{D}|\RV{X}$ Markov kernels $X\kto D$ and $\Delta(\Omega)^H$ is the set of valid Markov kernels $H\kto \Omega$. We require of $\prob{P}$:
\begin{enumerate}
    \item $\kernel{P}_\alpha^{\RV{D}|\RV{X}}=\model{Q}_\alpha^{\RV{D}|\RV{X}}$ for all decision functions $\model{Q}_\alpha^{\RV{D}|\RV{X}}\in \Delta(D)^X$
    \item $\prob{P}^{\RV{X}|\RV{H}}=\model{P}_\alpha^{\RV{X}|\RV{H}}$ for all $\model{P}_\alpha:=\model{P}(\model{Q}_\alpha^{\RV{D}|\RV{X}})$
    \item $\prob{P}^{\RV{Y}|\RV{XDH}}=\model{P}_\alpha^{\RV{Y}|\RV{XDH}}$ for all $\model{P}_\alpha:=\model{P}(\model{Q}_\alpha^{\RV{D}|\RV{X}})$
\end{enumerate}
\end{definition}

(1) reflects the assumption that the ``probability of $\RV{D}$ given $\RV{X}$'' based on the induced model is equal to the ``probability of $\RV{D}$ given $\RV{X}$'' based on the chosen decision function. (2) reflects the assumption that the observations should be modelled identically no matter which decision function is chosen. (3) reflects the assumption that given hypothesis, the observations and the decision, the model of $\RV{Y}$ does not depend any further on the decision function $\alpha$.

Under these assumptions $\prob{P}_\square$ is an order 2 model $(\kernel{P}_\square^{\RV{X},\prob{P}_\square^\RV{Y}|\RV{XD}},A)$ which we call a ``see-do model''.\todo{I need to update the proof for this claim}

% \subsection{What should a probability model represent? Controversies about decision theories}

% There are some decision problems problems in which one or more of these assumptions may be unreasonable, and the correct way to approach to these problems is controversial. Newcomb's problem, for example, invites us to consider a problem where a second party has predicted our choice of decision function $\alpha$ before we have made it, and we have good reasons to believe this prediction is correct \citep{nozick_newcombs_1969}. \emph{The predictor} may then make choices that affect the consequences we expect to see, and this could mean that it is appropriate to consider models in which consequences to depend on $\alpha$ in addition to $\RV{D}$. The question of which kind of model \emph{should} be adopted in such a situation is controversial \citet{weirich_causal_2016,lewis_causation_1986}, and two prominent views on the correct answer are \emph{causal decision theory} and \emph{evidential decision theory}.

% This work does not propose normative rules for getting from a description of the world to a see-do model, and so the question of ``which decision theory?'' is not addressed here. We could ask if causal and evidential decision theory can be operationalised as different (vague) rules for getting from descriptions of the world to probability 2-combs $\model{P}^{\RV{X}|\RV{H}\square \RV{Y}|\RV{D}}$, but we leave this question open.

\subsection{Decisions as measurement procedures}

We have previously posited that observed variables are variables $\RV{X}$ -- themselves purely mathematical objects -- associated with a measurment process $\proc{X}$ that has ``one foot in the real world''. In the framework we have proposed here, decisions correspond to a special class of measurement procedure.

Suppose that we are only contemplating decision functions that map deterministically to $\RV{D}$. Suppose furthermore that we will $\RV{D}$ according to a model $\prob{P}_\square$, a utility function on $X\times D\times Y\to \mathbb{R}$ and a decision rule which is a function $f$ from models, utility functions and decision rules to decisions. Note that models, utility functions and decision rules are all well-defined mathematical objects. If we are confident that our choice will in the end be an element of a well-defined set of objects of the appropriate type, then we are positing that we have a ``measurement procedure'' $\proc{M}$ that yield models, utilities and decision rules. If so, $f\circ \proc{M}$ -- that is, the function that yields a decision -- is itself a measurement procedure. This is what is unique about decisions: proposing a complete decision problem with models, utilities and decision rules, defines a measurement procedure for decisions. Other quantities of interest do not seem to have this property -- we \emph{require} a measurement process for observations in order to make the whole setup work, but we do not \emph{define} it in the course of setting up a model for our decision problem.

\todo[inline]{I don't know how important this observation is, but the fact that $\RV{D}$ is an output of a formal decision making system makes it different from other things we might call decisions, and I wonder if I should call it something else in order to avoid ambiguity.}

% \subsection{Unresponsiveness}

% Given a see-do model $\model{P}^{\RV{X}|\RV{H}\square \RV{Y}|\RV{D}}$, $\RV{A}\CI_{\prob{P}}^{2|*} \RV{D}|\RV{H}$ can be interpreted to express the property, given any hypothesis, $\RV{A}$ does not depend on $\RV{D}$ when we choose $\RV{D}$ randomly.

% This might sound like it expresses a property of ``causal independence''. However, it isn't quite satisfactory for this term. Consider $\RV{A}\in\{0,1\}$ representing the outcome of a fair coin toss, $\RV{D}\in\{0,1\}$ representing a bet on the coin toss and $\RV{B}\in\{0,1\}$ representing the outcome of the bet. There is one hypothesis -- ``the coin is fair'' -- and no observations. We construct a see-do model $\prob{P}$ in the obvious way given these assumptions. Then $\RV{A}\CI_{\prob{P}}^{2|*} \RV{D}|\RV{H}$ (``the coin toss is independent of the decision, for any decision rule'') and $\RV{B}\CI_{\prob{P}}^{2|*}\RV{D}|\RV{H}$ (``the outcome of the bet is independent of the decision, for any decision rule''). However, it is not the case that $(\RV{A},\RV{B})\CI_{\prob{P}}^{2|*}\RV{D}|\RV{H}$. Were both $\RV{A}$ and $\RV{B}$ causally independent of $\RV{D}$, then $(\RV{A},\RV{B})$ also ought to be independent of $\RV{D}$. This example is from \citet{heckerman_decision-theoretic_1995}.

% We will borrow the terminology of \emph{unresponsiveness} from \citet{heckerman_decision-theoretic_1995} to refer to independences like $\RV{A}\CI_{\prob{P}}^{2|*} \RV{D}|\RV{H}$; specifically, where a variable is independent of $\RV{D}$ given $\RV{H}$ under the restricted 2-comb $\model{P}^{\RV{X}|\RV{H}\framebox{*} \RV{Y}|\RV{D}}$.

\subsection{Causal models similar to see-do models}

\citet{lattimore_causal_2019} and \citet{lattimore_replacing_2019} consider an observational probability model and a collection of indexed interventional probability models, with the probability model tied to the interventional models by shared parameters. In these papers, they show how such a model can reproduce inferences made using Causal Bayesian Networks. This kind of model can be identified with a type of see-do model, where what we call hypotheses $\RV{H}$ are identified with the sequence of what Rohde and Lattimore call parameter variables.

The approach to decision theoretic causal inference described by \citet{dawid_decision-theoretic_2020} is somewhat different:

\begin{quote}
A fundamental feature of the DT approach is its consideration of the relationships between the various probability distributions that govern different regimes of interest. As a very simple example, suppose that we have a binary treatment variable $\RV{T}$, and a response variable $\RV{Y}$. We consider three different regimes [...] the first two regimes may be described as interventional, and the last as observational.
\end{quote}

The difference between the model described here and a see-do model is that a see-do model uses different variables $\RV{X}$ and $\RV{Y}$ to represent observations and consequences, while Dawid's model uses the same variable $(\RV{T},\RV{Y})$ to represent outcomes in interventional and observational regimes. In this work we associate one observed variable with each measurement process, while in Dawid's approach $(\RV{T},\RV{Y})$ seem to be doing double duty, representing mesurement processes carried out during observations and after taking action. This can be thought of as the causal analogue of the difference betwen saying we have a sequence $(\RV{X}_1,\RV{X}_2,\RV{X}_3)$ of observations independent and identically distributed according to $\mu\in \Delta(X)$ and saying that we have some observations distributed according to $\prob{P}^{\RV{X}}\in \Delta(X)$. People usually understand what is meant by the latter, but if one is trying to be careful the former is a more precise statement of the model in question.

\citet{heckerman_decision-theoretic_1995} also explore a decision theoretic approach to causal inference. Our approach is quite close to their approach if we identify what we call hypotheses with what they call states and allow for probabilistic dependence between states, decisions and consequences. It is an open question whether their notion of limited unresponsiveness corresponds to any notion of conditional independence in our work.

\citet{jacobs_causal_2019} has used a comb decomposition theorem to prove a sufficient identification condition similar to the identification condition given by \citet{tian2002general}. This theorem depends on the particular inductive hypotheses made by causal Bayesian networks.

\subsection{See-do models and classical statistics}

See-do models are capable of expressing the expected results of a particular choice of decision strategy, but they cannot by themselves tell us which strategies are more desirable than others. To do this, we need some measure of the desirability of our collection of results $\{\prob{P}_\alpha|\alpha\in A\}$. A common way to do this is to employ the principle of expected utility. The classic result of \citet{von_neumann_theory_1944} shows that all preferences over a collection of probability models that obey their axioms of completeness, transitivity, continuity and independence of irrelevant alternatives must be able to be expressed via the principle of expected utility. This does not imply that anyone knows what the appropriate utility function is.

A further property that may hold for some see-do models $\prob{P}^{\RV{X}|\RV{H}\square \RV{Y}|\RV{D}}$ is $\RV{Y}\CI^2_{\prob{P}} \RV{X}|(\RV{H},\RV{D})$. This expresses the view that the consequences are independent of the observations, once the hypothesis and the decision are fixed. Such a situation could hold in our scenario above, where the observations are trial data, the decisions are recommendations to care providers and the consequences are future patient outcomes. In such a situation, we might suppose that the trial data are informative about the consequences only via some parameter such as effect size; if the effect size can be deduced from $\RV{H}$ then our assumption corresponds to the conditional independence above.

Given a see-do model $\prob{P}^{\RV{X}|\RV{H}\square \RV{Y}|\RV{D}}$ along with the principle of expected utility to evaluate strategies, and the assumption $\RV{Y}\CI^2_{\prob{P}} \RV{X}|(\RV{H},\RV{D})$ we obtain a statistical decision problem in the form introduced by \citet{wald_statistical_1950}.

A \emph{statistical model} (or \emph{statistical experiment}) is a collection of probability distributions $\{\prob{P}_\theta\}$ indexed by some set $\Theta$. A statistical decision problem gives us an observation variable $\RV{X}:\Omega\kto X$ and a statistical experiment $\{\prob{P}^{\RV{X}}_\theta\}_\Theta$, a decision set $D$ and a loss $l:\Theta\times D\to \mathbb{R}$. A strategy $\model{S}^{\RV{D}|\RV{X}}_\alpha$ is evaluated according to the risk functional $R(\theta,\alpha):=\sum_{x\in X}\sum_{d\in D} \prob{P}^{\RV{X}}_\theta(x) S^{\RV{D}|\RV{X}}_\alpha (d|x) l(h,d)$. A strategy $\model{S}^{\RV{D}|\RV{X}}_\alpha$ is considered more desirable than $\model{S}^{\RV{D}|\RV{X}}_\beta$ if $R(\theta,\alpha)<R(\theta,\beta)$.

Suppose we have a see-do model $\prob{P}^{\RV{X}|\RV{H}\square \RV{Y}|\RV{D}}$ with $\RV{Y}\CI_{\model{P}} \RV{X}|(\RV{H,D})$, and suppose that the random variable $\RV{Y}$ is a ``negative utility'' function taking values in $\mathbb{R}$ for which \emph{low} values are considered desirable. Define a loss $l:H\times D\to \mathbb{R}$ by $l(h,d) = \sum_{y\in \mathbb{R}} y\model{P}^{\RV{Y}|\RV{H}\RV{D}}(y|h,d)$, we have 

\begin{align}
    \mathbb{E}_{\model{P}_{\alpha}}[\RV{Y}|h] &= \sum_{x\in X} \sum_{d\in D} \sum_{y\in Y} \model{P}^{\RV{X}|\RV{H}}(x|h) \model{Q}_\alpha^{\RV{D}|\RV{X}}(d|x) \model{P}^{\RV{Y}|\RV{HD}}(y|h,d)\\
    &= \sum_{x\in X} \sum_{d\in D} \model{P}^{\RV{X}|\RV{H}}(x|h) \model{Q}_\alpha^{\RV{D}|\RV{X}}(d|x) l(h,d)\\
    &= R(h,\alpha)
\end{align}

If we are given a see-do model where we interpret $\{\model{P}^{\RV{X}|\RV{H}}(\cdot|h)|h\in H\}$ as a statistical experiment and $\RV{Y}$ as a negative utility, the expectation of the utility under the strategy forecast given in equation \ref{eq:see_do_query} is the risk of that strategy under hypothesis $h$.

