%!TEX root = main.tex

\section{Decision theoretic causal inference}\label{sec:seedo_models}

People very often have to make decisions with some information they may consult to help them make the decision. We are going to examine how gappy probability models can formally represent problems of this type, which in turn allows us to make use of the theory of probability to help guide us to a good decision. Probabilistic models have a long history of being used to represent decision problems, and there exist a number of coherence theorems that show that preferences that satisfy certain kinds of constraints must admit representation by a probability model and a utility function of the appropriate type. Particularly noteworthy are the theorems of \citet{ramsey_truth_2016} and \citet{savage_foundations_1954}, which together yield a method for representing decision problems known as ``Savage decision theory'', and the theorem of \citet{bolker_functions_1966,jeffrey_logic_1990} which yields a rather different method for representing decision problems known as ``evidential decision theory''. \citet{joyce_foundations_1999} extends Jeffrey and Bolker's result to a representation theorem that subsumes both ``causal decision theory'' and ``evidential decision theory''.

None of these representation theorems explicitly concern themselves with probability gaps. One may try to find gappy probability models inside the theories, for example in the way that the Savage theory extends a probability distribution over \emph{states} to a probability distribution over \emph{consequence} when given an \emph{act}. However, the connection to probability gaps is not explicit and may not follow precisely. We could make similar comments about causal or evidential decision theories: perhaps ``causal conditionals'' are gappy probability models, but perhaps they aren't exactly.

We do not have a comparable axiomatisation of preferences that yield a representation of decision problems in terms of utility and gappy probability. Such an undertaking could potentially clarify some choices that can be made in setting up a gappy probability model of decision making, but it is the subject of future work. Instead, we suppose that we are satisfied with a particular probabilistic model of a decision problem, a supposition based on convention rather than axiomatisation.

\subsection{Decision problems}

Suppose we have an observation process $\proc{X}$, modelled by $\RV{X}$ taking values in $X$ (we are \emph{informed}). Given an observation $x\in X$, we suppose that we can choose a decision from a known set $D$ (the set of decisions is \emph{transparent}), and we suppose that choosing a decision results in some action being taken in the real world. As with processes of observation, we will mostly ignore the details of what ``taking an action'' involves. The process of choosing a decision that yields an element of $D$ is a decision making process $\proc{D}$ modelled by $\RV{D}$. We might be able to introduce randomness to the choice, in which case the relation between $\RV{X}$ and $\RV{D}$ may be stochastic.  We will assume that there is some $\proc{Y}$ modelled by $\RV{Y}$ such that $(\RV{X},\RV{D},\RV{Y})$ tell us everything we want to know for the purposes of deciding which outcomes are better than others.

We want a model that allows us to compare different stochastic \emph{decision functions} $\kernel{Q}^{\RV{D}|\RV{X}}_\alpha:X\kto D$. What we mean by compare is: we need a higher-order function $M$ that takes a decision function $\kernel{Q}^{\RV{X}|\RV{D}}_\alpha$ and returns a probabilistic model of the consequences of selecting that decision function $\kernel{P}_\alpha^{\RV{DXY}}:=M(\kernel{Q}_\alpha^{\RV{D}|\RV{X}})$. A probability 2-comb $\kernel{P}^{\RV{X}\square \RV{Y}|\RV{D}}$ along with the ``insert'' operation previously defined is such a function, but there are many such functions that are not probability 2-combs. A general function $M$ need not have, for example, $\kernel{Q}_\alpha^{\RV{D}|\RV{X}}=\disint{P}_\alpha^{\RV{D}|\RV{X}}$. We will define \emph{ordinary decision problems} to be those for which the desired model $M$ can be represented as probability 2-combs.

We allow for a further gap in our probability model; namely, we allow for the possibility that we don't know which probability 2-comb $\kernel{P}^{\RV{X}\square \RV{Y}|\RV{D}}$ we ``ought'' to use. We include an unobserved variable $\RV{H}$, which stands for ``hypothesis'', which can be interpreted as a handle by which we can represent another gap in our knowledge: if we knew the value of $\RV{H}$, or alternatively if we knew how $\RV{H}$ was distributed, then we would know that our decision problem was represented by a unique probability 2-comb $\kernel{P}_h^{\RV{X}\square \RV{Y}|\RV{D}}$. However, we do not assume a distribution over $\RV{H}$ is known, and so our model is given by $\kernel{P}^{\RV{X}|\RV{H}\square \RV{Y}|\RV{D}}$.

Specifically, an \emph{ordinary decision problem} $M$ features hypotheses $\RV{H}:\Omega\to H$, observations $\RV{X}\Omega\to X$, decisions $\RV{D}:\Omega\to D$ and consequences $\RV{Y}:\Omega\to Y$. It is modeled by a function $M:\Delta(D)^X\to \Delta(X\times D\times Y)^H$ such that, defining $\kernel{P}_\alpha^{\RV{DXY}}:=M(\kernel{Q}_\alpha^{\RV{D}|\RV{X}})$,

\begin{enumerate}
    \item There is some $\disint{P}_\alpha^{\RV{D}|\RV{X}}$ such that $\kernel{Q}_\alpha^{\RV{D}|\RV{X}}=\disint{P}_\alpha^{\RV{D}|\RV{X}}$ for all decision functions $\alpha$
    \item There is some $\prob{P}^{\RV{X}|\RV{H}}$ such that, for all decision functions $\alpha$, there is some $\disint{P}_\alpha^{\RV{X}|\RV{H}}$ such that $\prob{P}^{\RV{X}|\RV{H}}=\disint{P}_\alpha^{\RV{X}|\RV{H}}$
    \item There is some $\prob{P}^{\RV{Y}|\RV{XDH}}$ such that, for all decision functions $\alpha$, there is some $\disint{P}_\alpha^{\RV{Y}|\RV{XDH}}$ such that $\prob{P}^{\RV{Y}|\RV{XDH}}=\disint{P}_\alpha^{\RV{Y}|\RV{XDH}}$
\end{enumerate}

(1) reflects the assumption that the ``probability of $\RV{D}$ given $\RV{X}$'' based on the induced model is equal to the ``probability of $\RV{D}$ given $\RV{X}$'' based on the chosen decision function. (2) reflects the assumption that the observations should be modelled identically no matter which decision function is chosen. (3) reflects the assumption that given hypothesis, the observations and the decision, the model of $\RV{Y}$ does not depend any further on the decision function $\alpha$.

Under these assumptions, there exists a ``see-do model'' $\model{P}^{\RV{X}|\RV{H}\square \RV{Y}|\RV{D}}$ where, for all $\alpha$:

\begin{align}
    \model{P}_{\alpha} = \tikzfig{seedo} \label{eq:see_do_query}
\end{align}

The proof is given in Appendix \ref{sec:see-do-rep}.

\subsection{What should a probability model represent? Controversies about decision theories}

As we have said, we do not prove any representation theorems showing that a decision problem must be representable as a probability 2-comb $\model{P}^{\RV{X}|\RV{H}\square \RV{Y}|\RV{D}}$. Our motivations for this choice are convention and the fact that they seem intuitive for a number of causal problems. By convention, we mean that models of this form reduce with additional assumptions to well-known statistical and causal models. For an example of the intuitive appeal, we could consider for example a case where $\RV{X}$ represents medical trial data, $\RV{D}$ represents a recommendation to care providers and $\RV{Y}$ represents health indicators of interest. In such cases, it seems quite reasonable to assume that the decision rule (or inference rule) we choose to map data to recommendations is identical to the relationship between $\RV{X}$ and $\RV{D}$ that should appear in our model. It also seems reasonable to assume that our model should not consider the data collected to depend on the decision rule chosen, nor should it consider the consequences to have any additional dependence on the inference rule once the data and the decision have been fixed.

We could consider problems in which one or more of these assumptions could be argued to be unreasonable. Such questions are related to a number of controversies in decision theory. Newcomb's problem, for example, invites us to consider a problem where a second party has predicted our choice of decision function $\alpha$ before we have made the choice, and we have good reasons to believe this prediction is correct \citep{nozick_newcombs_1969}. \emph{The predictor} may then make choices that affect the consequences we expect to see, and this could mean that it is appropriate to consider models in which consequences to depend on $\alpha$ in addition to $\RV{D}$. The question of which kind of model \emph{should} be adopted in such a situation is controversial \citet{weirich_causal_2016,lewis_causation_1986}, and two prominent views on the correct answer are \emph{causal decision theory} and \emph{evidential decision theory}.

This work does not propose normative rules for getting from a description of the world to a see-do model, and so the question of ``which decision theory?'' is not addressed here. We could ask if causal and evidential decision theory can be operationalised as different (vague) rules for getting from descriptions of the world to probability 2-combs $\model{P}^{\RV{X}|\RV{H}\square \RV{Y}|\RV{D}}$, but we leave this question open.

\subsection{Unresponsiveness}

Given a see-do model $\model{P}^{\RV{X}|\RV{H}\square \RV{Y}|\RV{D}}$, $\RV{A}\CI_{\prob{P}}^{2|*} \RV{D}|\RV{H}$ can be interpreted to express the property, given any hypothesis, $\RV{A}$ does not depend on $\RV{D}$ when we choose $\RV{D}$ randomly.

This might sound like it expresses a property of ``causal independence''. However, it isn't quite satisfactory for this term. Consider $\RV{A}\in\{0,1\}$ representing the outcome of a fair coin toss, $\RV{D}\in\{0,1\}$ representing a bet on the coin toss and $\RV{B}\in\{0,1\}$ representing the outcome of the bet. There is one hypothesis -- ``the coin is fair'' -- and no observations. We construct a see-do model $\prob{P}$ in the obvious way given these assumptions. Then $\RV{A}\CI_{\prob{P}}^{2|*} \RV{D}|\RV{H}$ (``the coin toss is independent of the decision, for any decision rule'') and $\RV{B}\CI_{\prob{P}}^{2|*}\RV{D}|\RV{H}$ (``the outcome of the bet is independent of the decision, for any decision rule''). However, it is not the case that $(\RV{A},\RV{B})\CI_{\prob{P}}^{2|*}\RV{D}|\RV{H}$. Were both $\RV{A}$ and $\RV{B}$ causally independent of $\RV{D}$, then $(\RV{A},\RV{B})$ also ought to be independent of $\RV{D}$. This example is from \citet{heckerman_decision-theoretic_1995}.

We will borrow the terminology of \emph{unresponsiveness} from \citet{heckerman_decision-theoretic_1995} to refer to independences like $\RV{A}\CI_{\prob{P}}^{2|*} \RV{D}|\RV{H}$; specifically, where a variable is independent of $\RV{D}$ given $\RV{H}$ under the restricted 2-comb $\model{P}^{\RV{X}|\RV{H}\framebox{*} \RV{Y}|\RV{D}}$.

\subsection{Causal models similar to see-do models}

\citet{lattimore_causal_2019} and \citet{lattimore_replacing_2019} consider an observational probability model and a collection of indexed interventional probability models, with the probability model tied to the interventional models by shared parameters. In these papers, they show how such a model can reproduce inferences made using Causal Bayesian Networks. This kind of model can be identified with a type of see-do model, where what we call hypotheses $\RV{H}$ are identified with the sequence of what Rohde and Lattimore call parameter variables.

The approach to decision theoretic causal inference described by \citet{dawid_decision-theoretic_2020} is somewhat different:

\begin{quote}
A fundamental feature of the DT approach is its consideration of the relationships between the various probability distributions that govern different regimes of interest. As a very simple example, suppose that we have a binary treatment variable $\RV{T}$, and a response variable $\RV{Y}$. We consider three different regimes [...] the first two regimes may be described as interventional, and the last as observational.
\end{quote}

The difference between the model described here and a see-do model is that a see-do model uses different variables $\RV{X}$ and $\RV{Y}$ to represent observations and consequences, while Dawid's model uses the same variable $(\RV{T},\RV{Y})$ to represent outcomes in interventional and observational regimes. In this work we associate one observed variable with each measurement process, while in Dawid's approach $(\RV{T},\RV{Y})$ seem to be doing double duty, representing mesurement processes carried out during observations and after taking action. This can be thought of as the causal analogue of the difference betwen saying we have a sequence $(\RV{X}_1,\RV{X}_2,\RV{X}_3)$ of observations independent and identically distributed according to $\mu\in \Delta(X)$ and saying that we have some observations distributed according to $\prob{P}^{\RV{X}}\in \Delta(X)$. People usually understand what is meant by the latter, but if one is trying to be careful the former is a more precise statement of the model in question.

We have already noted a connection between our work and \citet{heckerman_decision-theoretic_1995}. Our approach is quite close to their approach if we identify what we call hypotheses with what they call states and allow for probabilistic dependence between states, decisions and consequences. It is an open question whether their notion of limited unresponsiveness corresponds to one of our notions of conditional independence.

\citet{jacobs_causal_2019} has used a comb decomposition theorem to prove a sufficient identification condition similar to the identification condition given by \citet{tian2002general}. This theorem depends on the particular inductive hypotheses made by causal Bayesian networks.

\subsection{See-do models and classical statistics}

See-do models are capable of expressing the expected results of a particular choice of decision strategy, but they cannot by themselves tell us which strategies are more desirable than others. To do this, we need some measure of the desirability of our collection of results $\{\prob{P}_\alpha|\alpha\in A\}$. A common way to do this is to employ the principle of expected utility. The classic result of \citet{von_neumann_theory_1944} shows that all preferences over a collection of probability models that obey their axioms of completeness, transitivity, continuity and independence of irrelevant alternatives must be able to be expressed via the principle of expected utility. This does not imply that anyone knows what the appropriate utility function is.

A further property that may hold for some see-do models $\prob{P}^{\RV{X}|\RV{H}\square \RV{Y}|\RV{D}}$ is $\RV{Y}\CI^2_{\prob{P}} \RV{X}|(\RV{H},\RV{D})$. This expresses the view that the consequences are independent of the observations, once the hypothesis and the decision are fixed. Such a situation could hold in our scenario above, where the observations are trial data, the decisions are recommendations to care providers and the consequences are future patient outcomes. In such a situation, we might suppose that the trial data are informative about the consequences only via some parameter such as effect size; if the effect size can be deduced from $\RV{H}$ then our assumption corresponds to the conditional independence above.

Given a see-do model $\prob{P}^{\RV{X}|\RV{H}\square \RV{Y}|\RV{D}}$ along with the principle of expected utility to evaluate strategies, and the assumption $\RV{Y}\CI^2_{\prob{P}} \RV{X}|(\RV{H},\RV{D})$ we obtain a statistical decision problem in the form introduced by \citet{wald_statistical_1950}.

A \emph{statistical model} (or \emph{statistical experiment}) is a collection of probability distributions $\{\prob{P}_\theta\}$ indexed by some set $\Theta$. A statistical decision problem gives us an observation variable $\RV{X}:\Omega\kto X$ and a statistical experiment $\{\prob{P}^{\RV{X}}_\theta\}_\Theta$, a decision set $D$ and a loss $l:\Theta\times D\to \mathbb{R}$. A strategy $\model{S}^{\RV{D}|\RV{X}}_\alpha$ is evaluated according to the risk functional $R(\theta,\alpha):=\sum_{x\in X}\sum_{d\in D} \prob{P}^{\RV{X}}_\theta(x) S^{\RV{D}|\RV{X}}_\alpha (d|x) l(h,d)$. A strategy $\model{S}^{\RV{D}|\RV{X}}_\alpha$ is considered more desirable than $\model{S}^{\RV{D}|\RV{X}}_\beta$ if $R(\theta,\alpha)<R(\theta,\beta)$.

Suppose we have a see-do model $\seedo{P,H,X,D,Y}$ with $\RV{Y}\CI_{\model{P}} \RV{X}|(\RV{H,D})$, and suppose that the random variable $\RV{Y}$ is a ``negative utility'' function taking values in $\mathbb{R}$ for which \emph{low} values are considered desirable. Define a loss $l:H\times D\to \mathbb{R}$ by $l(h,d) = \sum_{y\in \mathbb{R}} y\disint{P}^{\RV{Y}|\RV{H}\RV{D}}(y|h,d)$, we have 

\begin{align}
    \mathbb{E}_{\model{P}_{\alpha}}[\RV{Y}|h] &= \sum_{x\in X} \sum_{d\in D} \sum_{y\in Y} \model{P}^{\RV{X}|\RV{H}}(x|h) \model{Q}_\alpha^{\RV{D}|\RV{X}}(d|x) \disint{P}^{\RV{Y}|\RV{HD}}(y|h,d)\\
    &= \sum_{x\in X} \sum_{d\in D} \model{P}^{\RV{X}|\RV{H}}(x|h) \model{Q}_\alpha^{\RV{D}|\RV{X}}(d|x) l(h,d)\\
    &= R(h,\alpha)
\end{align}

If we are given a see-do model where we interpret $\{\model{P}^{\RV{X}|\RV{H}}(\cdot|h)|h\in H\}$ as a statistical experiment and $\RV{Y}$ as a negative utility, the expectation of the utility under the strategy forecast given in equation \ref{eq:see_do_query} is the risk of that strategy under hypothesis $h$.

