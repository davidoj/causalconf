%!TEX root = main.tex

\section{Conclusion}

Given a set of choices and the ability to compare the desirability of different outcomes, if we want to to compare the desirability of different choices then we need a function from choices to outcomes. If outcomes are to be represented probabilistically, we have proposed that we can represent the relevant kinds of functions using probability gap models, which are themselves defined using probability sets. Probability sets give us natural generalisations of well-established ideas of probabilistic variables, conditional probability and conditional independence, which we can make use of to reason about probabilistic models of choices and consequences.

Using this framework, we examine a particular question relevant to causal inference: when do ``objective'' collections of interventional distributions or distributions over potential outcomes exist? De Finetti previously addressed a similar question: when does an ``objective'' probability distribution describing a sequence of observations exist? He showed that under the assumption that the observations could be modeled exchangeably, an objective probability distribution appears as a parameter shared by a sequence of identically distributed observations, independent conditional on that parameter. We hypothesise that, generalising this argument to models with actions and responses, an ``objective collection of interventional distributions'' is a parameter shared by a conditionally independent and identical sequence of response conditionals.

Under this interpretation, we show that the existence of an ``objective'' response conditional is equivalent to the property of \emph{causal contractibility} of a model of choices and outcomes. We discuss experiments where we thing causal contractibility might hold and experiments where we think it might not. The differences between the two can sometimes be subtle. This refines the idea put forward by \citet{noauthor_does_2016} that potential outcomes are well-defined when they are suitably precisely specified; in particular, we argue that the necessary kind of ``precision'' is that actions are deterministically specified when the decision maker's knowledge is consistent with a judgement of causal contractibility.

There are two challenges that arise when we try to apply this approach to typical causal inference problems. The first is that choice variables (that is, variables that represent a decision maker's choices) play a prominent role in our theory but in many common causal investigations they do not play such a role. Strictly speaking, conditional probability models may be applicable to situations where no decision makers can be identified. However, they do seem to be a particularly natural fit for modelling the prospects a decision maker faces at the point of selecting a choice, and this interpretation played an important role in our investigation of the property of causal contractibility.

The second challenge, somewhat related to the first, is that we are often interested in causal investigations where the observed data are collected under somewhat different circumstances to the outcomes of actions. For example, observations might come from experiments conducted by another party with an action plan that is unknown to the decision maker.

A property of conditional probability models that may help bridge this gap is what we call \emph{proxy control}. This is the condition where, given a sequence of experiments with choices $\RV{D}_i$ and outcomes $\RV{Y}_i$ causally contractible with respect $(\RV{D}_i,\RV{Y}_i)$ pairs, if there exists some intermediate $\RV{X}_i$ such that $\RV{Y}_i\CI\RV{D}_i|\RV{X}_i$ then causal contractibility also holds with respect to $(\RV{X}_i,\RV{Y}_i)$ pairs. This implies, for example, in a randomised experiment where the choices $\RV{D}_i$ are functions from a random source $\RV{R}_i$ to treatments $\RV{X}_i$, we not only have response conditionals $\prob{P}_\square^{\RV{Y}_i|\RV{D}_i}$ that tell us how outcomes respond to treatment assignment functions, but also response conditionals $\prob{P}_\square^{\RV{Y}_i|\RV{X}_i}$ that tell us how outcomes respond to treatments.

The principle of proxy control is likely to be useful to analyse decision problems beyond idealised randomised experiments. For example, \emph{causal inference by invariant prediction} \citep{peters_causal_2016} is a method of causal inference in which data is divided according to a number of different environments, characterised as ``distributions observed under different interventions'', and sets of variables that predict an outcome in the same manner in all environments are taken to be a sufficient set of causal ancestors fo the outcome. We speculate that, where causal inference by invariant prediction is possible, the situation can be modeled with a conditional probability model causally contractible with respect to $(\RV{E},\RV{Y})$ where $\RV{E}$ is a variable representing the environment. Then, if we have $\RV{Y}\CI\RV{E}|\RV{X}$, we also have causal contractibility with respect to $(\RV{X},\RV{Y})$.

\subsection{Choices aren't always known}

One area of potential difficulty with our approach to formalising causal inference from the starting point of modelling decision problems is related to the issue of unknown choice sets. While causal investigations are often concerned with helping someone to make better decisions, the kind of ``decision making process'' associated with them is not necessarily well modeled by the setup above. Often the identity of the decision maker and the exact choices at hand are vague. Consider \citet{banerjee_mainstreaming_2016}: a large scale experiment was conducted trialing a number of different strategies all aiming to increase the amount of learning level appropriate instruction available to students in four Indian states. It is not clear who, exactly, is going to make a decision on the basis of this information, but one can guess:

\begin{itemize}
    \item They're someone with interest in and authority to make large scale changes to a school system
    \item They consider the evidence of effectiveness of teaching at the right level relevant to their situation
    \item They consider the evidence regarding which strategies work to implement this approach relevant to their situation
\end{itemize}

This could describe a writer who is considering what kind of advice they can provide in a document, a grant maker looking to direct funds, a policy maker trying to design policies with appropriate incentives a program manager trying to implement reforms or someone in a position we haven't thought of yet. All of these people have very different choices facing them, and to some extent it is desirable that this research is relevant to all of them.

These situations are common in the field of causal inference and to the extent that the decision theoretic approach aims to be applicable to many common causal inference questions, it must come with some understanding of how to deal with poorly specified choices. One feature of the probability set approach we can exploit is: if the set $C$ of choices for our model $\prob{P}_C$ contains the true set $C^*$ of choices, then universal features of $\prob{P}_C$ will also be universal features of $\prob{P}_{C^*}$ as the latter is a subset of the former. Thus if there is uncertainty about the actual set of choices that we should be considering, we may still be able to posit a large set of choices that we believe will contain the true set of interest.